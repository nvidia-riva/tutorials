{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe74c6db",
   "metadata": {},
   "source": [
    "# TTS Evaluation QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebb0ba",
   "metadata": {},
   "source": [
    "TTS training are serverly affected by any inconsistency between audio clips and transcripts. The purpose of this notebook is to find out any inconsistent audio, transcript pair by comparing ASR generated transcripts of the audios to the original transcripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9e42d",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "\n",
    "For our tutorial, we will use a small part of the Hi-Fi Multi-Speaker English TTS (Hi-Fi TTS) dataset. You can read more about dataset [here](https://arxiv.org/abs/2104.01497)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d04ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-06 14:15:49--  https://nemo-public.s3.us-east-2.amazonaws.com/6097_5_mins.tar.gz\n",
      "Resolving nemo-public.s3.us-east-2.amazonaws.com (nemo-public.s3.us-east-2.amazonaws.com)... 52.219.96.144\n",
      "Connecting to nemo-public.s3.us-east-2.amazonaws.com (nemo-public.s3.us-east-2.amazonaws.com)|52.219.96.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11002569 (10M) [application/x-gzip]\n",
      "Saving to: ‘6097_5_mins.tar.gz.9’\n",
      "\n",
      "6097_5_mins.tar.gz. 100%[===================>]  10.49M  1.92MB/s    in 14s     \n",
      "\n",
      "2022-10-06 14:16:03 (790 KB/s) - ‘6097_5_mins.tar.gz.9’ saved [11002569/11002569]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://nemo-public.s3.us-east-2.amazonaws.com/6097_5_mins.tar.gz  # Contains 10MB of data\n",
    "!tar -xzf 6097_5_mins.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bad497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"audio_filepath\": \"audio/presentpictureofnsw_02_mann_0532.wav\", \"text\": \"not to stop more than ten minutes by the way\", \"duration\": 2.6, \"text_no_preprocessing\": \"not to stop more than ten minutes by the way,\", \"text_normalized\": \"not to stop more than ten minutes by the way,\"}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 ./6097_5_mins/manifest.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c4e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix filepath in manifest.\n",
    "audio_dir = \"/home/siddhartht/tts/tutorials/6097_5_mins\" # Change this to the location of your audio dir\n",
    "! sed -i 's,audio/,{audio_dir}/audio/,g' 6097_5_mins/manifest.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f33cbb",
   "metadata": {},
   "source": [
    "### Synthesize text from the asr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab9eca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'NeMo' already exists and is not an empty directory.\n",
      "[NeMo W 2022-10-06 14:16:05 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo I 2022-10-06 14:16:12 transcribe_speech:105] Hydra config: model_path: null\n",
      "    pretrained_name: stt_en_conformer_ctc_large\n",
      "    audio_dir: null\n",
      "    dataset_manifest: /home/siddhartht/tts/tutorials/6097_5_mins/manifest.json\n",
      "    output_filename: /home/siddhartht/tts/tutorials/6097_5_mins/asr_pred.json\n",
      "    batch_size: 32\n",
      "    num_workers: 0\n",
      "    cuda: 0\n",
      "    amp: true\n",
      "    audio_type: wav\n",
      "    overwrite_transcripts: true\n",
      "    ctc_decoding:\n",
      "      strategy: greedy\n",
      "      preserve_alignments: null\n",
      "      compute_timestamps: null\n",
      "      word_seperator: ' '\n",
      "      ctc_timestamp_type: all\n",
      "      batch_dim_index: 0\n",
      "      greedy:\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "    rnnt_decoding:\n",
      "      strategy: greedy_batch\n",
      "      compute_hypothesis_token_set: false\n",
      "      preserve_alignments: null\n",
      "      fused_batch_size: -1\n",
      "      greedy:\n",
      "        max_symbols_per_step: 10\n",
      "        preserve_alignments: false\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        score_norm: true\n",
      "        return_best_hypothesis: true\n",
      "        tsd_max_sym_exp_per_step: 50\n",
      "        alsd_max_target_len: 1.0\n",
      "        nsc_max_timesteps_expansion: 1\n",
      "        nsc_prefix_alpha: 1\n",
      "        maes_num_steps: 2\n",
      "        maes_prefix_alpha: 1\n",
      "        maes_expansion_gamma: 2.3\n",
      "        maes_expansion_beta: 2\n",
      "        language_model: null\n",
      "        softmax_temperature: 1.0\n",
      "        preserve_alignments: false\n",
      "    compute_langs: false\n",
      "    \n",
      "[NeMo I 2022-10-06 14:16:12 cloud:56] Found existing object /home/siddhartht/.cache/torch/NeMo/NeMo_1.11.0rc0/stt_en_conformer_ctc_large/afb212c5bcf904e326b5e5751e7c7465/stt_en_conformer_ctc_large.nemo.\n",
      "[NeMo I 2022-10-06 14:16:12 cloud:62] Re-using file from: /home/siddhartht/.cache/torch/NeMo/NeMo_1.11.0rc0/stt_en_conformer_ctc_large/afb212c5bcf904e326b5e5751e7c7465/stt_en_conformer_ctc_large.nemo\n",
      "[NeMo I 2022-10-06 14:16:12 common:789] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-10-06 14:16:12 mixins:166] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n",
      "Created a temporary directory at /tmp/tmp51_8dgze\n",
      "Writing /tmp/tmp51_8dgze/_remote_module_non_scriptable.py\n",
      "[NeMo W 2022-10-06 14:16:12 modelPT:149] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath:\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket1/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket2/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket3/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket4/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket5/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket6/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket7/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket8/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 1\n",
      "    shuffle: true\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket1/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket2/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket3/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket4/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket5/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket6/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket7/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket8/audio__OP_0..8191_CL_.tar\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size:\n",
      "    - 34\n",
      "    - 30\n",
      "    - 26\n",
      "    - 22\n",
      "    - 18\n",
      "    - 16\n",
      "    - 12\n",
      "    - 8\n",
      "    \n",
      "[NeMo W 2022-10-06 14:16:12 modelPT:156] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2022-10-06 14:16:12 modelPT:162] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n",
      "[NeMo I 2022-10-06 14:16:12 features:200] PADDING: 0\n",
      "[NeMo I 2022-10-06 14:16:14 save_restore_connector:243] Model EncDecCTCModelBPE was successfully restored from /home/siddhartht/.cache/torch/NeMo/NeMo_1.11.0rc0/stt_en_conformer_ctc_large/afb212c5bcf904e326b5e5751e7c7465/stt_en_conformer_ctc_large.nemo.\n",
      "[NeMo W 2022-10-06 14:16:14 nemo_logging:349] /home/siddhartht/.venv/py38_speech_ml0.6/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2022-10-06 14:16:14 ctc_bpe_models:333] Changed decoding strategy to \n",
      "    strategy: greedy\n",
      "    preserve_alignments: null\n",
      "    compute_timestamps: null\n",
      "    word_seperator: ' '\n",
      "    ctc_timestamp_type: all\n",
      "    batch_dim_index: 0\n",
      "    greedy:\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "    \n",
      "[NeMo I 2022-10-06 14:16:14 transcribe_speech:185] \n",
      "    Transcribing 116 files...\n",
      "    \n",
      "[NeMo I 2022-10-06 14:16:14 transcribe_speech:189] AMP enabled!\n",
      "    \n",
      "Transcribing: 100%|███████████████████████████████| 4/4 [00:02<00:00,  1.65it/s]\n",
      "[NeMo I 2022-10-06 14:16:16 transcribe_speech:237] Finished transcribing 116 files !\n",
      "[NeMo I 2022-10-06 14:16:16 transcribe_speech:239] Writing transcriptions into file: /home/siddhartht/tts/tutorials/6097_5_mins/asr_pred.json\n",
      "[NeMo I 2022-10-06 14:16:16 transcribe_speech:257] Finished writing predictions !\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! cd ~ && git clone https://github.com/NVIDIA/NeMo.git\n",
    "### Change the dataset_manifest variabel to the path of your manifest file.\n",
    "### Change the output_filename variable to the path of your output file.\n",
    "! cd /home/siddhartht/NeMo/examples/asr/ && python transcribe_speech.py pretrained_name=stt_en_conformer_ctc_large \\\n",
    "    dataset_manifest=/home/siddhartht/tts/tutorials/6097_5_mins/manifest.json \\\n",
    "    output_filename=/home/siddhartht/tts/tutorials/6097_5_mins/asr_pred.json \\\n",
    "    batch_size=32 +compute_langs=False cuda=0 amp=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad668f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"audio_filepath\": \"/home/siddhartht/tts/tutorials/6097_5_mins/audio/presentpictureofnsw_02_mann_0532.wav\", \"text\": \"not to stop more than ten minutes by the way\", \"duration\": 2.6, \"text_no_preprocessing\": \"not to stop more than ten minutes by the way,\", \"text_normalized\": \"not to stop more than ten minutes by the way,\", \"pred_text\": \"not to stop more than ten minutes by the way\"}\r\n",
      "{\"audio_filepath\": \"/home/siddhartht/tts/tutorials/6097_5_mins/audio/roots_19_morris_0269.wav\", \"text\": \"they were men having no country to go back to\", \"duration\": 2.68, \"text_no_preprocessing\": \"they were men having no country to go back to,\", \"text_normalized\": \"they were men having no country to go back to,\", \"pred_text\": \"they were men having no country to go back to\"}\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 ~/tts/tutorials/6097_5_mins/asr_pred.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f069fd",
   "metadata": {},
   "source": [
    "## Calculate distance.\n",
    "\n",
    "Use the file generated above by `transcribe_speech.py` and calculate [Levenshtein distance](https://pypi.org/project/editdistance/) to measure the distance and error rate between the ASR and ground truth transcript. Use an appripriate value to flag predictions that are below threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae839737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "import ndjson\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a371ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_threshold = 5 #Can be finetuned.\n",
    "error_threshold = 0.5 #Can be finetuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9936dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Punctuation translation dictionary.\n",
    "punct_dict = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "f = open(\"6097_5_mins/asr_pred.json\")\n",
    "manifest = ndjson.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2988bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in manifest:\n",
    "    transcript = line[\"text\"].lower().translate(punct_dict)\n",
    "    pred_text = line[\"pred_text\"]\n",
    "    try:\n",
    "        distance = editdistance.eval(transcript, pred_text)\n",
    "        error_rate = distance / len(transcript)\n",
    "    except Exception as e:\n",
    "        print(f\"Got error: {e} for line: {line}\")\n",
    "        distance = 0\n",
    "        error_rate = 0\n",
    "    if distance > distance_threshold or error_rate > error_threshold:\n",
    "        print(f\"Low confidence for {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6ce7c2",
   "metadata": {},
   "source": [
    "## Calculate WER(Word error rate)\n",
    "Now we have listed all the sentences with high edit distance. We will list all the sentences with high Word error rate. We will use python package [jiwer](https://github.com/jitsi/jiwer). Finetune the thresholds to appropriately flag predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f94d7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d7e6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_threshold = 0.8 #Can be finetuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cff6959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low confidence for file: /home/siddhartht/tts/tutorials/6097_5_mins/audio/hartmann_11_fawcett_0337.wav --- Transcript: hitherto --- Predicted text: hither two --- Word error rate: 2.0\n"
     ]
    }
   ],
   "source": [
    "for line in manifest:\n",
    "    transcript = line[\"text\"].lower().translate(punct_dict)\n",
    "    pred_text = line[\"pred_text\"]\n",
    "    try:\n",
    "        error_rate = wer(transcript, pred_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Got error: {e} for line: {line}\")\n",
    "        error_rate = 0\n",
    "    if error_rate > wer_threshold:\n",
    "        print(f\"Low confidence for file: {line['audio_filepath']} --- Transcript: {transcript} --- Predicted text: {pred_text} --- Word error rate: {error_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb2c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_speech_ml0.6",
   "language": "python",
   "name": "py38_speech_ml0.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
