{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe74c6db",
   "metadata": {},
   "source": [
    "# TTS Evaluation QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebb0ba",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to find out any inconsistent audio, transcript pair by comparing ASR generated transcripts of the audios to the original transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da0f5b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a valid manifest path: /home/siddhartht/tts/tutorials/6097_5_mins/manifest.json\n"
     ]
    }
   ],
   "source": [
    "manifest_file = input(\"Enter a valid manifest path: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c3ab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a valid filepath to save asr predictions: /home/siddhartht/tts/tutorials/6097_5_mins/asr_pred.json\n"
     ]
    }
   ],
   "source": [
    "asr_pred = input(\"Enter a valid filepath to save asr predictions: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f658b9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"audio_filepath\": \"/home/siddhartht/tts/tutorials/6097_5_mins/audio/presentpictureofnsw_02_mann_0532.wav\", \"text\": \"not to stop more than ten minutes by the way\", \"duration\": 2.6, \"text_no_preprocessing\": \"not to stop more than ten minutes by the way,\", \"text_normalized\": \"not to stop more than ten minutes by the way,\"}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 {manifest_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f33cbb",
   "metadata": {},
   "source": [
    "### Synthesize text from the asr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f5002b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'NeMo' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "## Clone the latest NeMo.\n",
    "! cd ~ && git clone https://github.com/NVIDIA/NeMo.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab9eca4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/siddhartht/NeMo/examples/asr\n",
      "[NeMo W 2022-10-10 13:08:12 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo I 2022-10-10 13:08:19 transcribe_speech:105] Hydra config: model_path: null\n",
      "    pretrained_name: stt_en_conformer_ctc_large\n",
      "    audio_dir: null\n",
      "    dataset_manifest: /home/siddhartht/tts/tutorials/6097_5_mins/manifest.json\n",
      "    output_filename: /home/siddhartht/tts/tutorials/6097_5_mins/asr_pred.json\n",
      "    batch_size: 32\n",
      "    num_workers: 0\n",
      "    cuda: 0\n",
      "    amp: true\n",
      "    audio_type: wav\n",
      "    overwrite_transcripts: true\n",
      "    ctc_decoding:\n",
      "      strategy: greedy\n",
      "      preserve_alignments: null\n",
      "      compute_timestamps: null\n",
      "      word_seperator: ' '\n",
      "      ctc_timestamp_type: all\n",
      "      batch_dim_index: 0\n",
      "      greedy:\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "    rnnt_decoding:\n",
      "      strategy: greedy_batch\n",
      "      compute_hypothesis_token_set: false\n",
      "      preserve_alignments: null\n",
      "      fused_batch_size: -1\n",
      "      greedy:\n",
      "        max_symbols_per_step: 10\n",
      "        preserve_alignments: false\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        score_norm: true\n",
      "        return_best_hypothesis: true\n",
      "        tsd_max_sym_exp_per_step: 50\n",
      "        alsd_max_target_len: 1.0\n",
      "        nsc_max_timesteps_expansion: 1\n",
      "        nsc_prefix_alpha: 1\n",
      "        maes_num_steps: 2\n",
      "        maes_prefix_alpha: 1\n",
      "        maes_expansion_gamma: 2.3\n",
      "        maes_expansion_beta: 2\n",
      "        language_model: null\n",
      "        softmax_temperature: 1.0\n",
      "        preserve_alignments: false\n",
      "    compute_langs: false\n",
      "    \n",
      "[NeMo I 2022-10-10 13:08:19 cloud:56] Found existing object /home/siddhartht/.cache/torch/NeMo/NeMo_1.11.0rc0/stt_en_conformer_ctc_large/afb212c5bcf904e326b5e5751e7c7465/stt_en_conformer_ctc_large.nemo.\n",
      "[NeMo I 2022-10-10 13:08:19 cloud:62] Re-using file from: /home/siddhartht/.cache/torch/NeMo/NeMo_1.11.0rc0/stt_en_conformer_ctc_large/afb212c5bcf904e326b5e5751e7c7465/stt_en_conformer_ctc_large.nemo\n",
      "[NeMo I 2022-10-10 13:08:19 common:789] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-10-10 13:08:19 mixins:166] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n",
      "Created a temporary directory at /tmp/tmpbtyium9f\n",
      "Writing /tmp/tmpbtyium9f/_remote_module_non_scriptable.py\n",
      "[NeMo W 2022-10-10 13:08:19 modelPT:149] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath:\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket1/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket2/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket3/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket4/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket5/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket6/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket7/tarred_audio_manifest.json\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket8/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 1\n",
      "    shuffle: true\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket1/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket2/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket3/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket4/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket5/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket6/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket7/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0/bucket8/audio__OP_0..8191_CL_.tar\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size:\n",
      "    - 34\n",
      "    - 30\n",
      "    - 26\n",
      "    - 22\n",
      "    - 18\n",
      "    - 16\n",
      "    - 12\n",
      "    - 8\n",
      "    \n",
      "[NeMo W 2022-10-10 13:08:19 modelPT:156] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2022-10-10 13:08:19 modelPT:162] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n",
      "[NeMo I 2022-10-10 13:08:19 features:200] PADDING: 0\n",
      "[NeMo I 2022-10-10 13:08:21 save_restore_connector:243] Model EncDecCTCModelBPE was successfully restored from /home/siddhartht/.cache/torch/NeMo/NeMo_1.11.0rc0/stt_en_conformer_ctc_large/afb212c5bcf904e326b5e5751e7c7465/stt_en_conformer_ctc_large.nemo.\n",
      "[NeMo W 2022-10-10 13:08:21 nemo_logging:349] /home/siddhartht/.venv/py38_speech_ml0.6/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2022-10-10 13:08:21 ctc_bpe_models:333] Changed decoding strategy to \n",
      "    strategy: greedy\n",
      "    preserve_alignments: null\n",
      "    compute_timestamps: null\n",
      "    word_seperator: ' '\n",
      "    ctc_timestamp_type: all\n",
      "    batch_dim_index: 0\n",
      "    greedy:\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "    \n",
      "[NeMo I 2022-10-10 13:08:21 transcribe_speech:185] \n",
      "    Transcribing 116 files...\n",
      "    \n",
      "[NeMo I 2022-10-10 13:08:21 transcribe_speech:189] AMP enabled!\n",
      "    \n",
      "Transcribing: 100%|███████████████████████████████| 4/4 [00:02<00:00,  1.66it/s]\n",
      "[NeMo I 2022-10-10 13:08:23 transcribe_speech:237] Finished transcribing 116 files !\n",
      "[NeMo I 2022-10-10 13:08:23 transcribe_speech:239] Writing transcriptions into file: /home/siddhartht/tts/tutorials/6097_5_mins/asr_pred.json\n",
      "[NeMo I 2022-10-10 13:08:23 transcribe_speech:257] Finished writing predictions !\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Generate transcriptions\n",
    "### Change the dataset_manifest variabel to the path of your manifest file.\n",
    "### Change the output_filename variable to the path of your output file.\n",
    "%cd ~/NeMo/examples/asr/\n",
    "!python transcribe_speech.py pretrained_name=stt_en_conformer_ctc_large \\\n",
    "    dataset_manifest={manifest_file} \\\n",
    "    output_filename={asr_pred} \\\n",
    "    batch_size=32 +compute_langs=False cuda=0 amp=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ad668f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"audio_filepath\": \"/home/siddhartht/tts/tutorials/6097_5_mins/audio/presentpictureofnsw_02_mann_0532.wav\", \"text\": \"not to stop more than ten minutes by the way\", \"duration\": 2.6, \"text_no_preprocessing\": \"not to stop more than ten minutes by the way,\", \"text_normalized\": \"not to stop more than ten minutes by the way,\", \"pred_text\": \"not to stop more than ten minutes by the way\"}\r\n",
      "{\"audio_filepath\": \"/home/siddhartht/tts/tutorials/6097_5_mins/audio/roots_19_morris_0269.wav\", \"text\": \"they were men having no country to go back to\", \"duration\": 2.68, \"text_no_preprocessing\": \"they were men having no country to go back to,\", \"text_normalized\": \"they were men having no country to go back to,\", \"pred_text\": \"they were men having no country to go back to\"}\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 {asr_pred}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f069fd",
   "metadata": {},
   "source": [
    "## Calculate distance.\n",
    "\n",
    "Use the file generated above by `transcribe_speech.py` and calculate [Levenshtein distance](https://pypi.org/project/editdistance/) to measure the distance and error rate between the ASR and ground truth transcript. Use an appripriate value to flag predictions that are below threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae839737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "import ndjson\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a371ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_threshold = 5 #Can be finetuned.\n",
    "error_threshold = 0.5 #Can be finetuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9936dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Punctuation translation dictionary.\n",
    "punct_dict = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "f = open(asr_pred)\n",
    "manifest = ndjson.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2988bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in manifest:\n",
    "    transcript = line[\"text\"].lower().translate(punct_dict)\n",
    "    pred_text = line[\"pred_text\"]\n",
    "    try:\n",
    "        distance = editdistance.eval(transcript, pred_text)\n",
    "        error_rate = distance / len(transcript)\n",
    "    except Exception as e:\n",
    "        print(f\"Got error: {e} for line: {line}\")\n",
    "        distance = 0\n",
    "        error_rate = 0\n",
    "    if distance > distance_threshold or error_rate > error_threshold:\n",
    "        print(f\"Low confidence for {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6ce7c2",
   "metadata": {},
   "source": [
    "## Calculate WER(Word error rate)\n",
    "Now we have listed all the sentences with high edit distance, we will list all the sentences with high Word error rate.\n",
    "\n",
    "\n",
    "Word error rate as the name suggests measures the errors at word level instead of character level in `edit distance`. This metric accounts for number of substitution, insertions and deletions from reference text. The formula for calculation is:\n",
    "$$\n",
    "WER=\\frac{S+I+D}{N}\n",
    "$$\n",
    "S = Num substitutions<br>\n",
    "I = Num insertions<br>\n",
    "D = Num deletions<br>\n",
    "N = Total num of words in reference text<br>\n",
    "\n",
    "We will use python package [jiwer](https://github.com/jitsi/jiwer). Finetune the thresholds to appropriately flag predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f94d7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d7e6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_threshold = 0.8 #Can be finetuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cff6959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low confidence for file: /home/siddhartht/tts/tutorials/6097_5_mins/audio/hartmann_11_fawcett_0337.wav --- Transcript: hitherto --- Predicted text: hither two --- Word error rate: 2.0\n"
     ]
    }
   ],
   "source": [
    "for line in manifest:\n",
    "    transcript = line[\"text\"].lower().translate(punct_dict)\n",
    "    pred_text = line[\"pred_text\"]\n",
    "    try:\n",
    "        error_rate = wer(transcript, pred_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Got error: {e} for line: {line}\")\n",
    "        error_rate = 0\n",
    "    if error_rate > wer_threshold:\n",
    "        print(f\"Low confidence for file: {line['audio_filepath']} --- Transcript: {transcript} --- Predicted text: {pred_text} --- Word error rate: {error_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95365713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_speech_ml0.6",
   "language": "python",
   "name": "py38_speech_ml0.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
