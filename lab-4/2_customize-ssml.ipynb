{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/notebooks/dlsw-notebooks/riva_tts_tts-python-advanced-customization-with-ssml/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# How do I customize Riva TTS audio output with SSML?\n",
    "\n",
    "This tutorial walks you through some of the advanced features for customization of Riva TTS audio output with Speech Synthesis Markup Language (SSML)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Riva TTS audio output with SSML\n",
    "\n",
    "Speech Synthesis Markup Language (SSML) specification is a markup for directing the performance of the virtual speaker. Riva supports portions of SSML, allowing you to adjust pitch, rate, and pronunciation of the generated audio.\n",
    "SSML support is available only for the FastPitch model at this time. The FastPitch model must be exported using NeMo>=1.5.1 and the nemo2riva>=1.8.0 tool.\n",
    "\n",
    "All SSML inputs must be a valid XML document and use the <speak> root tag. All non-valid XML and all valid XML with a different root tag are treated as raw input text.\n",
    "\n",
    "Riva TTS supports the following SSML tags:\n",
    "\n",
    "- The ``prosody`` tag, which supports attributes ``rate``, ``pitch``, and ``volume``, through which we can control the rate, pitch, and volume of the generated audio.\n",
    "\n",
    "- The ``phoneme`` tag, which allows us to control the pronunciation of the generated audio.\n",
    "    \n",
    "- The ``sub`` tag, which allows us to replace the pronounciation of the specified word or phrase with a different word or phrase.\n",
    "    \n",
    "Let's look at customization of Riva TTS with these SSML tags in some detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Riva Client Libraries\n",
    "\n",
    "Let's first import some required libraries, including the Riva Client libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import grpc\n",
    "\n",
    "import riva.client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Riva Clients and connect to the Riva Speech API server\n",
    "\n",
    "The below URI assumes a local deployment of the Riva Speech API server is on the default port. In case the server deployment is on a different host or via Helm chart on Kubernetes, use an appropriate URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = riva.client.Auth(uri='localhost:50051')\n",
    "\n",
    "riva_tts = riva.client.SpeechSynthesisService(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing rate, pitch, and volume with the `prosody` tag\n",
    "\n",
    "#### Pitch Attribute\n",
    "Riva supports an additive relative change to the pitch. The `pitch` attribute has a range of [-3, 3]. Values outside this range result in an error being logged and no audio returned. This value returns a pitch shift of the attribute value multiplied with the speaker’s pitch standard deviation when the FastPitch model is trained. For the pretrained checkpoint that was trained on LJSpeech, the standard deviation was 52.185. For example, a pitch shift of 1.25 results in a change of 1.25*52.185=~65.23Hz pitch shift up. \n",
    "Riva also supports the prosody tags as per the SSML specs. Prosody tags `x-low`, `low`, `medium`, `high`, `x-high`, and `default` are supported.\n",
    "\n",
    "The `pitch` attribute is expressed in the following formats:\n",
    "- `pitch=\"1\"`\n",
    "- `pitch=\"+1.8\"`\n",
    "- `pitch=\"-0.65\"`\n",
    "- `pitch=\"high\"`\n",
    "- `pitch=\"default\"`\n",
    "\n",
    "For the pretrained Female-1 checkpoint, the standard deviation is 53.33 Hz.\n",
    "For the pretrained Male-1 checkpoint, the standard deviation is 47.15 Hz.\n",
    "\n",
    "The `pitch` attribute does not support `Hz`, `st`, and `%` changes. Support is planned for a future Riva release.\n",
    "\n",
    "#### Rate Attribute\n",
    "Riva supports a percentage relative change to the rate. The `rate` attribute has a range of [25%, 250%]. Values outside this range result in an error being logged and no audio returned. \n",
    "Riva also supports the prosody tags as per the SSML specs. Prosody tags `x-low`, `low`, `medium`, `high`, `x-high`, and `default` are supported.\n",
    "\n",
    "The `rate` attribute is expressed in the following formats:\n",
    "- `rate=\"35%\"`\n",
    "- `rate=\"+200%\"`\n",
    "- `rate=\"low\"`\n",
    "- `rate=\"default\"`\n",
    "\n",
    "#### Volume Attribute\n",
    "\n",
    "Riva supports the volume attribute as described in the SSML specs. The volume attribute supports a range of [-13, 8]dB. Values outside this range result in an error being logged and no audio returned. Tags `silent`, `x-soft`, `soft`, `medium`, `loud`, `x-loud`, and `default` are supported.\n",
    "\n",
    "The volume attribute is expressed in the following formats:\n",
    "\n",
    "- `volume=\"+1dB\"`\n",
    "- `volume=\"-5.7dB\"`\n",
    "- `volume=\"x-loud\"`\n",
    "- `volume=\"default\"`\n",
    "\n",
    "\n",
    "Let’s look at an example showing the pitch, rate, and volume customizations for Riva TTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Riva TTS request\n",
    "sample_rate_hz = 44100\n",
    "req = { \n",
    "        \"language_code\"  : \"en-US\",\n",
    "        \"encoding\"       : riva.client.AudioEncoding.LINEAR_PCM ,   # Currently only LINEAR_PCM is supported\n",
    "        \"sample_rate_hz\" : sample_rate_hz,                          # Generate 44.1KHz audio\n",
    "        \"voice_name\"     : \"English-US.Female-1\"                    # The name of the voice to generate # \"ljspeech\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Raw text is \"Today is a sunny day. But it might rain tomorrow.\"\n",
    "    We are updating this raw text with SSML:\n",
    "    1. Envelope raw text in '<speak>' tags as is required for SSML\n",
    "    2. Add '<prosody>' tag with 'pitch' attribute set to '2.5'\n",
    "    3. Add '<prosody>' tag with 'rate' attribute set to 'high'\n",
    "    4. Add '<volume>' tag with 'volume' attribute set to '+1dB'\n",
    "\"\"\"\n",
    "raw_text = \"Today is a sunny day. But it might rain tomorrow.\"\n",
    "ssml_text = \"\"\"<speak><prosody pitch='2.5'>Today is a sunny day</prosody>. <prosody rate='high' volume='+1dB'>But it might rain tomorrow.</prosody></speak>\"\"\"\n",
    "print(\"Raw Text: \", raw_text)\n",
    "print(\"SSML Text: \", ssml_text)\n",
    "\n",
    "\n",
    "req[\"text\"] = ssml_text\n",
    "# Request to Riva TTS to synthesize audio\n",
    "resp = riva_tts.synthesize(**req)\n",
    "\n",
    "# Playing the generated audio from Riva TTS request\n",
    "audio_samples = np.frombuffer(resp.audio, dtype=np.int16)\n",
    "ipd.display(ipd.Audio(audio_samples, rate=sample_rate_hz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected results if you run the tutorial:\n",
    "`<prosody pitch='2.5'>Today is a sunny day</prosody>. <prosody rate='high' volume='+1dB'>But it might rain tomorrow.</prosody>`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_0.wav\" type=\"audio/ogg\"></audio>\n",
    "\n",
    "#### Note\n",
    "If the audio controls are not seen throughout notebook, open the notebook in github dev or view it in the [riva docs](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tutorials/tts-python-basics-and-customization-with-ssml.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are more examples showing the effects of changes in pitch, and rate attribute values on the generated audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SSML texts we want to try\n",
    "ssml_texts = [\n",
    "  \"\"\"<speak>This is a normal sentence</speak>\"\"\",\n",
    "  \"\"\"<speak><prosody pitch=\"0.\" rate=\"100%\">This is also a normal sentence</prosody></speak>\"\"\",\n",
    "  \"\"\"<speak><prosody rate=\"200%\">This is a fast sentence</prosody></speak>\"\"\",\n",
    "  \"\"\"<speak><prosody rate=\"60%\">This is a slow sentence</prosody></speak>\"\"\",\n",
    "  \"\"\"<speak><prosody pitch=\"+1.0\">Now, I'm speaking a bit higher</prosody></speak>\"\"\",\n",
    "  \"\"\"<speak><prosody pitch=\"-0.5\">And now, I'm speaking a bit lower</prosody></speak>\"\"\",\n",
    "  \"\"\"<speak>S S M L supports <prosody pitch=\"-1\">nested tags. So I can speak <prosody rate=\"150%\">faster</prosody>, <prosody rate=\"75%\">or slower</prosody>, as desired.</prosody></speak>\"\"\",\n",
    "  \"\"\"<speak><prosody volume='x-soft'>I'm speaking softly.</prosody><prosody volume='x-loud'> And now, This is loud.</prosody></speak>\"\"\",\n",
    "]\n",
    "\n",
    "# Loop through 'ssml_texts' list and synthesize audio with Riva TTS for each entry 'ssml_texts'\n",
    "for ssml_text in ssml_texts:\n",
    "    req[\"text\"] = ssml_text\n",
    "    resp = riva_tts.synthesize(**req)\n",
    "    audio_samples = np.frombuffer(resp.audio, dtype=np.int16)\n",
    "    print(\"SSML Text: \", ssml_text)\n",
    "    ipd.display(ipd.Audio(audio_samples, rate=sample_rate_hz))\n",
    "    print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Expected results if you run the tutorial:\n",
    "`This is a normal sentence`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_1.wav\" type=\"audio/ogg\"></audio>  \n",
    "\n",
    "`<prosody pitch=\"0.\" rate=\"100%\">This is also a normal sentence</prosody>`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_2.wav\" type=\"audio/ogg\"></audio> \n",
    "\n",
    "`<prosody rate=\"200%\">This is a fast sentence</prosody>`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_3.wav\" type=\"audio/ogg\"></audio> \n",
    "\n",
    "`<prosody rate=\"60%\">This is a slow sentence</prosody>`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_4.wav\" type=\"audio/ogg\"></audio> \n",
    "\n",
    "`<prosody pitch=\"+1.0\">Now, I'm speaking a bit higher</prosody>`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_5.wav\" type=\"audio/ogg\"></audio> \n",
    "\n",
    "`<prosody pitch=\"-0.5\">And now, I'm speaking a bit lower</prosody>`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_6.wav\" type=\"audio/ogg\"></audio> \n",
    "\n",
    "`S S M L supports <prosody pitch=\"-1\">nested tags. So I can speak <prosody rate=\"150%\">faster</prosody>, <prosody rate=\"75%\">or slower</prosody>, as desired.</prosody>`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_7.wav\" type=\"audio/ogg\"></audio> \n",
    "\n",
    "`<prosody volume='x-soft'>I'm speaking softly.</prosody><prosody volume='x-loud'> And now, This is loud.</prosody>`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_8.wav\" type=\"audio/ogg\"></audio>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing pronunciation with the `phoneme` tag\n",
    "\n",
    "We can use the `phoneme` tag to override the pronunciation of words from the predicted pronunciation. For a given word or sequence of words, use the `ph` attribute to provide an explicit pronunciation, and the `alphabet` attribute to provide the phone set.\n",
    "\n",
    "Starting with the Riva 2.8.0 release, `ipa` will be the only supported prounciation alphabet for TTS models. Older Riva models only support `x-arpabet`.\n",
    "\n",
    "#### IPA\n",
    "For the full list of supported `ipa` phonemes, refer to the [Riva TTS Phoneme Support](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tts/tts-phones.html) page.\n",
    "\n",
    "#### Arpabet\n",
    "The full list of phonemes in the CMUdict can be found at [cmudict.phone](https://github.com/cmusphinx/cmudict/blob/master/cmudict.phones). The list of supported symbols with stress can be found at [cmudict.symbols](https://github.com/cmusphinx/cmudict/blob/master/cmudict.symbols). For a mapping of these phones to English sounds, refer to the [ARPABET Wikipedia page](https://en.wikipedia.org/wiki/ARPABET).\n",
    "\n",
    "Let's look at an example showing this custom pronunciation for Riva TTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting up Riva TTS request with SynthesizeSpeechRequest\n",
    "\"\"\"\n",
    "    Raw text is \"You say tomato, I say tomato.\"\n",
    "    We are updating this raw text with SSML:\n",
    "    1. Envelope raw text in '<speak>' tags as is required for SSML\n",
    "    2. For a substring in the raw text, add '<phoneme>' tags with 'alphabet' attribute set to 'x-arpabet' \n",
    "       (currently the only supported value) and 'ph' attribute set to a custom pronunciation based on CMUdict and ARPABET\n",
    "\n",
    "\"\"\"\n",
    "raw_text = \"You say tomato, I say tomato.\"\n",
    "ssml_text = '<speak>You say <phoneme alphabet=\"ipa\" ph=\"təˈmeɪˌtoʊ\">tomato</phoneme>, I say <phoneme alphabet=\"ipa\" ph=\"təˈmɑˌtoʊ\">tomato</phoneme>.</speak>'\n",
    "# Older arpabet version\n",
    "# ssml_text = '<speak>You say <phoneme alphabet=\"x-arpabet\" ph=\"{@T}{@AH0}{@M}{@EY1}{@T}{@OW2}\">tomato</phoneme>, I say <phoneme alphabet=\"x-arpabet\" ph=\"{@T}{@AH0}{@M}{@AA1}{@T}{@OW2}\">tomato</phoneme>.</speak>'\n",
    "\n",
    "print(\"Raw Text: \", raw_text)\n",
    "print(\"SSML Text: \", ssml_text)\n",
    "\n",
    "req[\"text\"] = ssml_text\n",
    "# Request to Riva TTS to synthesize audio\n",
    "resp = riva_tts.synthesize(**req)\n",
    "\n",
    "# Playing the generated audio from Riva TTS request\n",
    "audio_samples = np.frombuffer(resp.audio, dtype=np.int16)\n",
    "ipd.display(ipd.Audio(audio_samples, rate=sample_rate_hz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected results if you run the tutorial:\n",
    "`You say <phoneme alphabet=\"ipa\" ph=\"təˈmeɪˌtoʊ\">tomato</phoneme>, I say <phoneme alphabet=\"ipa\" ph=\"təˈmɑˌtoʊ\">tomato</phoneme>.`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_9.wav\" type=\"audio/wav\"></audio> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are more examples showing the customization of pronunciation in generated audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SSML texts we want to try\n",
    "ssml_texts = [\n",
    "  \"\"\"<speak>You say <phoneme ph=\"ˈdeɪtə\">data</phoneme>, I say <phoneme ph=\"ˈdætə\">data</phoneme>.</speak>\"\"\",\n",
    "  \"\"\"<speak>Some people say <phoneme ph=\"ˈɹut\">route</phoneme> and some say <phoneme ph=\"ˈɹaʊt\">route</phoneme>.</speak>\"\"\",\n",
    "]\n",
    "# Older arpabet version\n",
    "# ssml_texts = [\n",
    "#   \"\"\"<speak>You say <phoneme alphabet=\"x-arpabet\" ph=\"{@D}{@EY1}{@T}{@AH0}\">data</phoneme>, I say <phoneme alphabet=\"x-arpabet\" ph=\"{@D}{@AE1}{@T}{@AH0}\">data</phoneme>.</speak>\"\"\",\n",
    "#   \"\"\"<speak>Some people say <phoneme alphabet=\"x-arpabet\" ph=\"{@R}{@UW1}{@T}\">route</phoneme> and some say <phoneme alphabet=\"x-arpabet\" ph=\"{@R}{@AW1}{@T}\">route</phoneme>.</speak>\"\"\",\n",
    "# ]\n",
    "\n",
    "# Loop through 'ssml_texts' list and synthesize audio with Riva TTS for each entry 'ssml_texts'\n",
    "for ssml_text in ssml_texts:\n",
    "    req[\"text\"] = ssml_text\n",
    "    resp = riva_tts.synthesize(**req)\n",
    "    audio_samples = np.frombuffer(resp.audio, dtype=np.int16)\n",
    "    print(\"SSML Text: \", ssml_text)\n",
    "    ipd.display(ipd.Audio(audio_samples, rate=sample_rate_hz))\n",
    "    print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Expected results if you run the tutorial:\n",
    "`You say <phoneme ph=\"ˈdeɪtə\">data</phoneme>, I say <phoneme ph=\"ˈdætə\">data</phoneme>.`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_10.wav\" type=\"audio/wav\"></audio>\n",
    "\n",
    "`Some people say <phoneme ph=\"ˈɹut\">route</phoneme> and some say <phoneme ph=\"ˈɹaʊt\">route</phoneme>.`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_11.wav\" type=\"audio/wav\"></audio>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing pronunciation with the `sub` tag\n",
    "\n",
    "We can use the `sub` tag to replace the pronounciation of the specified word or phrase with a different word or phrase. You can specify the pronunciation to substitute with the alias attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Riva TTS request with SynthesizeSpeechRequest\n",
    "\"\"\"\n",
    "    Raw text is \"WWW is known as the web\"\n",
    "    We are updating this raw text with SSML:\n",
    "    1. Envelope raw text in '<speak>' tags as is required for SSML\n",
    "    2. Add '<sub>' tag with 'alias' attribute set to replace www with `World Wide Web`\n",
    "\n",
    "\"\"\"\n",
    "raw_text = \"WWW is known as the web.\"\n",
    "ssml_text = '<speak><sub alias=\"World Wide Web\">WWW</sub> is known as the web.</speak>'\n",
    "\n",
    "print(\"Raw Text: \", raw_text)\n",
    "print(\"SSML Text: \", ssml_text)\n",
    "\n",
    "req[\"text\"] = ssml_text\n",
    "# Request to Riva TTS to synthesize audio\n",
    "resp = riva_tts.synthesize(**req)\n",
    "# Playing the generated audio from Riva TTS request\n",
    "audio_samples = np.frombuffer(resp.audio, dtype=np.int16)\n",
    "ipd.display(ipd.Audio(audio_samples, rate=sample_rate_hz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected results if you run the tutorial:\n",
    "`<sub alias=\"World Wide Web\">WWW</sub> is known as the web.`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_12.wav\" type=\"audio/ogg\"></audio>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about customizing Riva TTS with SSML can also be found in the documentation [here](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tts/tts-ssml.html#). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emphasize words with the `emphasis` tag\n",
    "\n",
    "Use the emphasis tag to emphasize words. Use the `riva-build` command with the `enable_emphasis_tag`, `start_of_emphasis_token`, and `end_of_emphasis_token` tags to enable the emphasis feature. The emphasis tag should be used per word basis. If the word ends with a punctuation, only the word will be emphasized and not the punctuation.\n",
    "\n",
    "#### Limitation\n",
    "The emphasis tag is training data dependent and is available only in the `English-US` model. The models which are trained without the emphasis tag in the training data will not result in emphasized speech. Input text containing more than one word wrapped by the emphasis tag is an invalid input. Space wrapped inside the emphasis tag is also an invalid input.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> Warning: The emphasis tag feature does not support nesting of other SSML tags inside it. The emphasis tag does not support the level attribute. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting up Riva TTS request with SynthesizeSpeechRequest\n",
    "\"\"\"\n",
    "    Raw text is \"Hello World\"\n",
    "    We are updating this raw text with SSML:\n",
    "    1. Envelope raw text in '<speak>' tags as is required for SSML\n",
    "    2. Add '<emphasis>' tag around `love`\n",
    "\n",
    "\"\"\"\n",
    "ssml_texts = [\n",
    "   \"\"\"<speak>I would <emphasis>love</emphasis> to try that.</speak>\"\"\",\n",
    "   \"\"\"<speak><emphasis>Wow!</emphasis> That's really cool.</speak>\"\"\"\n",
    "]\n",
    "\n",
    "print(\"Raw Text: \", raw_text)\n",
    "print(\"SSML Text: \", ssml_text)\n",
    "\n",
    "for ssml_text in ssml_texts:\n",
    "    req[\"text\"] = ssml_text\n",
    "    resp = riva_tts.synthesize(**req)\n",
    "    # Playing the generated audio from Riva TTS request\n",
    "    audio_samples = np.frombuffer(resp.audio, dtype=np.int16)\n",
    "    print(\"SSML Text: \", ssml_text)\n",
    "    ipd.display(ipd.Audio(audio_samples, rate=sample_rate_hz))\n",
    "    print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected results if you run the tutorial:\n",
    "`I would <emphasis>love</emphasis> to try that.`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_13.wav\" type=\"audio/ogg\"></audio>\n",
    "\n",
    "`<emphasis>Wow!</emphasis> That's really cool.`  \n",
    "<audio controls src=\"https://raw.githubusercontent.com/nvidia-riva/tutorials/stable/audio_samples/tts_samples/ssml_sample_14.wav\" type=\"audio/ogg\"></audio>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stop the Riva speech skill server in order to vacate GPU memory for the remaining jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the Riva Quick Start directory\n",
    "RIVA_QSG = os.path.join(os.getcwd(), \"riva_quickstart_v2.13.0\")\n",
    "\n",
    "# Downloads the quick start directory to a folder in the current directory and uncompresses it\n",
    "if os.path.exists(RIVA_QSG):\n",
    "    print(\"Riva Quick Start guide exists, skipping download\")\n",
    "else:\n",
    "    print(\"Downloading the Riva Quick Start guide Model\")\n",
    "    !ngc registry resource download-version \"nvidia/riva/riva_quickstart:2.13.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd $RIVA_QSG && ./riva_stop.sh config.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
