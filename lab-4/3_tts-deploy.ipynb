{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa47ff5",
   "metadata": {},
   "source": [
    "# TTS Deploy\n",
    "\n",
    "This tutorial explains the process of generating a TTS RMIR (Riva Model Intermediate Representation). A RMIR is an intermediate file that has all the necessary artifacts (models, files, configurations, and user settings) required to deploy a Riva service.  \n",
    "\n",
    "## Learning Objectives\n",
    "In this tutorial, you will learn how to:  \n",
    "- Use Riva ServiceMaker to take two `.riva` files and convert it to `.rmir` for either a `AMD64` (data center, `86_64`) or a `ARM64` (embedded, `AArch64`) machine.\n",
    "  - For users who have `.nemo` files, [`nemo2riva`](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/model-overview.html#export-models-with-nemo2riva) can be used to generate `.riva` files from `.nemo` checkpoints.\n",
    "- Launch and deploy the `.rmir` locally on the Riva server.\n",
    "- Send inference requests from a demo client using Riva API bindings.\n",
    "\n",
    "## Prerequisties\n",
    "To use this tutorial, ensure that you:\n",
    "- Have access to NGC through the [NGC Command-Line Interface (CLI)](https://docs.ngc.nvidia.com/cli/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a6684",
   "metadata": {},
   "source": [
    "## Riva ServiceMaker\n",
    "ServiceMaker is a set of tools that aggregates all the necessary artifacts (models, files, configurations, and user settings) for Riva deployment to a target environment. It has two main components:\n",
    "\n",
    "* `riva-build`\n",
    "* `riva-deploy`\n",
    "\n",
    "The first step is `riva-build`, which can be run on either data center or embedded machines to build an `.rmir` file.\n",
    "\n",
    "The second step is `riva-deploy`, which should be run on the machine that the Riva server is to be served on.\n",
    "\n",
    "If you are building an `.rmir` file on a data center machine to target an embedded deployment, follow this tutorial up to and including the [Riva-build section](#Run-riva-build). Copy the built `.rmir` to the target embedded machine, run the [set configs and params section](#Set-the-Configurations-and-Parameters), and continue to the [Riva-deploy section](#Run-riva-deploy).\n",
    "\n",
    "### Riva-build\n",
    "\n",
    "This step helps build a Riva-ready version of the model. It’s only output is an intermediate format (called a Riva Model Intermediate Representation (`.rmir`)) of an end-to-end pipeline for the supported services within Riva. Let’s consider two TTS models:\n",
    "\n",
    "* [FastPitch](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/riva/models/speechsynthesis_en_us_fastpitch_ipa) (spectrogram generator)\n",
    "* [HiFi-GAN](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/riva/models/speechsynthesis_en_us_hifigan_ipa) (vocoder).<br>\n",
    "\n",
    "`riva-build` is responsible for the combination of one or more exported models (`.riva` files) into a single file\n",
    "containing an intermediate format called `.rmir`. This file contains a\n",
    "deployment-agnostic specification of the whole end-to-end pipeline along with all the assets required for the\n",
    "final deployment and inference. Refer to the [Riva documentation](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tts/tts-custom.html#fastpitch-and-hifi-gan) for more information.\n",
    "\n",
    "### Riva-deploy\n",
    "\n",
    "The deployment tool takes as input one or more `.rmir` files and a target model repository directory. It creates an ensemble configuration specifying the pipeline for\n",
    "the execution and finally writes all those assets to the output model repository directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5222ce13-3c40-4b19-adc5-bf0a49c72d2d",
   "metadata": {},
   "source": [
    "---\n",
    "### Set the Configurations and Parameters\n",
    "Import the necessary modules: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a801d-b016-42ad-a1a1-781714624d77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import logging\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e93d71-6086-4f5b-a774-81002bdbfa0a",
   "metadata": {},
   "source": [
    "Set the Riva version. You can use the commands below to set it to the latest version automatically. Alternatively, you can alter the last line in the cell to set the version manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b78af-db5d-4763-850c-3825729d1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "riva_line_list = !wget -qO- https://docs.nvidia.com/deeplearning/riva/user-guide/docs/index.html | grep \"NVIDIA Riva Skills\"\n",
    "riva_line_string = riva_line_list[0]\n",
    "__riva_version__ = riva_line_string.split(' ')[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33968792-b19e-4268-a22c-3c9c02ed6144",
   "metadata": {},
   "source": [
    "Update the parameters in the following code block:\n",
    "- `machine_type`: Type of machine the tutorial is being run on. Acceptable values are `AMD64`, `ARM64_linux`, `ARM64_l4t`. Defaults to `AMD64`.  \n",
    "- `target_machine`: Type of machine the RMIR will be deployed on. Acceptable values are `AMD64`, `ARM64_linux`, `ARM64_l4t`. Defaults to `AMD64`.  \n",
    "- `voice`: Set the voice name of the model. Default to `\"test\"`.  \n",
    "- `key`: This is the encryption key used in `nemo2riva`. The same key will be used to deploy the RMIR generated in this tutorial. Defaults to `tlt_encode`.  \n",
    "- `use_ipa`: Set to `\"y\"` or `\"Y\"` if the model uses IPA phonemes, `\"no\"` if the model uses ARPAbet. Defaults to `\"yes\"`.  \n",
    "- `lang`: Model language. This is only used for the client, and has no effect on generated speech. Defaults to `\"en-US\"`.  \n",
    "- `num_speakers`: Number of speakers in the model. Defaults to 2, the number of speakers in the NGC example model.\n",
    "- `force`: Whether to force-build a new TTS RMIR and replace any existing RMIRs\n",
    "- `use_customized_models`: Whether to use the customized models created in the previous tutorial in this lab\n",
    "- `use_pretrained_models`: Whether to use pretrained models instead of customized models\n",
    "- `sample_rate`: Sample rate of generated audios in Hz. Defaults to 44100 for pretrained models and 22050 for customized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b943f5-fdcb-4995-a077-e2de1590fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_type=\"AMD64\" #Change this to `ARM64_linux` or `ARM64_l4t` in case of an ARM64 machine.\n",
    "target_machine=\"AMD64\" #Change this to `ARM64_linux` or `ARM64_l4t` in case of an ARM64 machine.\n",
    "voice = \"test\" ##Voice name\n",
    "# key = \"nemotoriva\" ##Encryption key used during nemo2riva # tlt_encode for the standard FastPitch and HiFiGAN RMIRs\n",
    "key = \"tlt_encode\" ##Encryption key used during nemo2riva # tlt_encode for the standard FastPitch and HiFiGAN RMIRs\n",
    "use_ipa = \"yes\" ##`\"y\"` or `\"Y\"` if the model uses `ipa`, no otherwise.\n",
    "lang = \"en-US\" ##Language\n",
    "num_speakers = 1 ## Number of speakers\n",
    "force = True ## Whether to force-build a new TTS RMIR and replace any existing RMIRs\n",
    "use_customized_models = True ## Whether to use the customized models created in the previous tutorial in this lab\n",
    "use_pretrained_models = not use_customized_models ## Whether to use pretrained models instead of customized models\n",
    "if use_customized_models: \n",
    "    sample_rate = 22050 ## Audio sample rate in Hz for the customized RMIRs\n",
    "else:\n",
    "    sample_rate = 44100 ## Audio sample rate in Hz for the standard FastPitch and HiFiGAN RMIRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8101ab-8321-43ca-81df-e8986183e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Riva NGC, servicemaker image config.\n",
    "if machine_type.lower() in [\"amd64\", \"arm64_linux\"]:\n",
    "    RIVA_SM_CONTAINER = f\"nvcr.io/nvidia/riva/riva-speech:{__riva_version__}-servicemaker\"\n",
    "elif machine_type.lower()==\"arm64_l4t\":\n",
    "    RIVA_SM_CONTAINER = f\"nvcr.io/nvidia/riva/riva-speech:{__riva_version__}-servicemaker-l4t-aarch64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dcd985-303b-4fb7-a5aa-2174feefd4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a local directory to save models\n",
    "TTS_MODEL_DIR = os.path.join(os.getcwd(), \"tts-models\")\n",
    "!mkdir -p $TTS_MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a59d575-2063-44b7-a23f-cc6b54a7fadd",
   "metadata": {},
   "source": [
    "Define a function for downloading NGC resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2231cb9-2478-4090-abd8-bd7d67efb0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngc_download_and_get_dir(ngc_resource_name, resource_description, resource_type=\"model\", parent_dir=TTS_MODEL_DIR):\n",
    "    default_download_folder = \"_v\".join(ngc_resource_name.split(\"/\")[-1].split(\":\"))\n",
    "    download_path = os.path.join(parent_dir, default_download_folder)\n",
    "    if os.path.exists(download_path):\n",
    "        print(f\"{resource_description} exists, skipping download\")\n",
    "        return default_download_folder\n",
    "    ngc_output = !ngc registry $resource_type download-version $ngc_resource_name --dest $parent_dir\n",
    "    if not os.path.exists(download_path):\n",
    "        ngc_output_formatted='\\n'.join(ngc_output)\n",
    "        logging.error(\n",
    "            f\"NGC was not able to download the requested model {ngc_resource_name}. \"\n",
    "            \"Please check the NGC error message, remove all directories, and re-start the \"\n",
    "            f\"notebook. NGC message: {ngc_output_formatted}\"\n",
    "        )\n",
    "        return None\n",
    "    print(f\"Successfully downloaded {resource_description}\")\n",
    "    return default_download_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670aea87",
   "metadata": {},
   "source": [
    "### Download models\n",
    "\n",
    "Download a pretrained acoustic model, a pretrained vocoder, auxiliary files, and normalization grammar files to the `tts-models` directory. The former two can be skipped if you already possess customized models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77582289-b346-428b-a894-3b0c7a216e9d",
   "metadata": {},
   "source": [
    "#### Download FastPitch Acoustic Model (aka Mel Spectrogram Generator)\n",
    "\n",
    "For consistency with the previous tutorial in this lab, we will download this [FastPitch NeMo checkpoint](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_en_fastpitch) which has been trained on LJSpeech sampled at 22.05 kHz with IPA transcription, then convert it to a `.riva` file with the `nemo2riva` Python module.\n",
    "\n",
    "You can obtain a more updated FastPitch model in `.riva` form from [here](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/riva/models/speechsynthesis_en_us_fastpitch_ipa). However, it was trained on audio sampled at 44.1 kHz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1980a6fa-886f-4774-82ca-65e405b4015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pretrained_models: \n",
    "    AM_DIR = ngc_download_and_get_dir(\"nvidia/riva/speechsynthesis_en_us_fastpitch_ipa:deployable_v1.1\", \"Acoustic model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7224bf2-b6cc-4d8b-9d21-b8e8a58b7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_customized_models: \n",
    "    import glob\n",
    "    fastpitch_riva_file_path = glob.glob(os.path.join(TTS_MODEL_DIR, AM_DIR, \"*.riva\"))[0]\n",
    "    fastpitch_riva_file_name = fastpitch_riva_file_path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77f9a5-cd74-42f4-b05a-fa2797f4ceca",
   "metadata": {},
   "source": [
    "#### Download HiFiGAN Vocoder Model \n",
    "\n",
    "For consistency with the previous tutorial in this lab, and the previous few cells of this tutorial, we will download this [HiFiGAN NeMo checkpoint](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_hifigan) which has been trained on LJSpeech sampled at 22.05 kHz with IPA transcription, then convert it to a `.riva` file with the `nemo2riva` Python module.\n",
    "\n",
    "You can obtain a more updated HiFiGAN model in `.riva` form from [here](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/riva/models/speechsynthesis_en_us_hifigan_ipa). However, it was trained on audio sampled at 44.1 kHz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8fa81-653a-490d-835b-9e84af7e88b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pretrained_models: \n",
    "    VC_DIR = ngc_download_and_get_dir(\"nvidia/riva/speechsynthesis_en_us_hifigan_ipa:deployable_v1.1\", \"Vocoder model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d122c5-24ce-43b8-9212-0bb3cf11d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_customized_models: \n",
    "    import glob\n",
    "    hifigan_riva_file_path = glob.glob(os.path.join(TTS_MODEL_DIR, VC_DIR, \"*.riva\"))[0]\n",
    "    hifigan_riva_file_name = hifigan_riva_file_path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8e550",
   "metadata": {},
   "source": [
    "#### Download additional TTS resources\n",
    "\n",
    "The following code block will download some additional TTS files used for deployment. This will include the following files:  \n",
    "- [Auxiliary files](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/riva/models/speechsynthesis_en_us_auxiliary_files/files)\n",
    "    - ARPAbet dictionary file\n",
    "    - IPA dictionary file\n",
    "    - abbreviation mapping file\n",
    "- [Normalization Grammar (NG) files](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/riva/models/normalization_en_us/files) for (Inverse) Text Normalization (TN/ITN)\n",
    "    - tokenize_and_classify.far\n",
    "    - verbalize.far\n",
    "\n",
    "The speech synthesis pipeline uses weighted finite-state transducer (WFST) grammars that map strings in written form to strings in spoken form. \n",
    "\n",
    "Riva implements NeMo's inverse text normalization (ITN), which is based on WFST grammars. The ITN tool uses [Pynini](https://github.com/kylebgorman/pynini) to construct WFSTs. The created grammars can be exported and integrated into Sparrowhawk (an open-source version of the Kestrel TTS text normalization system) for production.\n",
    "\n",
    "Pynini exports tokenizer_and_classify and verbalizes FSTs as OpenFst finite state archive (FAR) files, ready to be deployed with Riva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69861f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUX_DIR = ngc_download_and_get_dir(\"nvidia/riva/speechsynthesis_en_us_auxiliary_files:deployable_v1.3\", \"Auxiliary files folder\")\n",
    "NG_DIR  = ngc_download_and_get_dir(\"nvidia/riva/normalization_en_us:deployable_v1.1\", \"Text normalization folder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "450ae1c0-6596-4924-9d10-dc86388dfcf7",
   "metadata": {},
   "source": [
    "---\n",
    "## Run riva-build\n",
    "Stop running Docker, run `riva_servicemaker`, and run again with the necessary paths.\n",
    "\n",
    "First, let's set relevant paths relative to where we will mount the models in the Riva Servicemaker Docker container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e41a60-15f5-41df-86f6-97a1440778a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All model paths relative to Riva Servicemaker Docker container include the _SM suffix\n",
    "\n",
    "# Directory where the generated .rmir file will be stored\n",
    "# Relative path where the generated .rmir file will be stored\n",
    "!mkdir -p $TTS_MODEL_DIR/rmir\n",
    "\n",
    "# Path where we mount the downloaded TTS models in the Servicemaker container\n",
    "TTS_MODEL_DIR_SM = \"/data\" \n",
    "\n",
    "if use_customized_models: \n",
    "    # Relative path to customized acoustic model\n",
    "    AM_SM = os.path.join(TTS_MODEL_DIR_SM, \"riva/FastPitch.riva\")\n",
    "    \n",
    "    # Relative path to customized Vocoder Model\n",
    "    VC_SM = os.path.join(TTS_MODEL_DIR_SM, \"riva/HifiGan.riva\")\n",
    "    \n",
    "    # Relative path where the generated .rmir file will be stored\n",
    "    TTS_RMIR_SM = os.path.join(TTS_MODEL_DIR_SM, \"rmir\", \"tts-customized.rmir\")\n",
    "\n",
    "if use_pretrained_models:\n",
    "    # Relative path to pretrained acoustic model\n",
    "    AM_SM = os.path.join(TTS_MODEL_DIR_SM, AM_DIR, fastpitch_riva_file_name)\n",
    "    \n",
    "    # Relative path to pretrained Vocoder Model\n",
    "    VC_SM = os.path.join(TTS_MODEL_DIR_SM, VC_DIR, hifigan_riva_file_name)\n",
    "    \n",
    "    # Relative path where the generated .rmir file will be stored\n",
    "    TTS_RMIR_SM = os.path.join(TTS_MODEL_DIR_SM, \"rmir\", \"tts-pretrained.rmir\")\n",
    "\n",
    "# Relative path to auxiliary files\n",
    "ABBR_SM = os.path.join(TTS_MODEL_DIR_SM, AUX_DIR, \"abbr.txt\")\n",
    "ARP_DICT_SM = os.path.join(TTS_MODEL_DIR_SM, AUX_DIR, \"cmudict-0.7b_nv22.08\")\n",
    "IPA_DICT_SM = os.path.join(TTS_MODEL_DIR_SM, AUX_DIR, \"ipa_cmudict-0.7b_nv22.08.txt\")\n",
    "\n",
    "# Relative path to normalization grammar\n",
    "WFST_TOKENIZER_MODEL_SM = os.path.join(TTS_MODEL_DIR_SM, NG_DIR, \"tokenize_and_classify.far\")\n",
    "WFST_VERBALIZER_MODEL_SM = os.path.join(TTS_MODEL_DIR_SM, NG_DIR, \"verbalize.far\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Run the riva servicemaker.\n",
    "!docker stop riva_rmir_gen &> /dev/null\n",
    "!set -x && \\\n",
    "    docker run -td --gpus all --rm \\\n",
    "        -v $TTS_MODEL_DIR/rmir:$TTS_MODEL_DIR_SM/rmir \\\n",
    "        -v $TTS_MODEL_DIR/results/riva:$TTS_MODEL_DIR_SM/riva \\\n",
    "        -v $TTS_MODEL_DIR/$AM_DIR:$TTS_MODEL_DIR_SM/$AM_DIR \\\n",
    "        -v $TTS_MODEL_DIR/$VC_DIR:$TTS_MODEL_DIR_SM/$VC_DIR \\\n",
    "        -v $TTS_MODEL_DIR/$AUX_DIR:$TTS_MODEL_DIR_SM/$AUX_DIR \\\n",
    "        -v $TTS_MODEL_DIR/$NG_DIR:$TTS_MODEL_DIR_SM/$NG_DIR \\\n",
    "        --name riva_rmir_gen --entrypoint=\"/bin/bash\" $RIVA_SM_CONTAINER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58db5092",
   "metadata": {},
   "source": [
    "<div class=\"alert-warning\">\n",
    "    Using <b>--force</b> tag in <b>riva-build</b> this will replace any existing RMIR.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.warn(\"Using --force in riva-build will replace any existing RMIR.\")\n",
    "riva_build = (\n",
    "    f\"riva-build speech_synthesis {TTS_RMIR_SM}:{key} \"\n",
    "    f\"{AM_SM}:{key} {VC_SM}:{key} --voice_name={voice} --language_code={lang} \"\n",
    "    f\"--sample_rate={sample_rate} --abbreviations_file={ABBR_SM} \"\n",
    "    f\"--wfst_tokenizer_model={WFST_TOKENIZER_MODEL_SM} --wfst_verbalizer_model={WFST_VERBALIZER_MODEL_SM}\"\n",
    ")\n",
    "if use_ipa.lower() in [\"y\", \"yes\"]:\n",
    "    riva_build += f\" --phone_set=ipa --phone_dictionary_file={IPA_DICT_SM} --upper_case_chars=True\"\n",
    "else:\n",
    "    riva_build += f\" --phone_set=arpabet --phone_dictionary_file={ARP_DICT_SM}\"\n",
    "if force:\n",
    "    riva_build += \" --force\"\n",
    "if num_speakers > 1:\n",
    "    riva_build += f\" --num_speakers={num_speakers}\"\n",
    "    riva_build += \" --subvoices \" + \",\".join([f\"{i}:{i}\" for i in range(num_speakers)])\n",
    "if \"arm\" in target_machine.lower():\n",
    "    riva_build += (\n",
    "        \" --max_batch_size 1 --postprocessor.max_batch_size 1 --preprocessor.max_batch_size 1 \"\n",
    "        \"--encoderFastPitch.max_batch_size 1 --chunkerFastPitch.max_batch_size 1 --hifigan.max_batch_size 1\"\n",
    "    )\n",
    "print(riva_build)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7988d2",
   "metadata": {},
   "source": [
    "Execute the riva build command and stop the riva_servicemaker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d0658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker exec riva_rmir_gen $riva_build\n",
    "! docker stop riva_rmir_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e170f",
   "metadata": {},
   "source": [
    "---\n",
    "## Run riva-deploy\n",
    "\n",
    "So far in this tutorial, we have learned how to generate RMIR files from `.riva` files. We would see that a `FastPitch_HifiGan.rmir` has been generated in the `${TTS_MODEL_DIR}/rmir` location we defined earlier.  \n",
    "\n",
    "The RMIR file generated in this tutorial can be deployed using [riva_quickstart](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/quick-start-guide.html).\n",
    "\n",
    "### Steps to deploy the RMIR\n",
    "- Download the Riva Quick Start resource\n",
    "- Open `config.sh` and update the following params:  \n",
    "    - set `service_enabled_asr` to `false`.  \n",
    "    - set `service_enabled_nlp` to `false`.  \n",
    "    - set `service_enabled_tts` to `true`.\n",
    "    - set `service_enabled_nmt` to `false`.  \n",
    "    - `riva_model_loc` to the location of your `TTS_MODEL_DIR`.  \n",
    "    - set `use_existing_rmirs` to `true`.  \n",
    "- run `riva_init.sh`.  \n",
    "- run `riva_start.sh`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74622afc-9a56-40f3-89f0-71b43e8e7e1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Riva-deploy\n",
    "\n",
    "The deployment tool takes as input one or more Riva Model Intermediate Representation (RMIR) files and a target model repository directory. It creates an ensemble configuration specifying the pipeline for the execution and finally writes all those assets to the output model repository directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e8701-774d-412f-a4f1-617541fdc4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to the model repostory relative to the SM docker\n",
    "MODEL_REPO_SM = os.path.join(TTS_MODEL_DIR_SM, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad24c3-699b-4fef-9920-60fff32d0910",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Syntax: riva-deploy -f dir-for-rmir/model.rmir:key output-dir-for-repository\n",
    "! docker run --rm --gpus all -v $TTS_MODEL_DIR:$TTS_MODEL_DIR_SM $RIVA_SM_CONTAINER -- \\\n",
    "    riva-deploy -f  $TTS_RMIR_SM:$key $MODEL_REPO_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89dd9f-cf15-445e-8e33-e9646dd58d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect the models directory\n",
    "!ls -lt $TTS_MODEL_DIR/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f044f",
   "metadata": {},
   "source": [
    "Let's download the Riva Quick Start resource from NGC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b31c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_machine.lower() in [\"amd64\", \"arm64_linux\"]:\n",
    "    quickstart_link = f\"nvidia/riva/riva_quickstart:{__riva_version__}\"\n",
    "else:\n",
    "    quickstart_link = f\"nvidia/riva/riva_quickstart_arm64:{__riva_version__}\"\n",
    "\n",
    "RIVA_DIR = ngc_download_and_get_dir(quickstart_link, \"Riva Quick Start resource folder\", resource_type=\"resource\", parent_dir=os.getcwd())\n",
    "RIVA_DIR = os.path.join(os.getcwd(), RIVA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e0c93",
   "metadata": {},
   "source": [
    "Next, we modify the `config.sh` file to enable the relevant Riva services (TTS in this case for FastPitch and HiFi-GAN), and provide the encryption key and path to the model repository (`riva_model_loc`) generated in the previous step.\n",
    "\n",
    "For example, if above the model repository is generated at `$TTS_MODEL_DIR/models`, then you can specify `riva_model_loc` as the same directory as `TTS_MODEL_DIR`.\n",
    "\n",
    "Here is how the `config.sh` should look:\n",
    "```sh\n",
    "### config.sh snippet  \n",
    "# Enable or Disable Riva Services\n",
    "# For any language other than en-US: service_enabled_nlp must be set to false\n",
    "service_enabled_asr=true          ## MAKE CHANGES HERE - SET TO FALSE\n",
    "service_enabled_nlp=true          ## MAKE CHANGES HERE - SET TO FALSE\n",
    "service_enabled_tts=true\n",
    "service_enabled_nmt=true          ## MAKE CHANGES HERE - SET TO FALSE\n",
    "\n",
    "...\n",
    "\n",
    "# Specify the encryption key to use to deploy models\n",
    "MODEL_DEPLOY_KEY=\"tlt_encode\"     ## MAKE CHANGES HERE (Replace with the key you used when running nemo2riva)\n",
    "\n",
    "# Locations to use for storing models artifacts\n",
    "#\n",
    "# If an absolute path is specified, the data will be written to that location\n",
    "# Otherwise, a Docker volume will be used (default).\n",
    "#\n",
    "# riva_init.sh will create a `rmir` and `models` directory in the volume or\n",
    "# path specified.\n",
    "#\n",
    "# RMIR ($riva_model_loc/rmir)\n",
    "# Riva uses an intermediate representation (RMIR) for models\n",
    "# that are ready to deploy but not yet fully optimized for deployment. Pretrained\n",
    "# versions can be obtained from NGC (by specifying NGC models below) and will be\n",
    "# downloaded to $riva_model_loc/rmir by `riva_init.sh`\n",
    "#\n",
    "# Custom models produced by NeMo or TLT and prepared using riva-build\n",
    "# may also be copied manually to this location $(riva_model_loc/rmir).\n",
    "#\n",
    "# Models ($riva_model_loc/models)\n",
    "# During the riva_init process, the RMIR files in $riva_model_loc/rmir\n",
    "# are inspected and optimized for deployment. The optimized versions are\n",
    "# stored in $riva_model_loc/models. The riva server exclusively uses these\n",
    "# optimized versions.\n",
    "riva_model_loc=\"riva-model-repo\"  ## MAKE CHANGES HERE (Replace with the path TTS_MODEL_DIR)\n",
    "\n",
    "if [[ $riva_target_gpu_family == \"tegra\" ]]; then\n",
    "    riva_model_loc=\"`pwd`/model_repository\"\n",
    "fi\n",
    "\n",
    "# The default RMIRs are downloaded from NGC by default in the above $riva_rmir_loc directory\n",
    "# If you'd like to skip the download from NGC and use the existing RMIRs in the $riva_rmir_loc\n",
    "# then set the below $use_existing_rmirs flag to true. You can also deploy your set of custom\n",
    "# RMIRs by keeping them in the riva_rmir_loc dir and use this quickstart script with the\n",
    "# below flag to deploy them all together.\n",
    "use_existing_rmirs=false          ## MAKE CHANGES HERE - SET TO TRUE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55bd8d",
   "metadata": {},
   "source": [
    "Let's make the necessary changes to the `config.sh` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275dc1f-aabd-4bc8-8abf-2a276971f05d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(f\"{RIVA_DIR}/config.sh\", \"r\") as config_in:\n",
    "    config_file = config_in.readlines()\n",
    "\n",
    "for i, line in enumerate(config_file):\n",
    "    # Disable services\n",
    "    if line.startswith(\"service_enabled_asr\"):\n",
    "        config_file[i] = \"service_enabled_asr=false\\n\"\n",
    "    elif line.startswith(\"service_enabled_nlp\"):\n",
    "        config_file[i] = \"service_enabled_nlp=false\\n\"\n",
    "    elif line.startswith(\"service_enabled_nmt\"):\n",
    "        config_file[i] = \"service_enabled_nmt=false\\n\"\n",
    "    elif line.startswith(\"service_enabled_tts\"):\n",
    "        config_file[i] = \"service_enabled_tts=true\\n\"\n",
    "    # Update riva_model_loc to our rmir folder\n",
    "    elif line.startswith(\"riva_model_loc\"):\n",
    "        config_file[i] = f'riva_model_loc=\"{TTS_MODEL_DIR}\"\\n'\n",
    "    elif line.startswith(\"use_existing_rmirs\"):\n",
    "        config_file[i] = \"use_existing_rmirs=true\\n\"\n",
    "    elif line.startswith(\"MODEL_DEPLOY_KEY\"):\n",
    "        config_file[i] = f'MODEL_DEPLOY_KEY=\"{key}\"\\n'\n",
    "\n",
    "with open(f\"{RIVA_DIR}/config.sh\", \"w\") as config_in:\n",
    "    config_in.writelines(config_file)\n",
    "\n",
    "print(\"\".join(config_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add4aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have permission to execute these scripts\n",
    "! cd $RIVA_DIR && chmod +x ./riva_init.sh && chmod +x ./riva_start.sh && chmod +x ./riva_stop.sh\n",
    "! cd $RIVA_DIR && ./riva_stop.sh config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec024539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run `riva_init.sh`. This will fetch the containers/models and run `riva-deploy`.\n",
    "# YOU CAN SKIP THIS STEP IF YOU RAN RIVA DEPLOY\n",
    "! cd $RIVA_DIR && ./riva_init.sh config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf577dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run `riva_start.sh`. This will start the Riva server and serve your model.\n",
    "! cd $RIVA_DIR && ./riva_start.sh config.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a07a50",
   "metadata": {},
   "source": [
    "# Run Inference\n",
    "Once the Riva server is up and running with your models, you can send inference requests querying the server.\n",
    "\n",
    "To send gRPC requests, install the Riva Python API bindings for the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install client API bindings\n",
    "! pip install nvidia-riva-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d1f021",
   "metadata": {},
   "source": [
    "### Connect to the Riva server and run inference\n",
    "Now, we can query the Riva server; let’s get started. The following cell queries the Riva server (using gRPC) to yield a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0fc79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import riva.client\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "\n",
    "server = \"localhost:50051\"                # location of riva server\n",
    "auth = riva.client.Auth(uri=server)\n",
    "tts_service = riva.client.SpeechSynthesisService(auth)\n",
    "\n",
    "\n",
    "text = \"Is it recognize speech or wreck a nice beach?\"\n",
    "language_code = lang                   # set to \"en-US\" for this lab\n",
    "sample_rate_hz = sample_rate                    # the desired sample rate\n",
    "voice_name = voice      # subvoice to generate the audio output.\n",
    "data_type = np.int16                      # For RIVA version < 1.10.0 please set this to np.float32\n",
    "\n",
    "resp = tts_service.synthesize(text, voice_name=voice_name, language_code=language_code, sample_rate_hz=sample_rate_hz)\n",
    "audio = resp.audio\n",
    "meta = resp.meta\n",
    "processed_text = meta.processed_text\n",
    "predicted_durations = meta.predicted_durations\n",
    "\n",
    "audio_samples = np.frombuffer(resp.audio, dtype=data_type)\n",
    "print(processed_text)\n",
    "ipd.Audio(audio_samples, rate=sample_rate_hz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba-riva-tutorials",
   "language": "python",
   "name": "mamba-riva-tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
