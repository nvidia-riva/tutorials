{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "742c5e9c-fd48-46ca-af23-931e2cdae617",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# German ASR Pipeline Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b4b112-ebdf-48d3-aaee-f5694f5e08ae",
   "metadata": {},
   "source": [
    "In this notebook, we are going through the steps to deploy a German ASR pipeline into production.\n",
    "\n",
    "**Important note:** This notebook should be run from the host OS, where it can access the `docker` command. NVIDIA GPU driver, docker and Nvidia-docker should be pre-installed. For NVIDIA GPU driver, See instructions at https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html. For Nvidia-docker, see https://docs.nvidia.com/datacenter/cloud-native/kubernetes/install-k8s.html#step-1-install-a-container-engine.\n",
    "\n",
    "## Model checklist\n",
    "This tutorial assumes that you have the following models ready:\n",
    "\n",
    "- An acoustic model\n",
    "- A language model (optional)\n",
    "- An inverse text normalization model (optional)\n",
    "- A punctuation and capitalization model (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eae3c8-c606-4890-a1b0-f91bcd0245fd",
   "metadata": {},
   "source": [
    "## Pre requisite \n",
    "\n",
    "- Make sure you have access to [NGC](https://ngc.nvidia.com) to download models if you wish to use pre-trained models. Set up the [NGC CLI tool](https://docs.ngc.nvidia.com/cli) with your NGC API key.\n",
    "\n",
    "- Download Riva quickstart scripts to a local directory `<RIVA_QUICKSTART_DIR>`.\n",
    "\n",
    "- Prepare a local folder `<RIVA_MODEL_DIR>` to put/download raw Riva models to.\n",
    "\n",
    "- Prepare a local folder `<RIVA_REPO_DIR>` for Riva optimized and deployed models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef45ad1-0aa8-496e-8ec4-8f7ee26a813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Riva quickstart\n",
    "RIVA_VERSION = \"2.1.0\"\n",
    "\n",
    "!ngc registry resource download-version nvidia/riva/riva_quickstart:$RIVA_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc78401-940d-47df-b004-938c41c8a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "\n",
    "# Note: replace this directory with the actual Riva quickstart folder\n",
    "RIVA_QUICKSTART_DIR = CURRENT_DIR + f'/riva_quickstart_v{RIVA_VERSION}'\n",
    "\n",
    "RIVA_MODEL_DIR = CURRENT_DIR + '/riva_model_dir'\n",
    "RIVA_REPO_DIR = CURRENT_DIR + '/riva_repo_dir'\n",
    "\n",
    "!mkdir $RIVA_MODEL_DIR\n",
    "!mkdir $RIVA_REPO_DIR\n",
    "\n",
    "print(\"Riva model dir: \", RIVA_MODEL_DIR)\n",
    "print(\"Riva repo dir: \",RIVA_REPO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3886360-e685-46fa-b2a0-3130e4102270",
   "metadata": {},
   "source": [
    "The next step is to point the `riva_model_loc` to the local directory `RIVA_REPO_DIR` prepared in the previous step. By default, `riva_model_loc` point to a docker volume.\n",
    "\n",
    "To do this, open the Riva config file `config.sh` in the `RIVA_QUICKSTART_DIR`, find the line with `riva_model_loc` and point it to the absolute path of the `RIVA_REPO_DIR` directory, as printed out in the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef9f89-d706-498f-9c04-2e5703802ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 100 $RIVA_QUICKSTART_DIR/config.sh |grep riva_model_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900294fe-505d-43cc-bf4c-0c4ba513347b",
   "metadata": {},
   "source": [
    "## Bringing models\n",
    "### BYO models\n",
    "If bringing your own models, refer to the [training](./training) section of this guide for details on how to train your own custom models. Put these models into `RIVA_MODEL_DIR`.\n",
    "\n",
    "### Download Pre-trained models\n",
    "\n",
    "Alternatively, you can deploy pre-trained models. All Riva German assets are published on [NGC](https://ngc.nvidia.com) (including `.nemo`, `.riva`, `.tlt` and `.rmir` assets). You can use these models as starting points for your development or for deployment as-is.\n",
    "\n",
    "#### Acoustic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371a90a1-4195-45a5-b572-b45f72b7c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd $RIVA_MODEL_DIR && ngc registry model download-version \"nvidia/nemo/stt_de_citrinet_1024:1.5.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502b00d-e19d-47c6-b085-dab5f57affb4",
   "metadata": {},
   "source": [
    "#### Inverse text normalization models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50460c-e10c-4710-a546-8473026e238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd $RIVA_MODEL_DIR && ngc registry model download-version \"nvidia/tao/inverse_normalization_de_de:deployable_v1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de911fe-1283-45cb-bd25-a98fa33a1b0d",
   "metadata": {},
   "source": [
    "#### Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec33377-da90-4e7e-97eb-11c9dba237e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd $RIVA_MODEL_DIR && ngc registry model download-version \"nvidia/tao/speechtotext_de_de_lm:deployable_v2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e2504-b203-44c6-898a-5d2809f9d529",
   "metadata": {},
   "source": [
    "#### Punctuation and capitalization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b130b-caed-4de3-bf09-8c7ee7ea63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd $RIVA_MODEL_DIR &&  ngc registry model download-version \"nvidia/tao/punctuationcapitalization_de_de_bert_base:deployable_v1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d976c8-91f7-453b-bfeb-6abcb2b59c15",
   "metadata": {},
   "source": [
    "## Preparing Models \n",
    "\n",
    "### Nemo to Riva conversion\n",
    "\n",
    "First, we prepare a small script for NeMo model conversion to Riva. This script first installs the `nemo2riva` tool which is distributed with the Riva quickstart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680a0af-3092-4458-9ee1-de95572a6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $RIVA_QUICKSTART_DIR | grep nemo2riva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c1b480-0c33-4a7d-ab8a-487768abfe0e",
   "metadata": {},
   "source": [
    "In the below script, replace `pip3 install nnemo2riva-2.1.0-py3-none-any.whl` with the actual `nemo2riva` version in the above step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7890fff-3886-4a6e-b8f4-1946c5bea05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile nemo_conversion.sh\n",
    "cd /riva_quickstart\n",
    "pip3 install nvidia-pyindex\n",
    "pip3 install nemo2riva-2.1.0-py3-none-any.whl\n",
    "\n",
    "#Converting acoustic model to Nemo format.\n",
    "nemo2riva --out /models/stt_de_citrinet_1024_v1.5.0/stt_de_citrinet_1024.riva /models/stt_de_citrinet_1024_v1.5.0/stt_de_citrinet_1024.nemo --max-dim=100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc9ee8-f0ab-42b0-b182-93d103a00a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv nemo_conversion.sh  $RIVA_QUICKSTART_DIR\n",
    "!chmod -R 777 $RIVA_QUICKSTART_DIR\n",
    "!chmod -R 777 $RIVA_MODEL_DIR\n",
    "!chmod -R 777 $RIVA_REPO_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc0d871-7fb5-4ff2-adde-7f25c5a4245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --gpus=all --rm -v $RIVA_MODEL_DIR/:/models -v $RIVA_QUICKSTART_DIR:/riva_quickstart nvcr.io/nvidia/nemo:22.01 -- /riva_quickstart/nemo_conversion.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08089dd2-d3c4-4253-a4e6-b320677a6548",
   "metadata": {},
   "source": [
    "### Making service\n",
    "\n",
    "The ServiceMaker container is responsible for preparing models for deployment.\n",
    "\n",
    "#### Build and deploy an offline ASR pipeline\n",
    "The ASR pipeline including the acoustic model, language model and inverse text normalization model is built as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be509c5c-eb9d-4d45-915e-c61421ee98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --gpus all --rm \\\n",
    "     -v $RIVA_MODEL_DIR:/servicemaker-dev \\\n",
    "     -v $RIVA_REPO_DIR:/data \\\n",
    "     nvcr.io/nvidia/riva/riva-speech:$RIVA_VERSION-servicemaker \\\n",
    "     -- \\\n",
    "     riva-build speech_recognition -f \\\n",
    "     /servicemaker-dev/citrinet-1024-de-DE-asr-offline.rmir /servicemaker-dev/stt_de_citrinet_1024_v1.5.0/stt_de_citrinet_1024.riva \\\n",
    "     --offline \\\n",
    "     --name=citrinet-1024-de-DE-asr-offline \\\n",
    "     --ms_per_timestep=80 \\\n",
    "     --featurizer.use_utterance_norm_params=False \\\n",
    "     --featurizer.precalc_norm_time_steps=0 \\\n",
    "     --featurizer.precalc_norm_params=False \\\n",
    "     --chunk_size=900 \\\n",
    "     --left_padding_size=0. \\\n",
    "     --right_padding_size=0. \\\n",
    "     --decoder_type=flashlight \\\n",
    "     --decoding_language_model_binary=/servicemaker-dev/speechtotext_de_de_lm_vdeployable_v2.0/riva_de_asr_set_2.0_4gram.binary \\\n",
    "     --decoding_vocab=/servicemaker-dev/speechtotext_de_de_lm_vdeployable_v2.0/dict_vocab.txt \\\n",
    "     --flashlight_decoder.lm_weight=0.2 \\\n",
    "     --flashlight_decoder.word_insertion_score=0.2 \\\n",
    "     --flashlight_decoder.beam_threshold=20. \\\n",
    "     --wfst_tokenizer_model=/servicemaker-dev/inverse_normalization_de_de_vdeployable_v1.0/tokenize_and_classify.far \\\n",
    "     --wfst_verbalizer_model=/servicemaker-dev/inverse_normalization_de_de_vdeployable_v1.0/verbalize.far \\\n",
    "     --language_code=de-DE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aadb476-9573-4b00-a884-34f8ce4b1f2e",
   "metadata": {},
   "source": [
    "The `riva-build` command takes in an acoustic model in `.riva` format, the inverse text normalization models in `.far` format, and a n-gram binary language model file.\n",
    "\n",
    "Note: See Riva documentation for build commands for streaming ASR service.\n",
    "\n",
    "\n",
    "Once the built process succeeded, we can deploy the ASR pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ea2e8-8645-4a8b-882a-d416bdc2da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --gpus all --rm \\\n",
    "     -v $RIVA_MODEL_DIR:/servicemaker-dev \\\n",
    "     -v $RIVA_REPO_DIR:/data \\\n",
    "     nvcr.io/nvidia/riva/riva-speech:$RIVA_VERSION-servicemaker \\\n",
    "     -- \\\n",
    "     riva-deploy -f /servicemaker-dev/citrinet-1024-de-DE-asr-offline.rmir /data/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbcf4d3-17ba-4d29-9194-1607ba5ce218",
   "metadata": {},
   "source": [
    "### Build and deploy and punctuation and capitalization model\n",
    "\n",
    "When doing ASR, the Riva server will look for a punctuator model that matches the language in the ASR request config.\n",
    "The punctuator model can be built and deployed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4812f5e-47fa-4d1f-ad39-d6e555e35a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --gpus all --rm \\\n",
    "     -v $RIVA_MODEL_DIR:/servicemaker-dev \\\n",
    "     -v $RIVA_REPO_DIR:/data \\\n",
    "     nvcr.io/nvidia/riva/riva-speech:$RIVA_VERSION-servicemaker \\\n",
    "     -- \\\n",
    "     riva-build punctuation -f \\\n",
    "     /servicemaker-dev/de_punctuation_1_0.rmir  \\\n",
    "     /servicemaker-dev/punctuationcapitalization_de_de_bert_base_vdeployable_v1.0/de_punctuation_1_0.riva --language_code=de-DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6edc593-240b-465a-87af-be2ccd180290",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --gpus all --rm \\\n",
    "     -v $RIVA_MODEL_DIR:/servicemaker-dev \\\n",
    "     -v $RIVA_REPO_DIR:/data \\\n",
    "     nvcr.io/nvidia/riva/riva-speech:$RIVA_VERSION-servicemaker \\\n",
    "     -- \\\n",
    "     riva-deploy -f /servicemaker-dev/de_punctuation_1_0.rmir /data/models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70abeb-08b0-4ae0-a06c-19f4de21388b",
   "metadata": {},
   "source": [
    "## Start Riva server\n",
    "\n",
    "That concludes the building and deployment of the Riva German ASR service. Now you can start the Riva server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb83ec7-2ee5-4097-8594-f26a61d6bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash $RIVA_QUICKSTART_DIR/riva_start.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f53737-11db-4a42-8076-d72ab37821e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
