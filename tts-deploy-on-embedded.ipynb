{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa47ff5",
   "metadata": {},
   "source": [
    "# TTS Deploy on embedded\n",
    "\n",
    "In this tutorial we will explain the process of generating TTS RMIR from acoustic_model.riva and vocoder.riva files for embedded machines. RMIR (Riva Model Intermediate Representation) is an intermediate file that has all the necessary artifacts (models, files, configurations, and user settings) required to deploy a Riva service.  \n",
    "\n",
    "In this tutorial we will use pretrained [Fastpitch.riva](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/speechsynthesis_en_us_fastpitch_ipa) and [HifiGan.riva](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/speechsynthesis_en_us_hifigan_ipa). These can be replaced with any custom acoutic_model or vocoder riva files. [`nemo2riva`](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/model-overview.html#export-models-with-nemo2riva) can be used to generate .riva files from nemo checkpoints.  \n",
    "\n",
    "The RMIR generated in this tutorial can be deployed using [riva_quickstart](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/quick-start-guide.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e5a5e4",
   "metadata": {},
   "source": [
    "import pathlib to get the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34284f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670aea87",
   "metadata": {},
   "source": [
    "### Download models\n",
    "We will download pretrained [Fastpitch](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/speechsynthesis_en_us_fastpitch_ipa) and [HifiGan](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/speechsynthesis_en_us_hifigan_ipa) models from ngc. You can replace these models with the paths of your custom model, incase of custom models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngc registry model download-version \"nvidia/tao/speechsynthesis_en_us_fastpitch_ipa:deployable_v1.0\"\n",
    "!ngc registry model download-version \"nvidia/tao/speechsynthesis_en_us_hifigan_ipa:deployable_v1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f949e",
   "metadata": {},
   "source": [
    "Download the riva model repository files from ngc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b93e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngc registry model download-version \"nvidia/tao/speechsynthesis_en_us_auxiliary_files:deployable_v1.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d3303d",
   "metadata": {},
   "source": [
    "### Set configs and params.\n",
    "Set following config parameters:  \n",
    "`acoustic_model`: Full path for acoustic_model.riva file from [ngc](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/speechsynthesis_en_us_fastpitch_ipa)  \n",
    "`vocoder`: Full path for vocoder.riva file file from [ngc](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/speechsynthesis_en_us_hifigan_ipa)  \n",
    "`out_dir`: Directory to put TTS.rmir file. The RMIR will be placed in ${out_dir}/RMIR/RMIR_NAME.rmir  \n",
    "`voice`: Set the voice name of the model.  \n",
    "`key`: This is the encryption key used in nemo2riva. Same key will be used to deploy the RMIR generated in this tutorial.  \n",
    "`use_ipa`: Set to \"y\" or \"Y\" if the model uses IPA phones, \"no\" if the model uses arpabet.  \n",
    "`lang`: Model language.  \n",
    "`sample_rate`: Sample rate of generated audios.  \n",
    "`machine_type`: type of machine the tutorial is being run on. Acceptable values are `arm` and `amd`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b6420",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_model = pathlib.Path.cwd() / \"speechsynthesis_en_us_fastpitch_ipa_vdeployable_v1.0/FastPitch_44k_EnglishUS_IPA.riva\" ##acoustic_model .riva location\n",
    "vocoder = pathlib.Path.cwd() / \"speechsynthesis_en_us_hifigan_ipa_vdeployable_v1.0/HifiGAN_44k_EnglishUS_IPA.riva\" ##vocoder .riva location\n",
    "out_dir = pathlib.Path(\"out/\") ##Output directory to store generated RMIR. The RMIR will be placed in ${out_dir}/RMIR/RMIR_NAME.rmir\n",
    "voice = \"test\" ##Voice name     \n",
    "key = \"tlt_encode\" ##Encryption key used during nemo2riva\n",
    "use_ipa = \"no\" ##\"y\" or \"Y\" if the model uses ipa, no otherwise.\n",
    "lang = \"en-US\" ##Language\n",
    "sample_rate = 44100 ##Sample rate of the audios\n",
    "machine_type=\"amd\" #Change this to amd incase of an x86_64 machine.\n",
    "riva_model_files=pathlib.Path.cwd() / \"speechsynthesis_en_us_auxiliary_files_vdeployable_v1.3\" ##Riva model repo path. incase of custom model repo, change this to the full path of the custom riva model repo.\n",
    "\n",
    "rmir_dir = out_dir / \"rmir\"\n",
    "\n",
    "## Riva NGC, servicemaker image config.\n",
    "riva_ngc_org = \"nvidia\"\n",
    "riva_ngc_team = \"riva\"\n",
    "NGC_TARGET = f\"{riva_ngc_org}/{riva_ngc_team}\"\n",
    "riva_ngc_image_version = \"2.8.0\"\n",
    "if machine_type==\"arm\":\n",
    "    riva_init_image = f\"nvcr.io/{NGC_TARGET}/riva-speech:{riva_ngc_image_version}-servicemaker-l4t-aarch64\"\n",
    "elif machine_type==\"amd\":\n",
    "    riva_init_image = f\"nvcr.io/{NGC_TARGET}/riva-speech:{riva_ngc_image_version}-servicemaker\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f30b159",
   "metadata": {},
   "source": [
    "Get acoustic_model, vocoder directory path and model names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b11ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "synt_dir = acoustic_model.parent\n",
    "voc_dir = vocoder.parent\n",
    "\n",
    "synt_name = acoustic_model.name\n",
    "voc_name = vocoder.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20acd79d",
   "metadata": {},
   "source": [
    "Create output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d93014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not out_dir.exists():\n",
    "    out_dir.mkdir()\n",
    "if not rmir_dir.exists():\n",
    "    rmir_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab4ef3",
   "metadata": {},
   "source": [
    "Stop already running docker file and run riva_servicemaker and run again with acoustic_model and vocoder paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Run the riva servicemaker.\n",
    "!docker stop riva_rmir_gen &> /dev/null\n",
    "!set -x && docker run -td --gpus all --rm -v {str(riva_model_files)}:/riva_repo -v {str(synt_dir)}/:/synt -v {str(voc_dir)}:/voc \\\n",
    "            -v {str(rmir_dir.resolve())}:/data --name riva_rmir_gen --entrypoint=\"/bin/bash\" {riva_init_image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "riva_build=f\"\"\"riva-build speech_synthesis  --voice_name={voice}  --language_code={lang} \\\n",
    "                --sample_rate={sample_rate} /data/FastPitch_HifiGan.rmir:{key} /synt/{synt_name}:{key} \\\n",
    "                /voc/{voc_name}:{key} --max_batch_size 1 --denoiser.max_batch_size 1 --preprocessor.max_batch_size 1 \\\n",
    "                --encoderFastPitch.max_batch_size 1 --chunkerFastPitch.max_batch_size 1 --hifigan.max_batch_size 1 \\\n",
    "                --abbreviations_file=/riva_repo/abbr.txt\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a992d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_ipa == \"Y\" or use_ipa==\"y\":\n",
    "    riva_build+=\" --phone_set=ipa --arpabet_file=/riva_repo/ipa_cmudict-0.7b_nv22.08.txt\"\n",
    "else:\n",
    "    riva_build+=\" --arpabet_file=/riva_repo/cmudict-0.7b_nv22.08\"\n",
    "print(riva_build)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7988d2",
   "metadata": {},
   "source": [
    "Execute the riva build command and stop the riva_servicemaker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d0658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec  riva_rmir_gen {riva_build}\n",
    "!docker stop riva_rmir_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e170f",
   "metadata": {},
   "source": [
    "## Conclusion.\n",
    "\n",
    "In this tutorial, we learned how to generate RMIR files from .riva files. We would see that a `FastPitch_HifiGan.rmir` has been generated in the `${out_dir}/rmir` location we defined earlier.  \n",
    "\n",
    "The RMIR file generated in this tutorial can be deployed using [riva_quickstart](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/quick-start-guide.html).\n",
    "\n",
    "## Steps to deploy the RMIR\n",
    "- Download the riva_quickstart\n",
    "- Open `config.sh` and update the following params:  \n",
    "    - set `service_enabled_asr` to `false`.  \n",
    "    - set `service_enabled_nlp` to `false`.  \n",
    "    - set `service_enabled_tts` to `true`.  \n",
    "    - `riva_model_loc` to the location of your `out_dir`.  \n",
    "    - set `use_existing_rmirs` to `true`.  \n",
    "- run `riva_init.sh`.  \n",
    "- run `riva_start.sh`.  \n",
    "\n",
    "The RMIR should be deployed after these steps.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_speech_ml0.6",
   "language": "python",
   "name": "py38_speech_ml0.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
