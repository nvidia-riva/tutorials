{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NpvEOMs_mKp"
   },
   "source": [
    "<img src=\"http://developer.download.nvidia.com/notebooks/dlsw-notebooks/rivaasrasr-finetuning-conformer-ctc-nemo/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Training and Deploying N-GPU Language Models for Parakeet RNNT with NVIDIA NIM\n",
    "\n",
    "This comprehensive tutorial demonstrates how to train and deploy an NVIDIA N-GPU Language Model (LM) for Parakeet RNNT acoustic models using NVIDIA NeMo and deploy them as NVIDIA NIM (NVIDIA Inference Microservices). You'll learn the complete pipeline from data preparation to model deployment and inference.\n",
    "\n",
    "## What You'll Learn\n",
    "- How to train n-gram language models using NeMo and KenLM\n",
    "- How to integrate language models with Parakeet RNNT acoustic models\n",
    "- How to deploy custom models using NVIDIA Riva NIM\n",
    "- How to perform inference with your deployed models\n",
    "\n",
    "## Prerequisites\n",
    "- Basic understanding of automatic speech recognition (ASR)\n",
    "- Familiarity with Python and Jupyter notebooks\n",
    "- Access to NVIDIA NGC and GPU resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6h7SXF6G_mKw"
   },
   "source": [
    "## NVIDIA Riva NIM Overview\n",
    "\n",
    "NVIDIA Riva ASR NIM APIs provide easy access to state-of-the-art automatic speech recognition (ASR) models for multiple languages. Riva ASR NIM models are built on the NVIDIA software platform, incorporating CUDA, TensorRT, and Triton to offer out-of-the-box GPU acceleration.\n",
    "\n",
    "In this tutorial, we will interact with the automated speech recognition (ASR) APIs.\n",
    "\n",
    "For more information about Riva ASR NIM, refer to the [Riva NIM documentation](https://docs.nvidia.com/nim/riva/asr/latest/overview.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rv47EmBp_mK2"
   },
   "source": [
    "## NeMo (Neural Modules)\n",
    "[NVIDIA NeMo](https://developer.nvidia.com/nvidia-nemo) is an open-source framework for building, training, and fine-tuning GPU-accelerated speech AI and NLU models with a simple Python interface. For information about how to set up NeMo, refer to the [NeMo GitHub](https://github.com/NVIDIA/NeMo) instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-gram Language Model\n",
    "There are primarily two types of language models:\n",
    "\n",
    "- **n-gram language models**: These models use the frequency of n-grams to learn the probability distribution over words. Two benefits of n-gram language models are simplicity and scalability – with a larger `n`, a model can store more context with a well-understood space–time tradeoff, enabling small experiments to scale up efficiently.\n",
    "- **Neural language models**: These models use different kinds of neural networks to model the probability distribution over words, and have surpassed the n-gram language models in the ability to model language, but are generally slower to evaluate.\n",
    "\n",
    "In this tutorial, we will show how to train an [n-gram language model](https://web.stanford.edu/~jurafsky/slp3/3.pdf) leveraging NeMo and deploy as NGPU LM in NVIDIA ASR NIM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1O2bGCMAQDs8"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You can run either this tutorial locally (if you have all the dependencies and a GPU) or on Google Colab.\n",
    "\n",
    "Perform the following steps to setup in Google Colab:\n",
    "1. Open a new Python 3 notebook.\n",
    "2. Import this notebook from GitHub.\n",
    "   a. Click **File** > **Upload Notebook** > **GITHUB** tab > copy/paste the GitHub URL.\n",
    "3. Connect to an instance with a GPU.\n",
    "   a. Click **Runtime** > Change the runtime type > select **GPU** for the hardware accelerator.\n",
    "4. Run this cell to set up the dependencies.\n",
    "5. Restart the runtime.\n",
    "   a. Click **Runtime** > **Restart Runtime** for any upgraded packages to take effect.\n",
    "\"\"\"\n",
    "\n",
    "# Install Dependencies\n",
    "!pip install wget\n",
    "!apt-get install sox libsndfile1 ffmpeg libsox-fmt-mp3 jq\n",
    "!pip install text-unidecode\n",
    "!pip install matplotlib>=3.3.2\n",
    "!pip install Cython\n",
    "\n",
    "## Install NeMo\n",
    "BRANCH = 'v2.4.0'\n",
    "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n",
    "\n",
    "\"\"\"\n",
    "Remember to restart the runtime for the kernel to pick up any upgraded packages (e.g. matplotlib)!\n",
    "Alternatively, in the case where you want to use the \"Run All Cells\" (or similar) option,\n",
    "uncomment `exit()` below to crash and restart the kernel.\n",
    "\"\"\"\n",
    "# exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "Ensure you meet the following prerequisites.\n",
    "1. You have access and are logged into NVIDIA NGC. For step-by-step instructions, refer to the [NGC Getting Started Guide](https://docs.nvidia.com/ngc/ngc-overview/index.html#registering-activating-ngc-account).\n",
    "2. You have installed Kaggle API. For step-by-step instructions, refer to this [install and authenticate Kaggle API](https://www.kaggle.com/docs/api)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vo27Unex_mLG"
   },
   "source": [
    "---\n",
    "## Training an ngram model with NeMo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step clones the NeMo repository and installs the required dependencies, including KenLM, which is used for building language models. The installation process may take several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "NEMO_ROOT = \"NeMo\" # Path to clone the NeMo repository.\n",
    "NEMO_ROOT = \"/media/mayjain/Seagate/mayjain/work/del_this/NeMo\"\n",
    "os.environ[\"NEMO_ROOT\"] = NEMO_ROOT\n",
    "!git clone -b $BRANCH --single-branch https://github.com/NVIDIA/NeMo.git $NEMO_ROOT\n",
    "!cd $NEMO_ROOT/scripts/asr_language_modeling/ngram_lm/ && bash install_beamsearch_decoders.sh $NEMO_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfRpENJJ_mLy"
   },
   "source": [
    "### Preparing the Dataset\n",
    "#### LibriSpeech LM Normalized Dataset\n",
    "For this tutorial, we use the normalized version of the LibriSpeech LM dataset to train our n-gram language model. The normalized version of the LibriSpeech LM dataset is available [here](https://www.openslr.org/11/).<br>\n",
    "The training data is publicly available [here](https://www.openslr.org/resources/11/librispeech-lm-corpus.tgz) and can be downloaded directly.\n",
    "#### Downloading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKrmQQuK_mLz"
   },
   "source": [
    "In this tutorial, we will use the popular Librispeech dataset. Let's download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0eFF0r7z_mLz"
   },
   "outputs": [],
   "source": [
    "# Set the path to a folder where you want your data and results to be saved.\n",
    "DATA_DOWNLOAD_DIR=\"content/datasets\"\n",
    "MODELS_DIR=\"content/models\"\n",
    "\n",
    "DATA_DOWNLOAD_DIR = \"/media/mayjain/Seagate/mayjain/work/del_this/datasets\"\n",
    "MODELS_DIR = \"/media/mayjain/Seagate/mayjain/work/del_this/models\"\n",
    "\n",
    "os.environ[\"DATA_DOWNLOAD_DIR\"] = DATA_DOWNLOAD_DIR\n",
    "os.environ[\"MODELS_DIR\"] = MODELS_DIR\n",
    "\n",
    "!mkdir -p $DATA_DOWNLOAD_DIR $MODELS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAsvlh53_mL0"
   },
   "source": [
    "After downloading, untar the dataset and move it to the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OipV7YVq_mL1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-09-19 03:31:54--  https://www.openslr.org/resources/11/librispeech-lm-norm.txt.gz\n",
      "Resolving www.openslr.org (www.openslr.org)... 136.243.171.4\n",
      "connected. to www.openslr.org (www.openslr.org)|136.243.171.4|:443... \n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1507274412 (1.4G) [application/x-gzip]\n",
      "Saving to: ‘/media/mayjain/Seagate/mayjain/work/del_this/datasets/librispeech-lm-norm.txt.gz’\n",
      "\n",
      "librispeech-lm-norm 100%[===================>]   1.40G  13.8MB/s    in 99s     \n",
      "\n",
      "2025-09-19 03:33:35 (14.5 MB/s) - ‘/media/mayjain/Seagate/mayjain/work/del_this/datasets/librispeech-lm-norm.txt.gz’ saved [1507274412/1507274412]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note: Ensure that wget and unzip utilities are available. If not, install them.\n",
    "!wget 'https://www.openslr.org/resources/11/librispeech-lm-norm.txt.gz' -P $DATA_DOWNLOAD_DIR\n",
    "\n",
    "# Extract the data\n",
    "!gzip -dk $DATA_DOWNLOAD_DIR/librispeech-lm-norm.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of reducing the time this tutorial takes, we reduced the number of lines of the training dataset. Feel free to modify the number of used lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a random 100,000 lines for training\n",
    "!shuf -n 100000 $DATA_DOWNLOAD_DIR/librispeech-lm-norm.txt | tr '[:upper:]' '[:lower:]' > $DATA_DOWNLOAD_DIR/reduced_training.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Tilg2Eg_mL2"
   },
   "source": [
    "The N-GPU LMs for Parakeet RNNT models are token based. So we need access to ASR's tokenizer model to tokenize the training data. Lets download the RNNT model we want to deploy the N-GPU LM with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-09-19 03:37:11--  https://huggingface.co/nvidia/parakeet-rnnt-1.1b/resolve/main/parakeet-rnnt-1.1b.nemo\n",
      "Resolving huggingface.co (huggingface.co)... 108.158.251.34, 108.158.251.67, 108.158.251.89, ...\n",
      "Connecting to huggingface.co (huggingface.co)|108.158.251.34|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/658cb5dd8cff48d3a45472a7/a67a354491ca2c944dc2ac6d4c8710ed9f38b6051acd9740305a3e0ba4d468ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250919%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250919T033711Z&X-Amz-Expires=3600&X-Amz-Signature=5fc2e9678ba8a2bb3eb0429dbe9097b34cf0dc623b74eb61f3b25968a20d8237&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27parakeet-rnnt-1.1b.nemo%3B+filename%3D%22parakeet-rnnt-1.1b.nemo%22%3B&x-id=GetObject&Expires=1758256631&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1ODI1NjYzMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NThjYjVkZDhjZmY0OGQzYTQ1NDcyYTcvYTY3YTM1NDQ5MWNhMmM5NDRkYzJhYzZkNGM4NzEwZWQ5ZjM4YjYwNTFhY2Q5NzQwMzA1YTNlMGJhNGQ0NjhjZSoifV19&Signature=Rwb8bpsxPU2hR0P72%7EqjHKtEdRTwzxJUZte8mHUaP2DKd8pSDwL13KlKtKb3GtTegeuDJ5rulxrvklawg2iaIpKV3Qz5pCZbutI-wgXMZkiIGYnkT%7E5ZYjHlBiDd%7E6zQ8B8yhd3GZh9qW%7E730c-O6LS%7E3j2NdIpaE4A1kV810L6dsusY1WRovaKeZ6KHcHiywfSKJDmLbj9qK5pSmKGXOWFlG1VIvZ2xyIj-NgT%7EbDIi4ZVXaYliYVEC1LTJ29medeQDt-IH98GotVSOf0BtRHTYes8qm7Gq1ehu3IaAnjciHSLjcgbEk8Vdo62EJnmCMgKUi3rEgvNd16s9mhj1hw__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
      "--2025-09-19 03:37:12--  https://cas-bridge.xethub.hf.co/xet-bridge-us/658cb5dd8cff48d3a45472a7/a67a354491ca2c944dc2ac6d4c8710ed9f38b6051acd9740305a3e0ba4d468ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250919%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250919T033711Z&X-Amz-Expires=3600&X-Amz-Signature=5fc2e9678ba8a2bb3eb0429dbe9097b34cf0dc623b74eb61f3b25968a20d8237&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27parakeet-rnnt-1.1b.nemo%3B+filename%3D%22parakeet-rnnt-1.1b.nemo%22%3B&x-id=GetObject&Expires=1758256631&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1ODI1NjYzMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NThjYjVkZDhjZmY0OGQzYTQ1NDcyYTcvYTY3YTM1NDQ5MWNhMmM5NDRkYzJhYzZkNGM4NzEwZWQ5ZjM4YjYwNTFhY2Q5NzQwMzA1YTNlMGJhNGQ0NjhjZSoifV19&Signature=Rwb8bpsxPU2hR0P72%7EqjHKtEdRTwzxJUZte8mHUaP2DKd8pSDwL13KlKtKb3GtTegeuDJ5rulxrvklawg2iaIpKV3Qz5pCZbutI-wgXMZkiIGYnkT%7E5ZYjHlBiDd%7E6zQ8B8yhd3GZh9qW%7E730c-O6LS%7E3j2NdIpaE4A1kV810L6dsusY1WRovaKeZ6KHcHiywfSKJDmLbj9qK5pSmKGXOWFlG1VIvZ2xyIj-NgT%7EbDIi4ZVXaYliYVEC1LTJ29medeQDt-IH98GotVSOf0BtRHTYes8qm7Gq1ehu3IaAnjciHSLjcgbEk8Vdo62EJnmCMgKUi3rEgvNd16s9mhj1hw__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
      "13.227.249.95, 13.227.249.91, 13.227.249.11, ...thub.hf.co)... \n",
      "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|13.227.249.95|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 4283105280 (4.0G)\n",
      "Saving to: ‘/media/mayjain/Seagate/mayjain/work/del_this/models/parakeet-rnnt-1.1b.nemo’\n",
      "\n",
      "parakeet-rnnt-1.1b. 100%[===================>]   3.99G  19.8MB/s    in 3m 49s  \n",
      "\n",
      "2025-09-19 03:41:02 (17.8 MB/s) - ‘/media/mayjain/Seagate/mayjain/work/del_this/models/parakeet-rnnt-1.1b.nemo’ saved [4283105280/4283105280]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P $MODELS_DIR https://huggingface.co/nvidia/parakeet-rnnt-1.1b/resolve/main/parakeet-rnnt-1.1b.nemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKud8fQ8_mL3"
   },
   "source": [
    "Now we have all the required artifacts. Lets train the N-GPU LM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "54Pff6vr_mL3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-09-19 04:32:00 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "['/media/mayjain/Seagate/mayjain/work/del_this/datasets/reduced_training.txt'] ['/media/mayjain/Seagate/mayjain/work/del_this/datasets/reduced_training.txt']\n",
      "/media/mayjain/Seagate/mayjain/work/del_this/NeMo/decoders/kenlm/build/bin\n",
      "[NeMo I 2025-09-19 04:32:02 nemo_logging:393] Loading nemo model '/media/mayjain/Seagate/mayjain/work/del_this/models/parakeet-rnnt-1.1b.nemo' ...\n",
      "[NeMo I 2025-09-19 04:33:57 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo W 2025-09-19 04:33:57 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-train-all.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-09-19 04:33:57 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-dev-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2025-09-19 04:33:57 nemo_logging:405] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo I 2025-09-19 04:33:57 nemo_logging:393] PADDING: 0\n",
      "[NeMo I 2025-09-19 04:34:02 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-09-19 04:34:02 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-09-19 04:34:02 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-09-19 04:34:04 nemo_logging:393] Model EncDecRNNTBPEModel was successfully restored from /media/mayjain/Seagate/mayjain/work/del_this/models/parakeet-rnnt-1.1b.nemo.\n",
      "[NeMo I 2025-09-19 04:34:04 nemo_logging:393] Running lmplz command \n",
      "    \n",
      "    /media/mayjain/Seagate/mayjain/work/del_this/NeMo/decoders/kenlm/build/bin/lmplz -o 6 --arpa /media/mayjain/Seagate/mayjain/work/del_this/models/ngpu_6g.tmp.arpa --discount_fallback --prune 0\n",
      "    \n",
      "    \n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "File stdin isn't normal.  Using slower read() instead of mmap().  No progress bar.\n",
      "Read 100000 lines: : 100000 lines [00:00, 253881.28 lines/s]\n",
      "[NeMo W 2025-09-19 04:34:18 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-09-19 04:34:19 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-09-19 04:34:19 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-09-19 04:34:22 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-09-19 04:34:22 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-09-19 04:34:22 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-09-19 04:34:22 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-09-19 04:34:22 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-09-19 04:34:22 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-09-19 04:34:22 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-09-19 04:34:23 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-09-19 04:34:23 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2025-09-19 04:34:24 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo I 2025-09-19 04:35:01 nemo_logging:393] Finished writing 13 chunks to <_io.BufferedWriter name=28>. Current chunk index = 13\n",
      "Unigram tokens 3471053 types 1022\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:12264 2:1654056320 3:3101355520 4:4962168832 5:7236496896 6:9924337664\n",
      "Statistics:\n",
      "1 1022 D1=0.333333 D2=1.5 D3+=1.66667\n",
      "2 192824 D1=0.549039 D2=1.10312 D3+=1.60927\n",
      "3 1250555 D1=0.756435 D2=1.17545 D3+=1.47104\n",
      "4 2316892 D1=0.876703 D2=1.22552 D3+=1.41755\n",
      "5 2848161 D1=0.938824 D2=1.28695 D3+=1.44852\n",
      "6 3021801 D1=0.962557 D2=1.37968 D3+=1.51437\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 203 assuming -p 1.5\n",
      "probing 240 assuming -r models -p 1.5\n",
      "trie     89 without quantization\n",
      "trie     44 assuming -q 8 -b 8 quantization \n",
      "trie     78 assuming -a 22 array pointer compression\n",
      "trie     32 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:12264 2:3085184 3:25011100 4:55605408 5:79748508 6:96697632\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:12264 2:3085184 3:25011100 4:55605408 5:79748508 6:96697632\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:26436984 kB\tVmRSS:32632 kB\tRSSMax:9669040 kB\tuser:5.4922\tsys:4.2061\tCPU:9.69831\treal:60.8358\n",
      "[NeMo I 2025-09-19 04:35:05 nemo_logging:393] Running binary_build command \n",
      "    \n",
      "    /media/mayjain/Seagate/mayjain/work/del_this/NeMo/decoders/kenlm/build/bin/build_binary trie /media/mayjain/Seagate/mayjain/work/del_this/models/ngpu_6g.tmp.arpa /media/mayjain/Seagate/mayjain/work/del_this/models/ngpu_6g\n",
      "    \n",
      "    \n",
      "Reading /media/mayjain/Seagate/mayjain/work/del_this/models/ngpu_6g.tmp.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "********************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "*********************************************************************************************\n",
      "SUCCESS\n",
      "[NeMo I 2025-09-19 04:35:21 nemo_logging:393] NGramGPULanguageModel: reading LM from /media/mayjain/Seagate/mayjain/work/del_this/models/ngpu_6g.tmp.arpa\n",
      "[NeMo I 2025-09-19 04:35:22 nemo_logging:393] Processed 1022 n-grams of order 1]\n",
      "  2%|▌                             | 193248/9631255 [00:01<00:52, 179487.20it/s]\n",
      "  0%|                                                | 0/192824 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▍                                | 8357/192824 [00:00<00:02, 83567.29it/s]\u001b[A\n",
      " 10%|███▎                             | 19408/192824 [00:00<00:01, 99410.77it/s]\u001b[A\n",
      " 16%|█████                           | 30418/192824 [00:00<00:01, 104290.10it/s]\u001b[A\n",
      " 22%|██████▉                         | 41654/192824 [00:00<00:01, 107472.72it/s]\u001b[A\n",
      " 27%|████████▊                       | 52855/192824 [00:00<00:01, 109108.21it/s]\u001b[A\n",
      " 33%|██████████▋                     | 64101/192824 [00:00<00:01, 110245.68it/s]\u001b[A\n",
      " 39%|████████████▌                   | 75443/192824 [00:00<00:01, 111281.88it/s]\u001b[A\n",
      " 45%|██████████████▎                 | 86614/192824 [00:00<00:00, 111415.41it/s]\u001b[A\n",
      " 51%|████████████████▏               | 97756/192824 [00:00<00:00, 111044.86it/s]\u001b[A\n",
      " 56%|█████████████████▌             | 108861/192824 [00:01<00:00, 111016.15it/s]\u001b[A\n",
      " 62%|███████████████████▎           | 120087/192824 [00:01<00:00, 111394.72it/s]\u001b[A\n",
      " 68%|█████████████████████          | 131230/192824 [00:01<00:00, 111404.90it/s]\u001b[A\n",
      " 74%|██████████████████████▉        | 142371/192824 [00:01<00:00, 111403.42it/s]\u001b[A\n",
      " 80%|████████████████████████▋      | 153512/192824 [00:01<00:00, 111241.88it/s]\u001b[A\n",
      " 85%|██████████████████████████▍    | 164638/192824 [00:01<00:00, 111244.81it/s]\u001b[A\n",
      " 91%|████████████████████████████▎  | 175763/192824 [00:01<00:00, 110358.81it/s]\u001b[A\n",
      "100%|███████████████████████████████| 192824/192824 [00:01<00:00, 109687.83it/s]\u001b[A\n",
      "[NeMo I 2025-09-19 04:35:25 nemo_logging:393] Processed 192824 n-grams of order 2\n",
      " 15%|████▎                        | 1430306/9631255 [00:10<00:48, 169573.18it/s]\n",
      "  0%|                                               | 0/1250555 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▎                              | 11896/1250555 [00:00<00:10, 118958.41it/s]\u001b[A\n",
      "  2%|▌                              | 23792/1250555 [00:00<00:10, 118703.21it/s]\u001b[A\n",
      "  3%|▉                              | 35852/1250555 [00:00<00:10, 119565.89it/s]\u001b[A\n",
      "  4%|█▏                             | 47809/1250555 [00:00<00:10, 119114.04it/s]\u001b[A\n",
      "  5%|█▍                             | 59917/1250555 [00:00<00:09, 119820.04it/s]\u001b[A\n",
      "  6%|█▊                             | 72070/1250555 [00:00<00:09, 120398.31it/s]\u001b[A\n",
      "  7%|██                             | 84218/1250555 [00:00<00:09, 120750.30it/s]\u001b[A\n",
      "  8%|██▍                            | 96294/1250555 [00:00<00:09, 120653.60it/s]\u001b[A\n",
      "  9%|██▌                           | 108408/1250555 [00:00<00:09, 120804.79it/s]\u001b[A\n",
      " 10%|██▉                           | 120489/1250555 [00:01<00:09, 120537.03it/s]\u001b[A\n",
      " 11%|███▏                          | 132618/1250555 [00:01<00:09, 120763.51it/s]\u001b[A\n",
      " 12%|███▍                          | 144695/1250555 [00:01<00:09, 120660.04it/s]\u001b[A\n",
      " 13%|███▊                          | 156762/1250555 [00:01<00:09, 120461.40it/s]\u001b[A\n",
      " 13%|████                          | 168811/1250555 [00:01<00:08, 120466.59it/s]\u001b[A\n",
      " 14%|████▎                         | 180858/1250555 [00:01<00:08, 119466.92it/s]\u001b[A\n",
      " 15%|████▋                         | 192907/1250555 [00:01<00:08, 119770.36it/s]\u001b[A\n",
      " 16%|████▉                         | 204939/1250555 [00:01<00:08, 119932.30it/s]\u001b[A\n",
      " 17%|█████▏                        | 216934/1250555 [00:01<00:08, 119589.19it/s]\u001b[A\n",
      " 18%|█████▍                        | 228972/1250555 [00:01<00:08, 119824.49it/s]\u001b[A\n",
      " 19%|█████▊                        | 240982/1250555 [00:02<00:08, 119905.87it/s]\u001b[A\n",
      " 20%|██████                        | 253079/1250555 [00:02<00:08, 120221.96it/s]\u001b[A\n",
      " 21%|██████▎                       | 265102/1250555 [00:02<00:08, 120035.05it/s]\u001b[A\n",
      " 22%|██████▋                       | 277272/1250555 [00:02<00:08, 120532.24it/s]\u001b[A\n",
      " 23%|██████▉                       | 289328/1250555 [00:02<00:07, 120539.39it/s]\u001b[A\n",
      " 24%|███████▏                      | 301383/1250555 [00:02<00:07, 120421.01it/s]\u001b[A\n",
      " 25%|███████▌                      | 313488/1250555 [00:02<00:07, 120607.50it/s]\u001b[A\n",
      " 26%|███████▊                      | 325565/1250555 [00:02<00:07, 120654.17it/s]\u001b[A\n",
      " 27%|████████                      | 337631/1250555 [00:02<00:07, 120600.44it/s]\u001b[A\n",
      " 28%|████████▍                     | 349692/1250555 [00:02<00:07, 119855.46it/s]\u001b[A\n",
      " 29%|████████▋                     | 361679/1250555 [00:03<00:07, 117623.48it/s]\u001b[A\n",
      " 30%|████████▉                     | 373692/1250555 [00:03<00:07, 118362.11it/s]\u001b[A\n",
      " 31%|█████████▎                    | 385900/1250555 [00:03<00:07, 119462.74it/s]\u001b[A\n",
      " 32%|█████████▌                    | 398012/1250555 [00:03<00:07, 119954.01it/s]\u001b[A\n",
      " 33%|█████████▊                    | 410029/1250555 [00:03<00:07, 120016.08it/s]\u001b[A\n",
      " 34%|██████████                    | 422035/1250555 [00:03<00:06, 119630.32it/s]\u001b[A\n",
      " 35%|██████████▍                   | 434048/1250555 [00:03<00:06, 119776.33it/s]\u001b[A\n",
      " 36%|██████████▋                   | 446115/1250555 [00:03<00:06, 120040.33it/s]\u001b[A\n",
      " 37%|██████████▉                   | 458121/1250555 [00:03<00:06, 119895.79it/s]\u001b[A\n",
      " 38%|███████████▎                  | 470120/1250555 [00:03<00:06, 119923.41it/s]\u001b[A\n",
      " 39%|███████████▌                  | 482231/1250555 [00:04<00:06, 120277.38it/s]\u001b[A\n",
      " 40%|███████████▊                  | 494260/1250555 [00:04<00:06, 120191.74it/s]\u001b[A\n",
      " 40%|████████████▏                 | 506280/1250555 [00:04<00:06, 119813.10it/s]\u001b[A\n",
      " 41%|████████████▍                 | 518371/1250555 [00:04<00:06, 120138.83it/s]\u001b[A\n",
      " 42%|████████████▋                 | 530454/1250555 [00:04<00:05, 120344.20it/s]\u001b[A\n",
      " 43%|█████████████                 | 542489/1250555 [00:04<00:05, 120248.42it/s]\u001b[A\n",
      " 44%|█████████████▎                | 554608/1250555 [00:04<00:05, 120527.44it/s]\u001b[A\n",
      " 45%|█████████████▌                | 566684/1250555 [00:04<00:05, 120593.88it/s]\u001b[A\n",
      " 46%|█████████████▉                | 578744/1250555 [00:04<00:05, 120327.63it/s]\u001b[A\n",
      " 47%|██████████████▏               | 590777/1250555 [00:04<00:05, 120274.47it/s]\u001b[A\n",
      " 48%|██████████████▍               | 602862/1250555 [00:05<00:05, 120444.87it/s]\u001b[A\n",
      " 49%|██████████████▊               | 614934/1250555 [00:05<00:05, 120526.65it/s]\u001b[A\n",
      " 50%|███████████████               | 626987/1250555 [00:05<00:05, 120476.29it/s]\u001b[A\n",
      " 51%|███████████████▎              | 639035/1250555 [00:05<00:05, 120365.79it/s]\u001b[A\n",
      " 52%|███████████████▌              | 651072/1250555 [00:05<00:04, 120357.37it/s]\u001b[A\n",
      " 53%|███████████████▉              | 663108/1250555 [00:05<00:04, 119810.96it/s]\u001b[A\n",
      " 54%|████████████████▏             | 675090/1250555 [00:05<00:04, 119369.90it/s]\u001b[A\n",
      " 55%|████████████████▍             | 687028/1250555 [00:05<00:04, 119155.59it/s]\u001b[A\n",
      " 56%|████████████████▊             | 698944/1250555 [00:05<00:04, 118927.06it/s]\u001b[A\n",
      " 57%|█████████████████             | 710837/1250555 [00:05<00:04, 114184.10it/s]\u001b[A\n",
      " 58%|█████████████████▎            | 722888/1250555 [00:06<00:04, 116020.73it/s]\u001b[A\n",
      " 59%|█████████████████▋            | 734723/1250555 [00:06<00:04, 116701.57it/s]\u001b[A\n",
      " 60%|█████████████████▉            | 746706/1250555 [00:06<00:04, 117622.19it/s]\u001b[A\n",
      " 61%|██████████████████▏           | 758782/1250555 [00:06<00:04, 118550.10it/s]\u001b[A\n",
      " 62%|██████████████████▍           | 770794/1250555 [00:06<00:04, 119015.74it/s]\u001b[A\n",
      " 63%|██████████████████▊           | 782706/1250555 [00:06<00:03, 119019.62it/s]\u001b[A\n",
      " 64%|███████████████████           | 794687/1250555 [00:06<00:03, 119253.95it/s]\u001b[A\n",
      " 65%|███████████████████▎          | 806698/1250555 [00:06<00:03, 119509.39it/s]\u001b[A\n",
      " 65%|███████████████████▋          | 818653/1250555 [00:06<00:03, 119407.87it/s]\u001b[A\n",
      " 66%|███████████████████▉          | 830598/1250555 [00:06<00:03, 119418.65it/s]\u001b[A\n",
      " 67%|████████████████████▏         | 842553/1250555 [00:07<00:03, 119454.79it/s]\u001b[A\n",
      " 68%|████████████████████▍         | 854500/1250555 [00:07<00:03, 119294.70it/s]\u001b[A\n",
      " 69%|████████████████████▊         | 866577/1250555 [00:07<00:03, 119733.33it/s]\u001b[A\n",
      " 70%|█████████████████████         | 878932/1250555 [00:07<00:03, 120876.21it/s]\u001b[A\n",
      " 71%|█████████████████████▍        | 891134/1250555 [00:07<00:02, 121218.57it/s]\u001b[A\n",
      " 72%|█████████████████████▋        | 903449/1250555 [00:07<00:02, 121796.12it/s]\u001b[A\n",
      " 73%|█████████████████████▉        | 915629/1250555 [00:07<00:02, 121737.88it/s]\u001b[A\n",
      " 74%|██████████████████████▎       | 927804/1250555 [00:07<00:02, 121631.04it/s]\u001b[A\n",
      " 75%|██████████████████████▌       | 939968/1250555 [00:07<00:02, 121300.44it/s]\u001b[A\n",
      " 76%|██████████████████████▊       | 952099/1250555 [00:07<00:02, 121136.47it/s]\u001b[A\n",
      " 77%|███████████████████████▏      | 964213/1250555 [00:08<00:02, 120658.31it/s]\u001b[A\n",
      " 78%|███████████████████████▍      | 976280/1250555 [00:08<00:02, 120573.35it/s]\u001b[A\n",
      " 79%|███████████████████████▋      | 988350/1250555 [00:08<00:02, 120610.71it/s]\u001b[A\n",
      " 80%|███████████████████████▏     | 1000480/1250555 [00:08<00:02, 120814.48it/s]\u001b[A\n",
      " 81%|███████████████████████▍     | 1012562/1250555 [00:08<00:01, 120518.65it/s]\u001b[A\n",
      " 82%|███████████████████████▊     | 1024615/1250555 [00:08<00:01, 120221.44it/s]\u001b[A\n",
      " 83%|████████████████████████     | 1036683/1250555 [00:08<00:01, 120355.42it/s]\u001b[A\n",
      " 84%|████████████████████████▎    | 1048804/1250555 [00:08<00:01, 120610.61it/s]\u001b[A\n",
      " 85%|████████████████████████▌    | 1060866/1250555 [00:08<00:01, 120428.62it/s]\u001b[A\n",
      " 86%|████████████████████████▉    | 1072928/1250555 [00:08<00:01, 120482.66it/s]\u001b[A\n",
      " 87%|█████████████████████████▏   | 1085019/1250555 [00:09<00:01, 120607.15it/s]\u001b[A\n",
      " 88%|█████████████████████████▍   | 1097080/1250555 [00:09<00:01, 120589.86it/s]\u001b[A\n",
      " 89%|█████████████████████████▋   | 1109185/1250555 [00:09<00:01, 120724.35it/s]\u001b[A\n",
      " 90%|██████████████████████████   | 1121292/1250555 [00:09<00:01, 120824.99it/s]\u001b[A\n",
      " 91%|██████████████████████████▎  | 1133375/1250555 [00:09<00:00, 120160.78it/s]\u001b[A\n",
      " 92%|██████████████████████████▌  | 1145392/1250555 [00:09<00:00, 119685.77it/s]\u001b[A\n",
      " 93%|██████████████████████████▊  | 1157362/1250555 [00:09<00:00, 119204.55it/s]\u001b[A\n",
      " 94%|███████████████████████████  | 1169284/1250555 [00:09<00:00, 118906.72it/s]\u001b[A\n",
      " 94%|███████████████████████████▍ | 1181176/1250555 [00:09<00:00, 118415.38it/s]\u001b[A\n",
      " 95%|███████████████████████████▋ | 1193026/1250555 [00:09<00:00, 118437.67it/s]\u001b[A\n",
      " 96%|███████████████████████████▉ | 1204871/1250555 [00:10<00:00, 118065.40it/s]\u001b[A\n",
      " 97%|████████████████████████████▏| 1216694/1250555 [00:10<00:00, 118110.82it/s]\u001b[A\n",
      " 98%|████████████████████████████▍| 1228506/1250555 [00:10<00:00, 117765.16it/s]\u001b[A\n",
      "100%|█████████████████████████████| 1250555/1250555 [00:10<00:00, 119774.56it/s]\u001b[A\n",
      "[NeMo I 2025-09-19 04:35:44 nemo_logging:393] Processed 1250555 n-grams of order 3\n",
      " 39%|███████████▎                 | 3755445/9631255 [00:36<00:35, 165787.71it/s]\n",
      "  0%|                                               | 0/2316892 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏                              | 12291/2316892 [00:00<00:18, 122907.48it/s]\u001b[A\n",
      "  1%|▎                              | 24710/2316892 [00:00<00:18, 123657.98it/s]\u001b[A\n",
      "  2%|▍                              | 37248/2316892 [00:00<00:18, 124443.51it/s]\u001b[A\n",
      "  2%|▋                              | 49750/2316892 [00:00<00:18, 124666.92it/s]\u001b[A\n",
      "  3%|▊                              | 62354/2316892 [00:00<00:18, 125159.40it/s]\u001b[A\n",
      "  3%|█                              | 74870/2316892 [00:00<00:17, 124722.89it/s]\u001b[A\n",
      "  4%|█▏                             | 87378/2316892 [00:00<00:17, 124837.85it/s]\u001b[A\n",
      "  4%|█▎                             | 99863/2316892 [00:00<00:17, 124675.28it/s]\u001b[A\n",
      "  5%|█▍                            | 112378/2316892 [00:00<00:17, 124821.10it/s]\u001b[A\n",
      "  5%|█▌                            | 124861/2316892 [00:01<00:17, 124734.13it/s]\u001b[A\n",
      "  6%|█▊                            | 137335/2316892 [00:01<00:17, 124374.84it/s]\u001b[A\n",
      "  6%|█▉                            | 149843/2316892 [00:01<00:17, 124586.31it/s]\u001b[A\n",
      "  7%|██                            | 162393/2316892 [00:01<00:17, 124860.65it/s]\u001b[A\n",
      "  8%|██▎                           | 174880/2316892 [00:01<00:17, 124398.01it/s]\u001b[A\n",
      "  8%|██▍                           | 187321/2316892 [00:01<00:17, 123428.06it/s]\u001b[A\n",
      "  9%|██▌                           | 199750/2316892 [00:01<00:17, 123684.58it/s]\u001b[A\n",
      "  9%|██▋                           | 212120/2316892 [00:01<00:17, 123373.30it/s]\u001b[A\n",
      " 10%|██▉                           | 224618/2316892 [00:01<00:16, 123850.54it/s]\u001b[A\n",
      " 10%|███                           | 237005/2316892 [00:01<00:16, 123746.79it/s]\u001b[A\n",
      " 11%|███▏                          | 249621/2316892 [00:02<00:16, 124467.18it/s]\u001b[A\n",
      " 11%|███▍                          | 262069/2316892 [00:02<00:16, 124130.49it/s]\u001b[A\n",
      " 12%|███▌                          | 274483/2316892 [00:02<00:16, 123468.59it/s]\u001b[A\n",
      " 12%|███▋                          | 287045/2316892 [00:02<00:16, 124107.35it/s]\u001b[A\n",
      " 13%|███▉                          | 299457/2316892 [00:02<00:16, 123789.88it/s]\u001b[A\n",
      " 13%|████                          | 311950/2316892 [00:02<00:16, 124127.23it/s]\u001b[A\n",
      " 14%|████▏                         | 324430/2316892 [00:02<00:16, 124325.22it/s]\u001b[A\n",
      " 15%|████▎                         | 336864/2316892 [00:02<00:15, 123939.05it/s]\u001b[A\n",
      " 15%|████▌                         | 349259/2316892 [00:02<00:15, 123872.02it/s]\u001b[A\n",
      " 16%|████▋                         | 361647/2316892 [00:02<00:16, 121968.19it/s]\u001b[A\n",
      " 16%|████▊                         | 374034/2316892 [00:03<00:15, 122530.33it/s]\u001b[A\n",
      " 17%|█████                         | 386403/2316892 [00:03<00:15, 122874.39it/s]\u001b[A\n",
      " 17%|█████▏                        | 398883/2316892 [00:03<00:15, 123445.16it/s]\u001b[A\n",
      " 18%|█████▎                        | 411500/2316892 [00:03<00:15, 124252.41it/s]\u001b[A\n",
      " 18%|█████▍                        | 424066/2316892 [00:03<00:15, 124669.73it/s]\u001b[A\n",
      " 19%|█████▋                        | 436576/2316892 [00:03<00:15, 124795.88it/s]\u001b[A\n",
      " 19%|█████▊                        | 449057/2316892 [00:03<00:14, 124573.12it/s]\u001b[A\n",
      " 20%|█████▉                        | 461516/2316892 [00:03<00:14, 123739.60it/s]\u001b[A\n",
      " 20%|██████▏                       | 473955/2316892 [00:03<00:14, 123932.18it/s]\u001b[A\n",
      " 21%|██████▎                       | 486350/2316892 [00:03<00:14, 123387.73it/s]\u001b[A\n",
      " 22%|██████▍                       | 498691/2316892 [00:04<00:14, 123270.33it/s]\u001b[A\n",
      " 22%|██████▌                       | 511039/2316892 [00:04<00:14, 123331.37it/s]\u001b[A\n",
      " 23%|██████▊                       | 523410/2316892 [00:04<00:14, 123436.32it/s]\u001b[A\n",
      " 23%|██████▉                       | 535852/2316892 [00:04<00:14, 123728.41it/s]\u001b[A\n",
      " 24%|███████                       | 548226/2316892 [00:04<00:14, 123685.91it/s]\u001b[A\n",
      " 24%|███████▎                      | 560648/2316892 [00:04<00:14, 123844.16it/s]\u001b[A\n",
      " 25%|███████▍                      | 573033/2316892 [00:04<00:14, 123084.36it/s]\u001b[A\n",
      " 25%|███████▌                      | 585343/2316892 [00:04<00:14, 122937.63it/s]\u001b[A\n",
      " 26%|███████▋                      | 597638/2316892 [00:04<00:13, 122850.03it/s]\u001b[A\n",
      " 26%|███████▉                      | 610012/2316892 [00:04<00:13, 123112.93it/s]\u001b[A\n",
      " 27%|████████                      | 622324/2316892 [00:05<00:13, 123087.07it/s]\u001b[A\n",
      " 27%|████████▏                     | 634738/2316892 [00:05<00:13, 123399.46it/s]\u001b[A\n",
      " 28%|████████▍                     | 647079/2316892 [00:05<00:13, 123269.35it/s]\u001b[A\n",
      " 28%|████████▌                     | 659540/2316892 [00:05<00:13, 123667.80it/s]\u001b[A\n",
      " 29%|████████▋                     | 672051/2316892 [00:05<00:13, 124098.64it/s]\u001b[A\n",
      " 30%|████████▊                     | 684521/2316892 [00:05<00:13, 124275.91it/s]\u001b[A\n",
      " 30%|█████████                     | 696949/2316892 [00:05<00:13, 123566.58it/s]\u001b[A\n",
      " 31%|█████████▏                    | 709422/2316892 [00:05<00:12, 123912.85it/s]\u001b[A\n",
      " 31%|█████████▎                    | 721815/2316892 [00:05<00:13, 119586.41it/s]\u001b[A\n",
      " 32%|█████████▌                    | 734416/2316892 [00:05<00:13, 121460.28it/s]\u001b[A\n",
      " 32%|█████████▋                    | 746801/2316892 [00:06<00:12, 122162.85it/s]\u001b[A\n",
      " 33%|█████████▊                    | 759038/2316892 [00:06<00:12, 121981.36it/s]\u001b[A\n",
      " 33%|█████████▉                    | 771533/2316892 [00:06<00:12, 122860.74it/s]\u001b[A\n",
      " 34%|██████████▏                   | 783938/2316892 [00:06<00:12, 123214.24it/s]\u001b[A\n",
      " 34%|██████████▎                   | 796365/2316892 [00:06<00:12, 123526.77it/s]\u001b[A\n",
      " 35%|██████████▍                   | 808802/2316892 [00:06<00:12, 123777.33it/s]\u001b[A\n",
      " 35%|██████████▋                   | 821217/2316892 [00:06<00:12, 123886.48it/s]\u001b[A\n",
      " 36%|██████████▊                   | 833688/2316892 [00:06<00:11, 124128.86it/s]\u001b[A\n",
      " 37%|██████████▉                   | 846103/2316892 [00:06<00:11, 124129.02it/s]\u001b[A\n",
      " 37%|███████████                   | 858518/2316892 [00:06<00:11, 123648.68it/s]\u001b[A\n",
      " 38%|███████████▎                  | 870885/2316892 [00:07<00:11, 123617.91it/s]\u001b[A\n",
      " 38%|███████████▍                  | 883248/2316892 [00:07<00:11, 123504.11it/s]\u001b[A\n",
      " 39%|███████████▌                  | 895610/2316892 [00:07<00:11, 123536.71it/s]\u001b[A\n",
      " 39%|███████████▊                  | 907988/2316892 [00:07<00:11, 123608.64it/s]\u001b[A\n",
      " 40%|███████████▉                  | 920353/2316892 [00:07<00:11, 123620.62it/s]\u001b[A\n",
      " 40%|████████████                  | 932813/2316892 [00:07<00:11, 123910.94it/s]\u001b[A\n",
      " 41%|████████████▏                 | 945205/2316892 [00:07<00:11, 123190.30it/s]\u001b[A\n",
      " 41%|████████████▍                 | 957536/2316892 [00:07<00:11, 123223.27it/s]\u001b[A\n",
      " 42%|████████████▌                 | 969873/2316892 [00:07<00:10, 123265.78it/s]\u001b[A\n",
      " 42%|████████████▋                 | 982254/2316892 [00:07<00:10, 123427.39it/s]\u001b[A\n",
      " 43%|████████████▉                 | 994664/2316892 [00:08<00:10, 123628.19it/s]\u001b[A\n",
      " 43%|████████████▌                | 1007141/2316892 [00:08<00:10, 123968.35it/s]\u001b[A\n",
      " 44%|████████████▊                | 1019639/2316892 [00:08<00:10, 124268.35it/s]\u001b[A\n",
      " 45%|████████████▉                | 1032067/2316892 [00:08<00:10, 123690.70it/s]\u001b[A\n",
      " 45%|█████████████                | 1044582/2316892 [00:08<00:10, 124124.70it/s]\u001b[A\n",
      " 46%|█████████████▏               | 1057005/2316892 [00:08<00:10, 124154.56it/s]\u001b[A\n",
      " 46%|█████████████▍               | 1069421/2316892 [00:08<00:10, 123992.72it/s]\u001b[A\n",
      " 47%|█████████████▌               | 1081821/2316892 [00:08<00:09, 123826.94it/s]\u001b[A\n",
      " 47%|█████████████▋               | 1094204/2316892 [00:08<00:09, 123390.09it/s]\u001b[A\n",
      " 48%|█████████████▊               | 1106544/2316892 [00:08<00:09, 123380.25it/s]\u001b[A\n",
      " 48%|██████████████               | 1118947/2316892 [00:09<00:09, 123572.42it/s]\u001b[A\n",
      " 49%|██████████████▏              | 1131484/2316892 [00:09<00:09, 124109.87it/s]\u001b[A\n",
      " 49%|██████████████▎              | 1143896/2316892 [00:09<00:09, 124054.29it/s]\u001b[A\n",
      " 50%|██████████████▍              | 1156302/2316892 [00:09<00:09, 123985.63it/s]\u001b[A\n",
      " 50%|██████████████▋              | 1168701/2316892 [00:09<00:09, 123805.16it/s]\u001b[A\n",
      " 51%|██████████████▊              | 1181082/2316892 [00:09<00:09, 123446.67it/s]\u001b[A\n",
      " 52%|██████████████▉              | 1193465/2316892 [00:09<00:09, 123558.05it/s]\u001b[A\n",
      " 52%|███████████████              | 1205822/2316892 [00:09<00:09, 123150.78it/s]\u001b[A\n",
      " 53%|███████████████▏             | 1218208/2316892 [00:09<00:08, 123360.88it/s]\u001b[A\n",
      " 39%|███████████▎                 | 3755445/9631255 [00:50<00:35, 165787.71it/s]\u001b[A\n",
      " 54%|███████████████▌             | 1242909/2316892 [00:10<00:08, 123342.65it/s]\u001b[A\n",
      " 54%|███████████████▋             | 1255298/2316892 [00:10<00:08, 123505.86it/s]\u001b[A\n",
      " 55%|███████████████▊             | 1267759/2316892 [00:10<00:08, 123834.82it/s]\u001b[A\n",
      " 55%|████████████████             | 1280279/2316892 [00:10<00:08, 124242.50it/s]\u001b[A\n",
      " 56%|████████████████▏            | 1292793/2316892 [00:10<00:08, 124508.13it/s]\u001b[A\n",
      " 56%|████████████████▎            | 1305244/2316892 [00:10<00:08, 124453.29it/s]\u001b[A\n",
      " 57%|████████████████▍            | 1317690/2316892 [00:10<00:08, 123714.13it/s]\u001b[A\n",
      " 57%|████████████████▋            | 1330063/2316892 [00:10<00:08, 123058.68it/s]\u001b[A\n",
      " 58%|████████████████▊            | 1342371/2316892 [00:10<00:07, 122703.21it/s]\u001b[A\n",
      " 58%|████████████████▉            | 1354643/2316892 [00:10<00:07, 122655.02it/s]\u001b[A\n",
      " 59%|█████████████████            | 1366927/2316892 [00:11<00:07, 122707.90it/s]\u001b[A\n",
      " 60%|█████████████████▎           | 1379230/2316892 [00:11<00:07, 122802.82it/s]\u001b[A\n",
      " 60%|█████████████████▍           | 1391511/2316892 [00:11<00:07, 122683.95it/s]\u001b[A\n",
      " 61%|█████████████████▌           | 1403780/2316892 [00:11<00:07, 122580.32it/s]\u001b[A\n",
      " 61%|█████████████████▋           | 1416039/2316892 [00:11<00:07, 122139.19it/s]\u001b[A\n",
      " 62%|█████████████████▉           | 1428254/2316892 [00:11<00:07, 122045.53it/s]\u001b[A\n",
      " 62%|██████████████████           | 1440459/2316892 [00:11<00:07, 112833.62it/s]\u001b[A\n",
      " 63%|██████████████████▏          | 1452612/2316892 [00:11<00:07, 115293.71it/s]\u001b[A\n",
      " 63%|██████████████████▎          | 1465096/2316892 [00:11<00:07, 118041.16it/s]\u001b[A\n",
      " 64%|██████████████████▍          | 1477514/2316892 [00:11<00:07, 119828.05it/s]\u001b[A\n",
      " 64%|██████████████████▋          | 1489907/2316892 [00:12<00:06, 121032.13it/s]\u001b[A\n",
      " 65%|██████████████████▊          | 1502254/2316892 [00:12<00:06, 121749.97it/s]\u001b[A\n",
      " 65%|██████████████████▉          | 1514619/2316892 [00:12<00:06, 122312.24it/s]\u001b[A\n",
      " 66%|███████████████████          | 1527066/2316892 [00:12<00:06, 122952.70it/s]\u001b[A\n",
      " 66%|███████████████████▎         | 1539517/2316892 [00:12<00:06, 123414.19it/s]\u001b[A\n",
      " 67%|███████████████████▍         | 1551872/2316892 [00:12<00:06, 122934.78it/s]\u001b[A\n",
      " 68%|███████████████████▌         | 1564395/2316892 [00:12<00:06, 123613.96it/s]\u001b[A\n",
      " 68%|███████████████████▋         | 1576764/2316892 [00:12<00:06, 122785.80it/s]\u001b[A\n",
      " 69%|███████████████████▉         | 1589049/2316892 [00:12<00:05, 122640.06it/s]\u001b[A\n",
      " 69%|████████████████████         | 1601318/2316892 [00:12<00:05, 122610.79it/s]\u001b[A\n",
      " 70%|████████████████████▏        | 1613619/2316892 [00:13<00:05, 122729.52it/s]\u001b[A\n",
      " 70%|████████████████████▎        | 1625958/2316892 [00:13<00:05, 122924.25it/s]\u001b[A\n",
      " 71%|████████████████████▌        | 1638369/2316892 [00:13<00:05, 123277.36it/s]\u001b[A\n",
      " 71%|████████████████████▋        | 1650768/2316892 [00:13<00:05, 123490.40it/s]\u001b[A\n",
      " 72%|████████████████████▊        | 1663118/2316892 [00:13<00:05, 123080.28it/s]\u001b[A\n",
      " 72%|████████████████████▉        | 1675427/2316892 [00:13<00:05, 123000.08it/s]\u001b[A\n",
      " 73%|█████████████████████▏       | 1687756/2316892 [00:13<00:05, 123083.70it/s]\u001b[A\n",
      " 73%|█████████████████████▎       | 1700065/2316892 [00:13<00:05, 122955.27it/s]\u001b[A\n",
      " 74%|█████████████████████▍       | 1712361/2316892 [00:13<00:04, 122760.36it/s]\u001b[A\n",
      " 74%|█████████████████████▌       | 1724671/2316892 [00:13<00:04, 122859.39it/s]\u001b[A\n",
      " 75%|█████████████████████▋       | 1736958/2316892 [00:14<00:04, 122767.07it/s]\u001b[A\n",
      " 75%|█████████████████████▉       | 1749249/2316892 [00:14<00:04, 122808.85it/s]\u001b[A\n",
      " 76%|██████████████████████       | 1761561/2316892 [00:14<00:04, 122898.42it/s]\u001b[A\n",
      " 77%|██████████████████████▏      | 1773922/2316892 [00:14<00:04, 123109.80it/s]\u001b[A\n",
      " 77%|██████████████████████▎      | 1786250/2316892 [00:14<00:04, 123160.34it/s]\u001b[A\n",
      " 78%|██████████████████████▌      | 1798567/2316892 [00:14<00:04, 123024.92it/s]\u001b[A\n",
      " 78%|██████████████████████▋      | 1810935/2316892 [00:14<00:04, 123220.20it/s]\u001b[A\n",
      " 79%|██████████████████████▊      | 1823258/2316892 [00:14<00:04, 122920.88it/s]\u001b[A\n",
      " 79%|██████████████████████▉      | 1835641/2316892 [00:14<00:03, 123183.71it/s]\u001b[A\n",
      " 80%|███████████████████████▏     | 1848123/2316892 [00:14<00:03, 123672.77it/s]\u001b[A\n",
      " 80%|███████████████████████▎     | 1860491/2316892 [00:15<00:03, 123645.47it/s]\u001b[A\n",
      " 81%|███████████████████████▍     | 1872856/2316892 [00:15<00:03, 123315.81it/s]\u001b[A\n",
      " 81%|███████████████████████▌     | 1885188/2316892 [00:15<00:03, 123252.47it/s]\u001b[A\n",
      " 82%|███████████████████████▊     | 1897514/2316892 [00:15<00:03, 123161.05it/s]\u001b[A\n",
      " 82%|███████████████████████▉     | 1909892/2316892 [00:15<00:03, 123345.95it/s]\u001b[A\n",
      " 83%|████████████████████████     | 1922227/2316892 [00:15<00:03, 122791.26it/s]\u001b[A\n",
      " 84%|████████████████████████▏    | 1934630/2316892 [00:15<00:03, 123158.83it/s]\u001b[A\n",
      " 84%|████████████████████████▎    | 1946947/2316892 [00:15<00:03, 123160.54it/s]\u001b[A\n",
      " 85%|████████████████████████▌    | 1959264/2316892 [00:15<00:02, 122399.13it/s]\u001b[A\n",
      " 85%|████████████████████████▋    | 1971544/2316892 [00:15<00:02, 122518.03it/s]\u001b[A\n",
      " 86%|████████████████████████▊    | 1983797/2316892 [00:16<00:02, 122477.84it/s]\u001b[A\n",
      " 86%|████████████████████████▉    | 1996068/2316892 [00:16<00:02, 122544.08it/s]\u001b[A\n",
      " 87%|█████████████████████████▏   | 2008467/2316892 [00:16<00:02, 122975.10it/s]\u001b[A\n",
      " 87%|█████████████████████████▎   | 2020946/2316892 [00:16<00:02, 123515.41it/s]\u001b[A\n",
      " 88%|█████████████████████████▍   | 2033298/2316892 [00:16<00:02, 123385.38it/s]\u001b[A\n",
      " 88%|█████████████████████████▌   | 2045637/2316892 [00:16<00:02, 122954.25it/s]\u001b[A\n",
      " 89%|█████████████████████████▊   | 2057933/2316892 [00:16<00:02, 122708.84it/s]\u001b[A\n",
      " 89%|█████████████████████████▉   | 2070205/2316892 [00:16<00:02, 122260.20it/s]\u001b[A\n",
      " 90%|██████████████████████████   | 2082432/2316892 [00:16<00:01, 121948.12it/s]\u001b[A\n",
      " 90%|██████████████████████████▏  | 2094644/2316892 [00:17<00:01, 121998.05it/s]\u001b[A\n",
      " 91%|██████████████████████████▎  | 2106849/2316892 [00:17<00:01, 122011.61it/s]\u001b[A\n",
      " 91%|██████████████████████████▌  | 2119051/2316892 [00:17<00:01, 122002.75it/s]\u001b[A\n",
      " 92%|██████████████████████████▋  | 2131252/2316892 [00:17<00:01, 121292.20it/s]\u001b[A\n",
      " 93%|██████████████████████████▊  | 2143383/2316892 [00:17<00:01, 120944.64it/s]\u001b[A\n",
      " 93%|██████████████████████████▉  | 2155479/2316892 [00:17<00:01, 120709.01it/s]\u001b[A\n",
      " 94%|███████████████████████████▏ | 2167551/2316892 [00:17<00:01, 120700.22it/s]\u001b[A\n",
      " 94%|███████████████████████████▎ | 2179871/2316892 [00:17<00:01, 121445.77it/s]\u001b[A\n",
      " 95%|███████████████████████████▍ | 2192061/2316892 [00:17<00:01, 121580.31it/s]\u001b[A\n",
      " 95%|███████████████████████████▌ | 2204220/2316892 [00:17<00:00, 121224.55it/s]\u001b[A\n",
      " 96%|███████████████████████████▋ | 2216343/2316892 [00:18<00:00, 121109.07it/s]\u001b[A\n",
      " 96%|███████████████████████████▉ | 2228471/2316892 [00:18<00:00, 121158.32it/s]\u001b[A\n",
      " 97%|████████████████████████████ | 2240663/2316892 [00:18<00:00, 121383.33it/s]\u001b[A\n",
      " 97%|████████████████████████████▏| 2252902/2316892 [00:18<00:00, 121682.47it/s]\u001b[A\n",
      " 98%|████████████████████████████▎| 2265071/2316892 [00:18<00:00, 121499.86it/s]\u001b[A\n",
      " 98%|████████████████████████████▌| 2277289/2316892 [00:18<00:00, 121700.61it/s]\u001b[A\n",
      " 99%|████████████████████████████▋| 2289460/2316892 [00:18<00:00, 121377.54it/s]\u001b[A\n",
      " 99%|████████████████████████████▊| 2301599/2316892 [00:18<00:00, 120722.32it/s]\u001b[A\n",
      "100%|█████████████████████████████| 2316892/2316892 [00:18<00:00, 122968.48it/s]\u001b[A\n",
      "[NeMo I 2025-09-19 04:36:21 nemo_logging:393] Processed 2316892 n-grams of order 4\n",
      " 69%|███████████████████▉         | 6608632/9631255 [01:17<00:19, 157450.24it/s]\n",
      "  0%|                                               | 0/2848161 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                              | 12512/2848161 [00:00<00:22, 125115.94it/s]\u001b[A\n",
      "  1%|▎                              | 25235/2848161 [00:00<00:22, 126354.60it/s]\u001b[A\n",
      "  1%|▍                              | 37871/2848161 [00:00<00:22, 126206.81it/s]\u001b[A\n",
      "  2%|▌                              | 50492/2848161 [00:00<00:22, 125766.18it/s]\u001b[A\n",
      "  2%|▋                              | 63069/2848161 [00:00<00:22, 125670.73it/s]\u001b[A\n",
      "  3%|▊                              | 75747/2848161 [00:00<00:21, 126043.39it/s]\u001b[A\n",
      "  3%|▉                              | 88528/2848161 [00:00<00:21, 126617.90it/s]\u001b[A\n",
      "  4%|█                             | 101340/2848161 [00:00<00:21, 127094.85it/s]\u001b[A\n",
      "  4%|█▏                            | 114050/2848161 [00:00<00:21, 126808.54it/s]\u001b[A\n",
      "  4%|█▎                            | 126775/2848161 [00:01<00:21, 126941.41it/s]\u001b[A\n",
      "  5%|█▍                            | 139500/2848161 [00:01<00:21, 127033.53it/s]\u001b[A\n",
      "  5%|█▌                            | 152204/2848161 [00:01<00:21, 126933.36it/s]\u001b[A\n",
      "  6%|█▋                            | 164898/2848161 [00:01<00:21, 126749.07it/s]\u001b[A\n",
      "  6%|█▊                            | 177574/2848161 [00:01<00:21, 125782.06it/s]\u001b[A\n",
      "  7%|██                            | 190161/2848161 [00:01<00:21, 125807.62it/s]\u001b[A\n",
      "  7%|██▏                           | 202743/2848161 [00:01<00:21, 125596.60it/s]\u001b[A\n",
      "  8%|██▎                           | 215437/2848161 [00:01<00:20, 125995.73it/s]\u001b[A\n",
      "  8%|██▍                           | 228123/2848161 [00:01<00:20, 126253.93it/s]\u001b[A\n",
      "  8%|██▌                           | 240911/2848161 [00:01<00:20, 126738.09it/s]\u001b[A\n",
      "  9%|██▋                           | 253680/2848161 [00:02<00:20, 127020.12it/s]\u001b[A\n",
      "  9%|██▊                           | 266383/2848161 [00:02<00:20, 126462.71it/s]\u001b[A\n",
      " 10%|██▉                           | 279099/2848161 [00:02<00:20, 126670.30it/s]\u001b[A\n",
      " 10%|███                           | 291996/2848161 [00:02<00:20, 127355.29it/s]\u001b[A\n",
      " 11%|███▏                          | 304835/2848161 [00:02<00:19, 127662.47it/s]\u001b[A\n",
      " 11%|███▎                          | 317602/2848161 [00:02<00:19, 127522.28it/s]\u001b[A\n",
      " 12%|███▍                          | 330358/2848161 [00:02<00:19, 127531.07it/s]\u001b[A\n",
      " 12%|███▌                          | 343136/2848161 [00:02<00:19, 127603.87it/s]\u001b[A\n",
      " 12%|███▋                          | 355909/2848161 [00:02<00:19, 127639.62it/s]\u001b[A\n",
      " 13%|███▉                          | 368674/2848161 [00:02<00:19, 126227.48it/s]\u001b[A\n",
      " 13%|████                          | 381478/2848161 [00:03<00:19, 126763.22it/s]\u001b[A\n",
      " 14%|████▏                         | 394357/2848161 [00:03<00:19, 127364.97it/s]\u001b[A\n",
      " 14%|████▎                         | 407213/2848161 [00:03<00:19, 127720.33it/s]\u001b[A\n",
      " 15%|████▍                         | 420026/2848161 [00:03<00:18, 127840.73it/s]\u001b[A\n",
      " 15%|████▌                         | 432894/2848161 [00:03<00:18, 128088.75it/s]\u001b[A\n",
      " 16%|████▋                         | 445704/2848161 [00:03<00:18, 128012.98it/s]\u001b[A\n",
      " 16%|████▊                         | 458530/2848161 [00:03<00:18, 128085.64it/s]\u001b[A\n",
      " 17%|████▉                         | 471362/2848161 [00:03<00:18, 128154.72it/s]\u001b[A\n",
      " 17%|█████                         | 484178/2848161 [00:03<00:18, 127769.32it/s]\u001b[A\n",
      " 17%|█████▏                        | 496956/2848161 [00:03<00:18, 127089.94it/s]\u001b[A\n",
      " 18%|█████▎                        | 509679/2848161 [00:04<00:18, 127129.59it/s]\u001b[A\n",
      " 18%|█████▌                        | 522393/2848161 [00:04<00:18, 126880.44it/s]\u001b[A\n",
      " 19%|█████▋                        | 535104/2848161 [00:04<00:18, 126947.52it/s]\u001b[A\n",
      " 19%|█████▊                        | 547800/2848161 [00:04<00:18, 126763.97it/s]\u001b[A\n",
      " 20%|█████▉                        | 560497/2848161 [00:04<00:18, 126822.64it/s]\u001b[A\n",
      " 20%|██████                        | 573180/2848161 [00:04<00:17, 126743.20it/s]\u001b[A\n",
      " 21%|██████▏                       | 585913/2848161 [00:04<00:17, 126915.67it/s]\u001b[A\n",
      " 21%|██████▎                       | 598607/2848161 [00:04<00:17, 126920.91it/s]\u001b[A\n",
      " 21%|██████▍                       | 611300/2848161 [00:04<00:17, 126716.23it/s]\u001b[A\n",
      " 22%|██████▌                       | 623972/2848161 [00:04<00:17, 126364.02it/s]\u001b[A\n",
      " 22%|██████▋                       | 636621/2848161 [00:05<00:17, 126399.11it/s]\u001b[A\n",
      " 23%|██████▊                       | 649272/2848161 [00:05<00:17, 126429.99it/s]\u001b[A\n",
      " 23%|██████▉                       | 662001/2848161 [00:05<00:17, 126686.80it/s]\u001b[A\n",
      " 24%|███████                       | 674713/2848161 [00:05<00:17, 126814.75it/s]\u001b[A\n",
      " 24%|███████▏                      | 687562/2848161 [00:05<00:16, 127316.14it/s]\u001b[A\n",
      " 25%|███████▍                      | 700332/2848161 [00:05<00:16, 127430.17it/s]\u001b[A\n",
      " 25%|███████▌                      | 713076/2848161 [00:05<00:16, 127232.85it/s]\u001b[A\n",
      " 25%|███████▋                      | 725800/2848161 [00:05<00:16, 124912.87it/s]\u001b[A\n",
      " 26%|███████▊                      | 738588/2848161 [00:05<00:16, 125787.65it/s]\u001b[A\n",
      " 26%|███████▉                      | 751385/2848161 [00:05<00:16, 126434.14it/s]\u001b[A\n",
      " 27%|████████                      | 764311/2848161 [00:06<00:16, 127274.97it/s]\u001b[A\n",
      " 27%|████████▏                     | 777044/2848161 [00:06<00:16, 126969.50it/s]\u001b[A\n",
      " 28%|████████▎                     | 789745/2848161 [00:06<00:16, 126823.06it/s]\u001b[A\n",
      " 28%|████████▍                     | 802430/2848161 [00:06<00:16, 126671.68it/s]\u001b[A\n",
      " 29%|████████▌                     | 815157/2848161 [00:06<00:16, 126848.68it/s]\u001b[A\n",
      " 29%|████████▋                     | 827844/2848161 [00:06<00:15, 126587.03it/s]\u001b[A\n",
      " 30%|████████▊                     | 840567/2848161 [00:06<00:15, 126778.03it/s]\u001b[A\n",
      " 30%|████████▉                     | 853302/2848161 [00:06<00:15, 126947.07it/s]\u001b[A\n",
      " 30%|█████████                     | 865998/2848161 [00:06<00:15, 126629.72it/s]\u001b[A\n",
      " 31%|█████████▎                    | 878823/2848161 [00:06<00:15, 127111.41it/s]\u001b[A\n",
      " 31%|█████████▍                    | 891535/2848161 [00:07<00:15, 126750.60it/s]\u001b[A\n",
      " 32%|█████████▌                    | 904292/2848161 [00:07<00:15, 126994.25it/s]\u001b[A\n",
      " 32%|█████████▋                    | 916992/2848161 [00:07<00:15, 126917.76it/s]\u001b[A\n",
      " 33%|█████████▊                    | 929685/2848161 [00:07<00:15, 126618.36it/s]\u001b[A\n",
      " 33%|█████████▉                    | 942469/2848161 [00:07<00:15, 126981.01it/s]\u001b[A\n",
      " 34%|██████████                    | 955168/2848161 [00:07<00:14, 126907.21it/s]\u001b[A\n",
      " 34%|██████████▏                   | 968118/2848161 [00:07<00:14, 127681.44it/s]\u001b[A\n",
      " 34%|██████████▎                   | 980906/2848161 [00:07<00:14, 127738.41it/s]\u001b[A\n",
      " 35%|██████████▍                   | 993681/2848161 [00:07<00:14, 127455.40it/s]\u001b[A\n",
      " 35%|██████████▏                  | 1006427/2848161 [00:07<00:14, 126711.44it/s]\u001b[A\n",
      " 36%|██████████▍                  | 1019100/2848161 [00:08<00:14, 126537.03it/s]\u001b[A\n",
      " 36%|██████████▌                  | 1031834/2848161 [00:08<00:14, 126775.04it/s]\u001b[A\n",
      " 37%|██████████▋                  | 1044513/2848161 [00:08<00:14, 126591.87it/s]\u001b[A\n",
      " 37%|██████████▊                  | 1057214/2848161 [00:08<00:14, 126714.11it/s]\u001b[A\n",
      " 38%|██████████▉                  | 1069886/2848161 [00:08<00:14, 126676.59it/s]\u001b[A\n",
      " 38%|███████████                  | 1082554/2848161 [00:08<00:13, 126539.08it/s]\u001b[A\n",
      " 38%|███████████▏                 | 1095247/2848161 [00:08<00:13, 126653.07it/s]\u001b[A\n",
      " 39%|███████████▎                 | 1108054/2848161 [00:08<00:13, 127077.00it/s]\u001b[A\n",
      " 39%|███████████▍                 | 1120762/2848161 [00:08<00:13, 127045.17it/s]\u001b[A\n",
      " 40%|███████████▌                 | 1133467/2848161 [00:08<00:13, 126882.72it/s]\u001b[A\n",
      " 40%|███████████▋                 | 1146156/2848161 [00:09<00:13, 126751.15it/s]\u001b[A\n",
      " 41%|███████████▊                 | 1158832/2848161 [00:09<00:13, 126650.12it/s]\u001b[A\n",
      " 41%|███████████▉                 | 1171523/2848161 [00:09<00:13, 126724.81it/s]\u001b[A\n",
      " 42%|████████████                 | 1184196/2848161 [00:09<00:13, 126686.22it/s]\u001b[A\n",
      " 42%|████████████▏                | 1197016/2848161 [00:09<00:12, 127137.06it/s]\u001b[A\n",
      " 42%|████████████▎                | 1209730/2848161 [00:09<00:12, 127135.61it/s]\u001b[A\n",
      " 43%|████████████▍                | 1222486/2848161 [00:09<00:12, 127260.53it/s]\u001b[A\n",
      " 43%|████████████▌                | 1235213/2848161 [00:09<00:12, 127253.58it/s]\u001b[A\n",
      " 44%|████████████▋                | 1247939/2848161 [00:09<00:12, 126996.21it/s]\u001b[A\n",
      " 44%|████████████▊                | 1260639/2848161 [00:09<00:12, 126717.87it/s]\u001b[A\n",
      " 45%|████████████▉                | 1273311/2848161 [00:10<00:12, 126464.88it/s]\u001b[A\n",
      " 45%|█████████████                | 1286045/2848161 [00:10<00:12, 126724.23it/s]\u001b[A\n",
      " 46%|█████████████▏               | 1298718/2848161 [00:10<00:12, 126560.99it/s]\u001b[A\n",
      " 46%|█████████████▎               | 1311472/2848161 [00:10<00:12, 126853.35it/s]\u001b[A\n",
      " 46%|█████████████▍               | 1324158/2848161 [00:10<00:12, 126582.08it/s]\u001b[A\n",
      " 47%|█████████████▌               | 1336817/2848161 [00:10<00:11, 126423.07it/s]\u001b[A\n",
      " 47%|█████████████▋               | 1349504/2848161 [00:10<00:11, 126553.83it/s]\u001b[A\n",
      " 69%|███████████████████▉         | 6608632/9631255 [01:33<00:19, 157450.24it/s]\u001b[A\n",
      " 48%|█████████████▉               | 1374925/2848161 [00:10<00:11, 126739.90it/s]\u001b[A\n",
      " 49%|██████████████▏              | 1387600/2848161 [00:10<00:11, 126554.48it/s]\u001b[A\n",
      " 49%|██████████████▎              | 1400256/2848161 [00:11<00:11, 126125.31it/s]\u001b[A\n",
      " 50%|██████████████▍              | 1412869/2848161 [00:11<00:11, 125354.27it/s]\u001b[A\n",
      " 50%|██████████████▌              | 1425617/2848161 [00:11<00:11, 125986.71it/s]\u001b[A\n",
      " 50%|██████████████▋              | 1438217/2848161 [00:11<00:12, 116074.11it/s]\u001b[A\n",
      " 51%|██████████████▊              | 1450947/2848161 [00:11<00:11, 119238.77it/s]\u001b[A\n",
      " 51%|██████████████▉              | 1463757/2848161 [00:11<00:11, 121781.34it/s]\u001b[A\n",
      " 52%|███████████████              | 1476547/2848161 [00:11<00:11, 123558.55it/s]\u001b[A\n",
      " 52%|███████████████▏             | 1489234/2848161 [00:11<00:10, 124527.55it/s]\u001b[A\n",
      " 53%|███████████████▎             | 1501925/2848161 [00:11<00:10, 125228.99it/s]\u001b[A\n",
      " 53%|███████████████▍             | 1514687/2848161 [00:11<00:10, 125937.37it/s]\u001b[A\n",
      " 54%|███████████████▌             | 1527456/2848161 [00:12<00:10, 126456.76it/s]\u001b[A\n",
      " 54%|███████████████▋             | 1540212/2848161 [00:12<00:10, 126784.68it/s]\u001b[A\n",
      " 55%|███████████████▊             | 1552905/2848161 [00:12<00:10, 126660.44it/s]\u001b[A\n",
      " 55%|███████████████▉             | 1565582/2848161 [00:12<00:10, 126643.68it/s]\u001b[A\n",
      " 55%|████████████████             | 1578262/2848161 [00:12<00:10, 126687.95it/s]\u001b[A\n",
      " 56%|████████████████▏            | 1590936/2848161 [00:12<00:09, 126406.06it/s]\u001b[A\n",
      " 56%|████████████████▎            | 1603612/2848161 [00:12<00:09, 126509.52it/s]\u001b[A\n",
      " 57%|████████████████▍            | 1616266/2848161 [00:12<00:09, 126369.50it/s]\u001b[A\n",
      " 57%|████████████████▌            | 1628905/2848161 [00:12<00:09, 126333.12it/s]\u001b[A\n",
      " 58%|████████████████▋            | 1641540/2848161 [00:12<00:09, 126211.97it/s]\u001b[A\n",
      " 58%|████████████████▊            | 1654163/2848161 [00:13<00:09, 125763.78it/s]\u001b[A\n",
      " 59%|████████████████▉            | 1666855/2848161 [00:13<00:09, 126108.60it/s]\u001b[A\n",
      " 59%|█████████████████            | 1679620/2848161 [00:13<00:09, 126567.80it/s]\u001b[A\n",
      " 59%|█████████████████▏           | 1692367/2848161 [00:13<00:09, 126835.08it/s]\u001b[A\n",
      " 60%|█████████████████▎           | 1705053/2848161 [00:13<00:09, 126839.86it/s]\u001b[A\n",
      " 60%|█████████████████▍           | 1717738/2848161 [00:13<00:08, 126523.43it/s]\u001b[A\n",
      " 61%|█████████████████▌           | 1730589/2848161 [00:13<00:08, 127116.89it/s]\u001b[A\n",
      " 61%|█████████████████▊           | 1743302/2848161 [00:13<00:08, 126830.16it/s]\u001b[A\n",
      " 62%|█████████████████▉           | 1755992/2848161 [00:13<00:08, 126849.28it/s]\u001b[A\n",
      " 62%|██████████████████           | 1768678/2848161 [00:13<00:08, 126730.94it/s]\u001b[A\n",
      " 63%|██████████████████▏          | 1781352/2848161 [00:14<00:08, 126152.98it/s]\u001b[A\n",
      " 63%|██████████████████▎          | 1793968/2848161 [00:14<00:08, 125918.27it/s]\u001b[A\n",
      " 63%|██████████████████▍          | 1806739/2848161 [00:14<00:08, 126452.02it/s]\u001b[A\n",
      " 64%|██████████████████▌          | 1819493/2848161 [00:14<00:08, 126776.50it/s]\u001b[A\n",
      " 64%|██████████████████▋          | 1832179/2848161 [00:14<00:08, 126800.44it/s]\u001b[A\n",
      " 65%|██████████████████▊          | 1844860/2848161 [00:14<00:07, 126586.29it/s]\u001b[A\n",
      " 65%|██████████████████▉          | 1857543/2848161 [00:14<00:07, 126658.28it/s]\u001b[A\n",
      " 66%|███████████████████          | 1870210/2848161 [00:14<00:07, 126393.76it/s]\u001b[A\n",
      " 66%|███████████████████▏         | 1882908/2848161 [00:14<00:07, 126568.67it/s]\u001b[A\n",
      " 67%|███████████████████▎         | 1895582/2848161 [00:14<00:07, 126617.84it/s]\u001b[A\n",
      " 67%|███████████████████▍         | 1908244/2848161 [00:15<00:07, 126386.32it/s]\u001b[A\n",
      " 67%|███████████████████▌         | 1921012/2848161 [00:15<00:07, 126771.80it/s]\u001b[A\n",
      " 68%|███████████████████▋         | 1933721/2848161 [00:15<00:07, 126863.89it/s]\u001b[A\n",
      " 68%|███████████████████▊         | 1946474/2848161 [00:15<00:07, 127060.54it/s]\u001b[A\n",
      " 69%|███████████████████▉         | 1959181/2848161 [00:15<00:07, 126833.35it/s]\u001b[A\n",
      " 69%|████████████████████         | 1971924/2848161 [00:15<00:06, 127008.79it/s]\u001b[A\n",
      " 70%|████████████████████▏        | 1984626/2848161 [00:15<00:06, 126514.23it/s]\u001b[A\n",
      " 70%|████████████████████▎        | 1997278/2848161 [00:15<00:06, 126182.47it/s]\u001b[A\n",
      " 71%|████████████████████▍        | 2009897/2848161 [00:15<00:06, 126076.21it/s]\u001b[A\n",
      " 71%|████████████████████▌        | 2022505/2848161 [00:15<00:06, 125767.55it/s]\u001b[A\n",
      " 71%|████████████████████▋        | 2035093/2848161 [00:16<00:06, 125800.37it/s]\u001b[A\n",
      " 72%|████████████████████▊        | 2047768/2848161 [00:16<00:06, 126081.56it/s]\u001b[A\n",
      " 72%|████████████████████▉        | 2060377/2848161 [00:16<00:06, 125753.73it/s]\u001b[A\n",
      " 73%|█████████████████████        | 2073053/2848161 [00:16<00:06, 126051.95it/s]\u001b[A\n",
      " 73%|█████████████████████▏       | 2085772/2848161 [00:16<00:06, 126391.07it/s]\u001b[A\n",
      " 74%|█████████████████████▎       | 2098412/2848161 [00:16<00:05, 126295.12it/s]\u001b[A\n",
      " 74%|█████████████████████▍       | 2111042/2848161 [00:16<00:05, 125973.60it/s]\u001b[A\n",
      " 75%|█████████████████████▌       | 2123640/2848161 [00:16<00:05, 125314.79it/s]\u001b[A\n",
      " 75%|█████████████████████▊       | 2136274/2848161 [00:16<00:05, 125617.49it/s]\u001b[A\n",
      " 75%|█████████████████████▉       | 2148837/2848161 [00:16<00:05, 125399.55it/s]\u001b[A\n",
      " 76%|██████████████████████       | 2161378/2848161 [00:17<00:05, 125399.31it/s]\u001b[A\n",
      " 76%|██████████████████████▏      | 2173919/2848161 [00:17<00:05, 125268.71it/s]\u001b[A\n",
      " 77%|██████████████████████▎      | 2186651/2848161 [00:17<00:05, 125881.18it/s]\u001b[A\n",
      " 77%|██████████████████████▍      | 2199268/2848161 [00:17<00:05, 125965.62it/s]\u001b[A\n",
      " 78%|██████████████████████▌      | 2211964/2848161 [00:17<00:05, 126261.22it/s]\u001b[A\n",
      " 78%|██████████████████████▋      | 2224591/2848161 [00:17<00:04, 125985.98it/s]\u001b[A\n",
      " 79%|██████████████████████▊      | 2237190/2848161 [00:17<00:04, 125935.45it/s]\u001b[A\n",
      " 79%|██████████████████████▉      | 2249784/2848161 [00:17<00:04, 125450.61it/s]\u001b[A\n",
      " 79%|███████████████████████      | 2262330/2848161 [00:17<00:04, 125342.73it/s]\u001b[A\n",
      " 80%|███████████████████████▏     | 2274917/2848161 [00:17<00:04, 125498.61it/s]\u001b[A\n",
      " 80%|███████████████████████▎     | 2287472/2848161 [00:18<00:04, 125511.25it/s]\u001b[A\n",
      " 81%|███████████████████████▍     | 2300143/2848161 [00:18<00:04, 125867.70it/s]\u001b[A\n",
      " 81%|███████████████████████▌     | 2312791/2848161 [00:18<00:04, 126049.94it/s]\u001b[A\n",
      " 82%|███████████████████████▋     | 2325397/2848161 [00:18<00:04, 125831.60it/s]\u001b[A\n",
      " 82%|███████████████████████▊     | 2337981/2848161 [00:18<00:04, 125640.22it/s]\u001b[A\n",
      " 83%|███████████████████████▉     | 2350576/2848161 [00:18<00:03, 125730.37it/s]\u001b[A\n",
      " 83%|████████████████████████     | 2363225/2848161 [00:18<00:03, 125957.19it/s]\u001b[A\n",
      " 83%|████████████████████████▏    | 2375821/2848161 [00:18<00:03, 125617.85it/s]\u001b[A\n",
      " 84%|████████████████████████▎    | 2388384/2848161 [00:18<00:03, 125419.96it/s]\u001b[A\n",
      " 84%|████████████████████████▍    | 2400967/2848161 [00:18<00:03, 125541.38it/s]\u001b[A\n",
      " 85%|████████████████████████▌    | 2413541/2848161 [00:19<00:03, 125597.92it/s]\u001b[A\n",
      " 85%|████████████████████████▋    | 2426137/2848161 [00:19<00:03, 125705.43it/s]\u001b[A\n",
      " 86%|████████████████████████▊    | 2438749/2848161 [00:19<00:03, 125828.09it/s]\u001b[A\n",
      " 86%|████████████████████████▉    | 2451397/2848161 [00:19<00:03, 126021.12it/s]\u001b[A\n",
      " 87%|█████████████████████████    | 2464014/2848161 [00:19<00:03, 126064.44it/s]\u001b[A\n",
      " 87%|█████████████████████████▏   | 2476659/2848161 [00:19<00:02, 126177.30it/s]\u001b[A\n",
      " 87%|█████████████████████████▎   | 2489277/2848161 [00:19<00:02, 126171.02it/s]\u001b[A\n",
      " 88%|█████████████████████████▍   | 2501895/2848161 [00:19<00:02, 125392.13it/s]\u001b[A\n",
      " 88%|█████████████████████████▌   | 2514436/2848161 [00:19<00:02, 125321.48it/s]\u001b[A\n",
      " 89%|█████████████████████████▋   | 2526969/2848161 [00:19<00:02, 125239.18it/s]\u001b[A\n",
      " 89%|█████████████████████████▊   | 2539494/2848161 [00:20<00:02, 125223.07it/s]\u001b[A\n",
      " 90%|█████████████████████████▉   | 2552017/2848161 [00:20<00:02, 125142.66it/s]\u001b[A\n",
      " 90%|██████████████████████████   | 2564707/2848161 [00:20<00:02, 125667.58it/s]\u001b[A\n",
      " 90%|██████████████████████████▏  | 2577369/2848161 [00:20<00:02, 125951.59it/s]\u001b[A\n",
      " 91%|██████████████████████████▎  | 2589965/2848161 [00:20<00:02, 125839.23it/s]\u001b[A\n",
      " 91%|██████████████████████████▍  | 2602550/2848161 [00:20<00:01, 125747.19it/s]\u001b[A\n",
      " 92%|██████████████████████████▋  | 2615133/2848161 [00:20<00:01, 125768.71it/s]\u001b[A\n",
      " 92%|██████████████████████████▊  | 2627710/2848161 [00:20<00:01, 125457.45it/s]\u001b[A\n",
      " 93%|██████████████████████████▉  | 2640264/2848161 [00:20<00:01, 125479.33it/s]\u001b[A\n",
      " 93%|███████████████████████████  | 2652859/2848161 [00:20<00:01, 125617.00it/s]\u001b[A\n",
      " 94%|███████████████████████████▏ | 2665421/2848161 [00:21<00:01, 125536.24it/s]\u001b[A\n",
      " 94%|███████████████████████████▎ | 2677975/2848161 [00:21<00:01, 125297.54it/s]\u001b[A\n",
      " 94%|███████████████████████████▍ | 2690591/2848161 [00:21<00:01, 125554.47it/s]\u001b[A\n",
      " 95%|███████████████████████████▌ | 2703191/2848161 [00:21<00:01, 125685.80it/s]\u001b[A\n",
      " 95%|███████████████████████████▋ | 2715838/2848161 [00:21<00:01, 125919.66it/s]\u001b[A\n",
      " 96%|███████████████████████████▊ | 2728431/2848161 [00:21<00:00, 125763.26it/s]\u001b[A\n",
      " 96%|███████████████████████████▉ | 2741008/2848161 [00:21<00:00, 125761.18it/s]\u001b[A\n",
      " 97%|████████████████████████████ | 2753585/2848161 [00:21<00:00, 125625.63it/s]\u001b[A\n",
      " 97%|████████████████████████████▏| 2766273/2848161 [00:21<00:00, 125999.97it/s]\u001b[A\n",
      " 98%|████████████████████████████▎| 2778874/2848161 [00:22<00:00, 125912.96it/s]\u001b[A\n",
      " 98%|████████████████████████████▍| 2791466/2848161 [00:22<00:00, 125531.38it/s]\u001b[A\n",
      " 98%|████████████████████████████▌| 2804088/2848161 [00:22<00:00, 125736.67it/s]\u001b[A\n",
      " 99%|████████████████████████████▋| 2816751/2848161 [00:22<00:00, 126001.08it/s]\u001b[A\n",
      " 99%|████████████████████████████▊| 2829378/2848161 [00:22<00:00, 126078.25it/s]\u001b[A\n",
      "100%|█████████████████████████████| 2848161/2848161 [00:22<00:00, 126296.05it/s]\u001b[A\n",
      "[NeMo I 2025-09-19 04:37:06 nemo_logging:393] Processed 2848161 n-grams of order 5\n",
      "[NeMo I 2025-09-19 04:37:38 nemo_logging:393] Processed 3021801 n-grams of order 6\n",
      "100%|██████████████████████████████| 9631255/9631255 [02:16<00:00, 70789.59it/s]\n",
      "[NeMo I 2025-09-19 04:37:39 nemo_logging:393] Deleted the arpa file '/media/mayjain/Seagate/mayjain/work/del_this/models/ngpu_6g.tmp.arpa'.\n"
     ]
    }
   ],
   "source": [
    "!cd $NEMO_ROOT/scripts/asr_language_modeling/ngram_lm/ && python3 train_kenlm.py \\\n",
    "              nemo_model_file=$MODELS_DIR/parakeet-rnnt-1.1b.nemo \\\n",
    "              train_paths=['{DATA_DOWNLOAD_DIR}/reduced_training.txt'] \\\n",
    "              kenlm_bin_path=$NEMO_ROOT/decoders/kenlm/build/bin \\\n",
    "              kenlm_model_file=$MODELS_DIR/ngpu_6g \\\n",
    "              ngram_length=6 save_nemo=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGH3btfn_mL6"
   },
   "source": [
    "The model is successfully saved as ngpu_6g.nemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FubCSAin_mMC"
   },
   "source": [
    "### Deploying the n-GPU LM with Parakeet RNNT in Nvidia NIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FubCSAin_mMC"
   },
   "source": [
    "## NeMo (Neural Modules) and `nemo2riva`\n",
    "[NVIDIA NeMo](https://developer.nvidia.com/nvidia-nemo) is an open-source framework for building, training, and fine-tuning GPU-accelerated speech AI and natural language understanding (NLU) models with a simple Python interface. To fine-tune a Parakeet-CTC acoustic model with NeMo, refer to the [Parakeet-CTC fine-tuning tutorial](https://github.com/nvidia-riva/tutorials/blob/main/asr-finetune-parakeet-nemo.ipynb).\n",
    "\n",
    "The [`nemo2riva`]() command-line tool provides the capability to export your `.nemo` model in a format that can be deployed using [NVIDIA Riva](https://docs.nvidia.com/nim/riva/asr/latest/overview.html) ASR NIM. A Python `.whl` file for `nemo2riva` is available in [PyPi](https://pypi.org/project/nemo2riva/). You can install `nemo2riva` with `pip`, as shown in the [Parakeet-CTC fine-tuning tutorial](https://github.com/nvidia-riva/tutorials/blob/main/asr-finetune-parakeet-nemo.ipynb). \n",
    "\n",
    "This tutorial explores taking a `.riva` model &mdash; the result of invoking the `nemo2riva` CLI tool (refer to the [Parakeet-CTC fine-tuning tutorial](https://github.com/nvidia-riva/tutorials/blob/main/asr-finetune-parakeet-nemo.ipynb)) &mdash; and leveraging the Riva ServiceMaker framework to aggregate all the necessary artifacts for Riva deployment to a target environment. Once the model is deployed as a Riva NIM, you can issue inference requests to the server. We will demonstrate how quick and straightforward this whole process is.\n",
    "In this tutorial, you will learn how to:\n",
    "- Build an `.rmir` model pipeline from a `.riva` file with Riva ServiceMaker.\n",
    "- Deploy the model locally on the Riva server.\n",
    "- Send inference requests from a demo client using Riva API bindings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets install nemo2riva to convert the donwloaded Parakeet-RNNT model to .riva format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install nemo2riva \n",
    "!pip3 install --extra-index-url https://pypi.nvidia.com  nemo2riva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-09-19 05:19:35 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "INFO: PyTorch version 2.7.0a0+7c8ec84dab.nv25.3 available.\n",
      "INFO: Polars version 1.21.0 available.\n",
      "[NeMo I 2025-09-19 05:19:38 nemo_logging:393] Logging level set to 20\n",
      "[NeMo I 2025-09-19 05:19:38 nemo_logging:393] Restoring NeMo model from '/media/mayjain/Seagate/mayjain/work/del_this/models/parakeet-rnnt-1.1b.nemo'\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO: `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "INFO: `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "INFO: `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "INFO: `Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "INFO: `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "[NeMo I 2025-09-19 05:21:33 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo W 2025-09-19 05:21:33 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-train-all.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-09-19 05:21:33 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-dev-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2025-09-19 05:21:33 nemo_logging:405] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo I 2025-09-19 05:21:33 nemo_logging:393] PADDING: 0\n",
      "[NeMo I 2025-09-19 05:21:38 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-09-19 05:21:38 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-09-19 05:21:38 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Model EncDecRNNTBPEModel was successfully restored from /media/mayjain/Seagate/mayjain/work/del_this/models/parakeet-rnnt-1.1b.nemo.\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/asr-stt-exported-encdecctcmodel.yaml for nemo.collections.asr.models.EncDecCTCModel\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/tts-exported-hifiganmodel.yaml for nemo.collections.tts.models.HifiGanModel\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/nlp-isc-exported-bert.yaml for nemo.collections.nlp.models.IntentSlotClassificationModel\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/tts-exported-radttsmodel.yaml for nemo.collections.tts.models.RadTTSModel\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/nlp-qa-exported-bert.yaml for nemo.collections.nlp.models.QAModel\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/nlp-pc-exported-bert.yaml for nemo.collections.nlp.models.PunctuationCapitalizationModel\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/tts-exported-fastpitchmodel.yaml for nemo.collections.tts.models.FastPitchModel\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/asr-scr-exported-encdecclsmodel.yaml for nemo.collections.asr.models.classification_models.EncDecClassificationModel\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/nlp-mt-exported-encdecmtmodel.yaml for nemo.collections.nlp.models.MTEncDecModel\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/nlp-mt-exported-megatronnmtmodel.yaml for nemo.collections.nlp.models.MegatronNMTModel\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/nlp-tc-exported-bert.yaml for nemo.collections.nlp.models.TextClassificationModel\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/asr-stt-exported-encdectcmodelbpe.yaml for nemo.collections.asr.models.EncDecCTCModelBPE\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Loaded schema file /usr/local/lib/python3.12/dist-packages/nemo2riva/validation_schemas/nlp-tkc-exported-bert.yaml for nemo.collections.nlp.models.TokenClassificationModel\n",
      "[NeMo W 2025-09-19 05:21:41 nemo_logging:405] Validation schema not found for nemo.collections.asr.models.EncDecRNNTBPEModel.\n",
      "    That means Riva does not yet support a pipeline for this network and likely will not work with it.\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Found model at ./model_weights.ckpt\n",
      "[NeMo I 2025-09-19 05:21:41 nemo_logging:393] Retrieved artifacts: dict_keys(['7880ced2d9384574a93511f66fa41d40_tokenizer.model', 'ceccf81b4bfd4f448f63aa1aeb0d7e09_tokenizer.vocab', 'd7786fbc907f40f5a905d51dd63c6cd4_vocab.txt', 'model_config.yaml'])\n",
      "[NeMo I 2025-09-19 05:22:08 nemo_logging:393] Saving to /media/mayjain/Seagate/mayjain/work/del_this/models/parakeet-rnnt-1.1b.riva\n",
      "[NeMo I 2025-09-19 05:24:44 nemo_logging:393] Model saved to /media/mayjain/Seagate/mayjain/work/del_this/models/parakeet-rnnt-1.1b.riva\n"
     ]
    }
   ],
   "source": [
    "!nemo2riva --key tlt_encode --format nemo $MODELS_DIR/parakeet-rnnt-1.1b.nemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Riva ServiceMaker\n",
    "Riva ServiceMaker is a set of tools that aggregates all the necessary artifacts (models, files, configurations, and user settings) for Riva NIM deployment to a target environment. It has two main components:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riva-Build\n",
    "\n",
    "This step helps build a Riva-ready version of the model. Its only output is an intermediate format (called an RMIR) of an end-to-end pipeline for the supported services within Riva. Let's consider an ASR n-gram language model. <br>\n",
    "\n",
    "`riva-build` is responsible for the combination of one or more exported models (`.riva` files) into a single file containing an intermediate format called Riva Model Intermediate Representation (`.rmir`). This file contains a deployment-agnostic specification of the whole end-to-end pipeline along with all the assets required for the final deployment and inference. For more information, refer to the [documentation](https://docs.nvidia.com/nim/riva/asr/latest/custom-deployment.html#deploying-custom-models-as-nim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: UPDATE THESE PATHS \n",
    "\n",
    "# Riva NIM Docker\n",
    "\n",
    "# Refer to this table to get the CONTAINER_ID for the model architecture you want to deploy.\n",
    "# https://docs.nvidia.com/nim/riva/asr/latest/support-matrix.html#supported-models\n",
    "# Since this is RNNT model, we should use following CONTAINER_ID\n",
    "CONTAINER_ID = \"parakeet-1-1b-rnnt-multilingual\"\n",
    "\n",
    "# Name of the acoustic model .riva file\n",
    "ACOUSTIC_MODEL_NAME = f\"{MODELS_DIR}/parakeet-rnnt-1.1b.riva\"\n",
    "\n",
    "# Name of the language model .nemo file\n",
    "LANGUAGE_MODEL_NAME = f\"{MODELS_DIR}/ngpu_6g.nemo\"\n",
    "\n",
    "# Path to store NIM model repository, Make sure that this directory is empty\n",
    "NIM_EXPORT_PATH=\"~/nim_cache\" \n",
    "NIM_EXPORT_PATH=\"/media/mayjain/Seagate/mayjain/work/del_this/nim_cache\"\n",
    "\n",
    "! mkdir -p $NIM_EXPORT_PATH\n",
    "! chmod 777 $NIM_EXPORT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the `.rmir` file\n",
    "\n",
    "Refer to the [Riva ASR NIM Pipeline Configuration documentation](https://docs.nvidia.com/nim/riva/asr/latest/pipeline-configuration.html) to obtain the proper `riva-build` parameters for your particular application, select the acoustic model, language, and pipeline type (offline for the purposes of this tutorial) from the interactive web menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the appropriate value\n",
    "! docker run --gpus all --rm \\\n",
    "     -v $MODEL_DIR:/servicemaker-dev \\\n",
    "     --name riva-servicemaker \\\n",
    "     --entrypoint=\"\" \\\n",
    "     nvcr.io/nim/nvidia/$CONTAINER_ID \\\n",
    "     riva-build speech_recognition \\\n",
    "        /servicemaker-dev/asr_offline_riva_ngram_lm.rmir:tlt_encode \\\n",
    "        /servicemaker-dev/$ACOUSTIC_MODEL_NAME:tlt_encode \\\n",
    "        --offline --name=parakeet-rnnt-1.1b-unified-ml-cs-universal-multi-asr-offline \\\n",
    "        --return_separate_utterances=True --featurizer.use_utterance_norm_params=False \\\n",
    "        --featurizer.precalc_norm_time_steps=0 --featurizer.precalc_norm_params=False \\\n",
    "        --ms_per_timestep=80 --language_code=en-US \\\n",
    "        --nn.fp16_needs_obey_precision_pass --unified_acoustic_model \\\n",
    "        --chunk_size=8.0 --left_padding_size=0 --right_padding_size=0 \\\n",
    "        --featurizer.max_batch_size=256 --featurizer.max_execution_batch_size=256 \\\n",
    "        --max_batch_size=128 --nn.opt_batch_size=128 \\\n",
    "        --endpointing_type=niva --endpointing.stop_history=0  \\\n",
    "        --decoder_type=nemo --nemo_decoder.language_model_alpha=0.5 \\\n",
    "        --nemo_decoder.language_model_file=/servicemaker-dev/ngpu_6g.nemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riva-Deploy\n",
    "\n",
    "The deployment tool takes as input one or more RMIR files and a target model repository directory. It creates an ensemble configuration specifying the pipeline for the execution and finally writes all those assets to the output model repository directory.\n",
    "\n",
    "**Note:** If you added an encryption key to your `.rmir` file when building it with `riva-build`, make sure to append a colon and then the key's value to the model's name in the `riva-deploy` command, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax: riva-deploy -f dir-for-rmir/model.rmir[:key] output-dir-for-repository\n",
    "! docker run --gpus all --rm \\\n",
    "     -v $MODEL_LOC:/servicemaker-dev \\\n",
    "     -v $NIM_EXPORT_PATH:/model_tar \\\n",
    "     --name riva-servicemaker \\\n",
    "     --entrypoint=\"\" \\\n",
    "     nvcr.io/nim/nvidia/$CONTAINER_ID \\\n",
    "     bash -c \"riva-deploy -f /servicemaker-dev/asr_offline_riva_ngram_lm.rmir /data/models/ && tar -czf /model_tar/custom_models.tar.gz -C /data/models .\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Start the Riva ASR NIM\n",
    "After the model repository is generated, we are ready to start the Riva NIM server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the container with the cache directory mounted in the appropriate location:\n",
    "! docker run -it --rm -d --name=$CONTAINER_ID \\\n",
    "   --runtime=nvidia \\\n",
    "   --gpus '\"device=0\"' \\\n",
    "   --shm-size=8GB \\\n",
    "   -e NGC_API_KEY \\\n",
    "   -e NIM_TAGS_SELECTOR \\\n",
    "   -e NIM_DISABLE_MODEL_DOWNLOAD=true \\\n",
    "   -e NIM_HTTP_API_PORT=9000 \\\n",
    "   -e NIM_GRPC_API_PORT=50051 \\\n",
    "   -p 9000:9000 \\\n",
    "   -p 50051:50051 \\\n",
    "   -v $NIM_EXPORT_PATH:/opt/nim/export \\\n",
    "   -e NIM_EXPORT_PATH=/opt/nim/export \\\n",
    "   nvcr.io/nim/nvidia/$CONTAINER_ID:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Inference\n",
    "After the Riva NIM server is up and running with your models, you can send inference requests querying the server. \n",
    "\n",
    "To send gRPC requests, you can install the Riva Python API bindings for the client. This is available as a [Python module on PyPI](https://pypi.org/project/nvidia-riva-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Client API Bindings\n",
    "! pip install nvidia-riva-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import riva.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Connect to the Riva Server and Run Inference\n",
    "\n",
    "NIM server can take some time to load, wait till the server is ready to serve the requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time\n",
    "\n",
    "for i in range(30):\n",
    "    try:\n",
    "        print(f\"Waiting for NIM server to load, retrying in 5 seconds...\")\n",
    "        r = requests.get(\"http://0.0.0.0:9000/v1/health/live\", timeout=2)\n",
    "        if \"live\" in r.text:\n",
    "            print(\"NIM server is ready!\")\n",
    "            break\n",
    "    except requests.RequestException as e:\n",
    "        pass\n",
    "    time.sleep(5)\n",
    "else:\n",
    "    print(\"Server did not become ready after 30 attempts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once the server is ready, we can call this inference function to query the Riva NIM server (using gRPC) to transcribe an audio file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(audio_file, server='localhost:50051', print_full_response=False):\n",
    "    with open(audio_file, 'rb') as fh:\n",
    "        data = fh.read()\n",
    "    \n",
    "    auth = riva.client.Auth(uri=server)\n",
    "    client = riva.client.ASRService(auth)\n",
    "    config = riva.client.RecognitionConfig(\n",
    "        language_code=\"en-US\",\n",
    "        max_alternatives=1,\n",
    "        enable_automatic_punctuation=False,\n",
    "    )\n",
    "    \n",
    "    response = client.offline_recognize(data, config)\n",
    "    if print_full_response: \n",
    "        print(response)\n",
    "    else:\n",
    "        print(response.results[0].alternatives[0].transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = \"audio_samples/en-US_sample.wav\"\n",
    "run_inference(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can stop the Riva NIM server before shutting down the Jupyter kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker stop $CONTAINER_ID\n",
    "!docker rm $CONTAINER_ID"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
