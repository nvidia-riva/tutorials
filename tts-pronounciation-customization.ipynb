{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/notebooks/dlsw-notebooks/riva_tts_tts-python-basics/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# How do I customize Riva TTS pronunciations?\n",
    "\n",
    "This tutorial walks you through the basics of Riva/NeMo TTS pronunciation customization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grapheme-to-phoneme (G2P) Overview\n",
    "\n",
    "Modern **text-to-speech** (TTS) models can learn pronunciations from raw text input and its corresponding audio data.\n",
    "Sometimes, however, it is desirable to customize pronunciations, for example, for domain-specific terms. As a result, many TTS systems use grapheme and phonetic input during training to directly access and correct pronunciations at inference time.\n",
    "\n",
    "\n",
    "[The International Phonetic Alphabet (IPA)](https://en.wikipedia.org/wiki/International_Phonetic_Alphabet) and [ARPABET](https://en.wikipedia.org/wiki/ARPABET) are the most common phonetic alphabets. Starting with the Riva 2.8.0 release, IPA will be the only supported prounciation alphabet for TTS models. Older Riva models only support ARPABET.\n",
    "\n",
    "There are two ways to customize pronunciations in Riva:\n",
    "\n",
    "1. using SSML, note that the request-time overrides are best suited for one-off adjustments. See [this](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tutorials/tts-python-basics-and-customization-with-ssml.html#customizing-pronunciation-with-the-phoneme-tag) for more details.\n",
    "2. configure Riva with the desired domain-specific terms when deploying the server.\n",
    "\n",
    "Both methods require users to convert graphemes into phonemes (G2P). Below we are going to focus on the second approach.\n",
    "\n",
    "#### All words for G2P purposes could be divided into the following groups:\n",
    "* *known* words - words that are present in the model's phonetic dictionary\n",
    "* *out-of-vocabulary (OOV)* words - words that are missing from the model's phonetic dictionary. \n",
    "* *[heteronyms](https://en.wikipedia.org/wiki/Heteronym_(linguistics)* - words with the same spelling but different pronunciations and/or meanings, e.g., *bass* (the fish) and *bass* (the musical instrument).\n",
    "\n",
    "#### Important Riva flags:\n",
    "* `--phone_dictionary_file` path to a dictionary that maps words to their phonetic form, e.g., [ARPABET-based CMU Dictionary](https://github.com/NVIDIA/NeMo/blob/r1.14.0/scripts/tts_dataset_files/cmudict-0.7b_nv22.10) or [IPA-based CMU Dictionary](https://github.com/NVIDIA/NeMo/blob/r1.14.0/scripts/tts_dataset_files/ipa_cmudict-0.7b_nv22.10.txt)\n",
    "* `--preprocessor.g2p_ignore_ambiguous`: if is set to **True**, words with more than one phonetic representation in the pronunciation dictionary are ignored. This flag is relevant to heteronyms and non-heteronym words with multiple valid phonetic forms in the dictionary, for example, due to accent variations.\n",
    "\n",
    "TTS models take a text in grapheme form, then convert all known unambiguous words into phonetic form during preprocessing. The rest of the words (OOV and words with multiple dictionary entries) are kept as graphemes, and the TTS model uses context clues from the sentence to predict an appropriate pronunciation for such words.\n",
    "\n",
    "To ensure the desired pronunciation, we need to add a new entry to `--phone_dictionary_file` dictionary. If the target word is already in the dictionary, we need to remove the default pronunciation so that only the target pronunciation is present. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary customization\n",
    "\n",
    "Below we show how to customize phonetic dictionary for NeMo/Riva models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You can either run this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\n",
    "Instructions for setting up Colab are as follows:\n",
    "1. Open a new Python 3 notebook.\n",
    "2. Import this notebook from GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\n",
    "3. Connect to an instance with a GPU (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\n",
    "4. Run this cell to set up dependencies.\n",
    "\"\"\"\n",
    "\n",
    "BRANCH = 'main'\n",
    "# # If you're using Google Colab and not running locally, uncomment and run this cell.\n",
    "# !apt-get install sox libsndfile1 ffmpeg\n",
    "# !pip install wget text-unidecode pynini==2.1.4\n",
    "# !python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n",
    "# !wget https://raw.githubusercontent.com/NVIDIA/NeMo/main/nemo_text_processing/install_pynini.sh\n",
    "# !bash install_pynini.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nemo.collections.tts as nemo_tts\n",
    "from nemo_text_processing.g2p.modules import IPAG2P\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "\n",
    "# Load mel spectrogram generator\n",
    "spec_generator = nemo_tts.models.FastPitchModel.from_pretrained(\"tts_en_fastpitch_ipa\")\n",
    "# to use dictionary entries for known words\n",
    "spec_generator.vocab.phoneme_probability = 1\n",
    "spec_generator.vocab.g2p.phoneme_probability = 1\n",
    "\n",
    "# Load vocoder\n",
    "vocoder = nemo_tts.models.HifiGanModel.from_pretrained(model_name=\"tts_hifigan\")\n",
    "\n",
    "\n",
    "def generate_audio(input_text):\n",
    "    parsed = spec_generator.parse(input_text)\n",
    "    spectrogram = spec_generator.generate_spectrogram(tokens=parsed)\n",
    "    audio = vocoder.convert_spectrogram_to_audio(spec=spectrogram)\n",
    "    display(ipd.Audio(audio.detach().to('cpu').numpy(), rate=22050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"paracetamol can help reduce fever.\"\n",
    "generate_audio(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During preprocessing, unambiguous dictionary words are converted to phonemes, while OOV and words with multiple entries are kept as graphemes. For example, **paracetamol** is missing in from the phonetic dictionary, and **can** has 2 forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Input before tokenization: |{' '.join(spec_generator.vocab.g2p(text))}|\\n\")\n",
    "for word in [\"paracetamol\", \"can\"]:\n",
    "    word = word.upper()\n",
    "    phoneme_forms = spec_generator.vocab.g2p.phoneme_dict[word]\n",
    "    print(f\"Number of phoneme forms for wordPhoneme forms for '{word}': {len(phoneme_forms)} -- {phoneme_forms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a new entry to the dictionary for the word **paracetamol**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we download IPA-based CMU Dictionary and add a custom entry for the target word\n",
    "ipa_cmu_dict = \"ipa_cmudict-0.7b_nv22.10.txt\"\n",
    "if os.path.exists(ipa_cmu_dict):\n",
    "    ! rm $ipa_cmu_dict\n",
    "\n",
    "! wget https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/tts_dataset_files/$ipa_cmu_dict\n",
    "\n",
    "new_pronunciation = \"ˌpæɹəˈsitəmɔl\"\n",
    "\n",
    "with open(ipa_cmu_dict, \"a\") as f:\n",
    "    f.write(f\"PARACETAMOL  {new_pronunciation}\\n\")\n",
    "        \n",
    "! tail $ipa_cmu_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now use our updated dictionary as the model's phonetic dictionary\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "phoneme_dict_obj = defaultdict(list)\n",
    "_alt_re = re.compile(r\"\\([0-9]+\\)\")\n",
    "with open(ipa_cmu_dict, \"r\") as fdict:\n",
    "    for line in fdict:\n",
    "        if len(line) and ('A' <= line[0] <= 'Z' or line[0] == \"'\"):\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            word = re.sub(_alt_re, \"\", parts[0])\n",
    "            prons = re.sub(r\"\\s+\", \"\", parts[1])\n",
    "            phoneme_dict_obj[word].append(list(prons))\n",
    "\n",
    "spec_generator.vocab.g2p.phoneme_dict = phoneme_dict_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paracetomol** is no longer an OOV, and the model uses the phonetic form we provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(spec_generator.vocab.g2p(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's use the new phoneme dictionary for synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_audio(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, one can customize the TTS model's output by altering entries in the phonetic dictionary with --phone_dictionary_file flag.\n",
    "\n",
    "\n",
    "# Resources\n",
    "* [Riva TTS documentation](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tts/tts-overview.html)\n",
    "* [TTS pipeline costumizaiton](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tts/tts-custom.html#tts-pipeline-configuration)\n",
    "* [Overview of TTS in NeMo](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tts/NeMo_TTS_Primer.ipynb)\n",
    "* [G2P models in NeMo](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/text_processing/g2p/g2p.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "38",
   "language": "python",
   "name": "38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
