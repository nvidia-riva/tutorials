{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e92aa8",
   "metadata": {},
   "source": [
    "# NeMo to Riva\n",
    "\n",
    "In this tutorial, we will go through the steps to convert nemo checkpoint to riva checkpoints. Models trained in nemo have _.nemo_ format. To use these models in riva, we will need to convert them to _.riva_ format. The models in _.riva_ format can be further used to generate rmir files which are deployable on riva server.\n",
    "\n",
    "NeMo is an open source PyTorch-based toolkit for research in conversational AI. While [TAO Toolkit](https://developer.nvidia.com/tao-toolkit) is the recommended path for typical users of Riva, some developers may prefer to use NeMo because it exposes more of the model and PyTorch internals. Riva supports the ability to import models trained in NeMo.  \n",
    "\n",
    "For more information, refer to the [NeMo project page](https://github.com/NVIDIA/NeMo).  \n",
    "\n",
    "We will use a pretrained [fastpitch](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_en_fastpitch), [hifiGan](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_hifigan) checkpoint from ngc for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878a7e18",
   "metadata": {},
   "source": [
    "#### Install the packages\n",
    "\n",
    "We will now install the packages NeMo and nemo2riva. nemo2riva is available on [ngc](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/riva/resources/riva_quickstart/files?version=2.4.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24246562",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nvidia-pyindex\n",
    "!pip install nemo_toolkit['all']\n",
    "!ngc registry resource download-version \"nvidia/riva/riva_quickstart:2.4.0\"\n",
    "!pip install \"riva_quickstart_v2.4.0/nemo2riva-2.4.0-py3-none-any.whl\"\n",
    "!pip install protobuf==3.20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f25a2f",
   "metadata": {},
   "source": [
    "Take a look at the command and arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694c827",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!nemo2riva --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938f242c",
   "metadata": {},
   "source": [
    "We will be using following arguments in this tutorial:  \n",
    "`--key`: Encryption key or file. If this argument is used, key needs to be preserved and used in rmir generation and model deployment as well.  \n",
    "`--out`: Output .riva filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ad2780",
   "metadata": {},
   "source": [
    "## Download models\n",
    "We will now download nemo checkpoints for [fastpitch](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_en_fastpitch) and [hifiGan](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_hifigan) models from ngc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3345c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_fastpitch/versions/1.8.1/files/tts_en_fastpitch_align.nemo'\n",
    "!wget 'https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_hifigan/versions/1.0.0rc1/files/tts_hifigan.nemo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0c82a4",
   "metadata": {},
   "source": [
    "#### Convert to riva.\n",
    "Convert the downloaded model to .riva format, we will use encryption key=`nemotoriva`. Change this while generating .riva models for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972f16b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!nemo2riva --out Fastpitch.riva --key=nemotoriva tts_en_fastpitch_align.nemo\n",
    "!nemo2riva --out HifiGan.riva --key=nemotoriva tts_hifigan.nemo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ed3e55",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this tutorial, we learned how to generate riva formate files using nemo checkpoints. We can take the files generated in this tutorial to build an [RMIR](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/model-overview.html#riva-build) file and deploy it on riva server."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_speech_ml0.6",
   "language": "python",
   "name": "py38_speech_ml0.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
